[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stephen Pierzchajlo",
    "section": "",
    "text": "MSc Neuroscience\nCurrently a PhD Candidate in Psychology at Stockholm University\n \n  \n   \n  \n    \n     E-mail\n  \n  \n    \n     Twitter\n  \n  \n    \n     Google Scholar\n  \n  \n    \n     GitHub"
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Stephen Pierzchajlo",
    "section": "About",
    "text": "About\nWrite Something About Myself Here.\nLearn more"
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Stephen Pierzchajlo",
    "section": "Projects",
    "text": "Projects\n\n\n\n\n\n\n\nWhy You Should Pre-specify Exploratory Analyses\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#blog-posts",
    "href": "index.html#blog-posts",
    "title": "Stephen Pierzchajlo",
    "section": "Blog posts",
    "text": "Blog posts\n\n\n\n\n\nWhy You Should Pre-specify Exploratory Analyses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\nMore posts"
  },
  {
    "objectID": "index.html#cv",
    "href": "index.html#cv",
    "title": "Stephen Pierzchajlo",
    "section": "CV",
    "text": "CV\nWrite Same Thing About Myself As I"
  },
  {
    "objectID": "index.html#learn-more",
    "href": "index.html#learn-more",
    "title": "Stephen Pierzchajlo",
    "section": "Learn more",
    "text": "Learn more"
  },
  {
    "objectID": "content/about.html",
    "href": "content/about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "content/posts/1-eyeball-test/1-eyeball-test.html",
    "href": "content/posts/1-eyeball-test/1-eyeball-test.html",
    "title": "Why You Should Pre-specify Exploratory Analyses",
    "section": "",
    "text": "# load libraries\nlibrary(tidyverse)\nlibrary(tidyr)\nlibrary(lsr)\nlibrary(ggpubr)"
  },
  {
    "objectID": "content/posts/1-eyeball-test/1-eyeball-test.html#how-does-a-simulation-work",
    "href": "content/posts/1-eyeball-test/1-eyeball-test.html#how-does-a-simulation-work",
    "title": "Why You Should Pre-specify Exploratory Analyses",
    "section": "How Does a Simulation Work?",
    "text": "How Does a Simulation Work?\nThis simulation will assume the null hypthesis is true. Therefore, there wonâ€™t be any difference between the groups at the population level. There may, however, be difference at the sample level. In fact, there almost always will be. Because I prefer linear regression, I will simulate data from a linear model:\n\\(Y_{i} \\mid \\beta_{0}, \\beta_{1}, \\sigma \\sim N (\\mu_{i}, \\sigma^{2})\\) with \\(\\mu_{i} = \\beta_{0} + \\beta_{1}X_{i}\\)\nHowever, because the slope will always be cancelled out by zero, this model can be simplified to this:\n\\(Y_{i} \\mid \\beta_{0}, \\sigma \\sim N (\\mu_{i}, \\sigma^{2})\\) with \\(\\mu_{i} = \\beta_{0}\\)\nFirst, I make an indicator for the independent variable. One group will have a zero, and the other a one. This also means the sample size is going to be n = 100.\n\nx &lt;- rep(c(0, 1), each = 50)\nx\n\n  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nTo make the dependent variable, one would need to add and multiply the model coefficients with the independent variable(s). That is what I will do here. No measurement is perfect though, so every sample will be measured with some error. I am simulating this error with the rnorm() function. Because there is no difference at the population level between the two groups, both groups are sampled from a normal distribution with a mean of 350 and a standard deviation of 30. To calculate the difference between groups, one would add a slope to the intercept. Here, the slope is zero and cancels out the influence of the independent variable.\n\nset.seed(1234)\ny &lt;- rnorm(100, mean = 350, sd = 30) + 0*x\ny\n\n  [1] 313.7880 358.3229 382.5332 279.6291 362.8737 365.1817 332.7578 333.6010\n  [9] 333.0664 323.2989 335.6842 320.0484 326.7124 351.9338 378.7848 346.6914\n [17] 334.6697 322.6641 324.8848 422.4751 354.0226 335.2794 336.7836 363.7877\n [25] 329.1884 306.5539 367.2427 319.2903 349.5459 321.9215 383.0689 335.7322\n [33] 328.7168 334.9623 301.1272 314.9714 284.5988 309.7702 341.1712 336.0231\n [41] 393.4849 317.9407 324.3391 341.5813 320.1698 320.9446 316.7805 312.4404\n [49] 334.2852 335.0945 295.8191 332.5377 316.7333 319.5511 345.1307 366.8917\n [57] 399.4345 326.7994 398.1773 315.2657 369.6977 426.4697 348.9572 329.9110\n [65] 349.7719 403.3125 315.8418 391.0348 389.8869 360.0942 350.2068 336.3359\n [73] 339.0043 369.4486 412.1081 345.3980 308.2790 328.2925 357.7479 340.4882\n [81] 344.6663 344.9002 308.8309 344.7864 375.5070 370.9283 366.4999 337.9180\n [89] 344.2522 314.1642 348.4052 357.6559 401.1789 380.0454 335.1325 360.6665\n [97] 315.9618 376.3461 379.1875 413.6335\n\n\nNow the data can be put in a dataframe\n\nsim_df &lt;- data.frame(x, y)\nhead(sim_df)\n\n  x        y\n1 0 313.7880\n2 0 358.3229\n3 0 382.5332\n4 0 279.6291\n5 0 362.8737\n6 0 365.1817\n\n\nFinally, a linear regression can be performed on the sample. Remember, their is no difference between the two groups at the pupulation level, but there almost certainlt will be differences at the sample level (due to sampling error).\n\nmodel &lt;-  lm(y ~ x, data = sim_df)\nsummary(model)\n\n\nCall:\nlm(formula = y ~ x, data = sim_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-58.367 -17.301  -3.815  15.830  86.067 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  336.408      4.090  82.242  &lt; 2e-16 ***\nx             17.777      5.785   3.073  0.00274 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 28.92 on 98 degrees of freedom\nMultiple R-squared:  0.0879,    Adjusted R-squared:  0.07859 \nF-statistic: 9.444 on 1 and 98 DF,  p-value: 0.002743\n\n\nAbove I can see the slope coefficient (x) is actually statistically significant. This is likely due to the dact that the Intercept estimate is so low. Both groups were sampled from the same distribution centered at 350. THe Intercept is 336, and the slope is 18. This means the mean of the second group is 336 + 18 = 354. In frequentist statistics, probabilities are conceptualized in reference to long-term frequencies. For instance, we know a fair coin has a 50% probability of coming up heads because if we flipped that coin a theoretically infinite number of times, approximately 50% of those flips would land heads. P-values can be thought of the same way: If you were to run the same experiment an infinite number of times, fixing the sample size and collecting a new sample with each experiment, how many p-values would be below your threshold (in most cases in science, the threshold is 0.05)? When the null hypothesis is true, only 5% of experiments will yield a p-value below 0.05."
  }
]