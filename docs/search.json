[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stephen Pierzchajlo",
    "section": "",
    "text": "MSc Neuroscience\nCurrently a PhD Candidate in Psychology at Stockholm University\n \n  \n   \n  \n    \n     E-mail\n  \n  \n    \n     Twitter\n  \n  \n    \n     Google Scholar\n  \n  \n    \n     GitHub"
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Stephen Pierzchajlo",
    "section": "About",
    "text": "About\nI am an experimental psychologist and cognitive neuroscientist with a passion for data analysis and statistics.\nLearn more"
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Stephen Pierzchajlo",
    "section": "Projects",
    "text": "Projects\n\n\n\n\n\n\n\nJournal Of Neuroscience: Bayesian Reanalysis\n\n\n\n\n\n\n\n\n\n\n\n\n\nThreat Imminence And Everyday Altruism During The COVID-19 Pandemic\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#blog-posts",
    "href": "index.html#blog-posts",
    "title": "Stephen Pierzchajlo",
    "section": "Blog posts",
    "text": "Blog posts\n\n\n\n\n\nWhy You Should Pre-specify Exploratory Analyses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\nMore posts"
  },
  {
    "objectID": "index.html#cv",
    "href": "index.html#cv",
    "title": "Stephen Pierzchajlo",
    "section": "CV",
    "text": "CV\nWrite Same Thing About Myself As I"
  },
  {
    "objectID": "index.html#learn-more",
    "href": "index.html#learn-more",
    "title": "Stephen Pierzchajlo",
    "section": "Learn more",
    "text": "Learn more"
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "",
    "text": "The data I am analysing comes from a paper I recently published in the Journal Of Neuroscience (https://www.jneurosci.org/content/44/22/e1232232024). The paper involves 3 experiments, of which I am only analysing data from the first. I have chosen this study because I actually wanted to do a Bayesian analysis originally, and wanted to do a random effects model as well. We opted for a Frequentist analysis and a 3-way ANOVA. Here I will perform the same analyses using a Bayesian random-effects model.\n\n\nPeople are notoriously bad at identifying odors. Herrick (1993) noted that the olfactory cortex of most species is large, relative to other areas, and it is only in humans that the olfactory epithelium becomes dwarfed by the neocortex. This is likely do to evolution favoring cognitive capabilities, along with senses more important to our lives, like vision. Herrick hypothesized that, because the human olfactory cortex still contains dense interconnectivity with other sensory modalities, that maybe olfaction relies on other senses to help with olfactory identification and localization. Additionally, a recent study found that when people describe different types of sensory stimuli, all but olfaction are described abstractly (i.e. bright). Olfactory stimuli alone Are described as object-based (i.e. lemon).\n\n\n\nAfter removing some participants for poor performance, this dataset includes 63 participants (40 female; age range: 18-65; mean age: 32 years) total.\n\n\n\nWe developed a behavioural task where people listened to a predictive cue, were presented with a target, and then had to determine whether the cue and target matched or did not match. The cue was delivered by a voice, and the target was either visual or olfactory. The cue could also be object-based (i.e. lemon) or category-based (i.e. fruit). The targets consisted of 4 stimuli: lavender, lilac, lemon, pear. These could be presented both visually and in an olfactory manner. We hypothesized that, if olfaction requires information from another sensory modality, that their would be a large disparity in reaction time between matching (congruent) and non-matching (incongruent) cues and targets. We further hypothesized that this disparity would not be seen when the targets were visual. We also hypothesized that, in olfaction, this disparity would be larger when the cues were object-based, rather than category based.\n\n\n\nTheir are several predictions that are important for this assignment. First, we predicted much slower responses to olfactory targets. We also predicted participants would be slower at responding when cues and targets did not match. We further predicted that this slowness in responding to cues and targets that were incongruent would be larger when the targets were olfactory. Finally, we predicted that, in olfaction, people would respond more slowly to incongruent cues/targets whe nthe cues were object-based."
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#short-introduction",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#short-introduction",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "",
    "text": "People are notoriously bad at identifying odors. Herrick (1993) noted that the olfactory cortex of most species is large, relative to other areas, and it is only in humans that the olfactory epithelium becomes dwarfed by the neocortex. This is likely do to evolution favoring cognitive capabilities, along with senses more important to our lives, like vision. Herrick hypothesized that, because the human olfactory cortex still contains dense interconnectivity with other sensory modalities, that maybe olfaction relies on other senses to help with olfactory identification and localization. Additionally, a recent study found that when people describe different types of sensory stimuli, all but olfaction are described abstractly (i.e. bright). Olfactory stimuli alone Are described as object-based (i.e. lemon)."
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#participant-information",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#participant-information",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "",
    "text": "After removing some participants for poor performance, this dataset includes 63 participants (40 female; age range: 18-65; mean age: 32 years) total."
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#hypotheses",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#hypotheses",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "",
    "text": "We developed a behavioural task where people listened to a predictive cue, were presented with a target, and then had to determine whether the cue and target matched or did not match. The cue was delivered by a voice, and the target was either visual or olfactory. The cue could also be object-based (i.e. lemon) or category-based (i.e. fruit). The targets consisted of 4 stimuli: lavender, lilac, lemon, pear. These could be presented both visually and in an olfactory manner. We hypothesized that, if olfaction requires information from another sensory modality, that their would be a large disparity in reaction time between matching (congruent) and non-matching (incongruent) cues and targets. We further hypothesized that this disparity would not be seen when the targets were visual. We also hypothesized that, in olfaction, this disparity would be larger when the cues were object-based, rather than category based."
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#predictions",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#predictions",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "",
    "text": "Their are several predictions that are important for this assignment. First, we predicted much slower responses to olfactory targets. We also predicted participants would be slower at responding when cues and targets did not match. We further predicted that this slowness in responding to cues and targets that were incongruent would be larger when the targets were olfactory. Finally, we predicted that, in olfaction, people would respond more slowly to incongruent cues/targets whe nthe cues were object-based."
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#load-global-environment",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#load-global-environment",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "Load Global Environment",
    "text": "Load Global Environment\n\n# load variables that are saved outside R\nload(\"C:/Users/STPI0560/Desktop/Archieve/Stat 2.5/assignment/workspace/assignmentworkspace.RData\")"
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#load-libraries",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#load-libraries",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "Load Libraries",
    "text": "Load Libraries\n\n# load libraries\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(brms)\nlibrary(bayesplot)\nlibrary(tidybayes) \nlibrary(ggpubr)\nlibrary(gridExtra)"
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#set-ggplot-theme-and-color-scheme",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#set-ggplot-theme-and-color-scheme",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "Set ggplot Theme And Color Scheme",
    "text": "Set ggplot Theme And Color Scheme\n\n# set ggplot theme\ntheme_set(theme_minimal())\n# set ggplot colors\ncolors &lt;- c(\"#d1e1ec\", \"#b3cde0\", \"#6497b1\", \"#005b96\", \"#03396c\", \"#011f4b\")"
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#example-dataframe",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#example-dataframe",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "Example Dataframe",
    "text": "Example Dataframe\nBelow is an example for how one participants’ data might look. These data are fake, but provide an overview for how the data are organized.\n\n# Fill dataframe with fake values for one participant\nfaketable &lt;- data.frame(\n  row = c(1, 2, 3, 4, \"...\", 44, 45, 46, 47, \"...\", 82, 83, 84, 85, \"...\", 127, 128, 129, 130),\n  subject = c(rep(1, times = 4), \"...\", rep(1, times = 4), \"...\", rep(1, times = 4), \"...\", rep(1, times = 4)),\n  modality = c(rep(\"visual\", times = 4), \"...\", rep(\"visual\", times = 4), \"...\", rep(\"olfactory\", times = 4), \"...\", rep(\"olfactory\", times = 4)),\n  congruency = c(rep(c(\"congruent\", \"incongruent\"), times = 2), \"...\",rep(c(\"congruent\", \"incongruent\"), times = 2), \"...\", rep(c(\"congruent\", \"incongruent\"), times = 2), \"...\",rep(c(\"congruent\", \"incongruent\"), times = 2)),\n  cue_type = c(rep(\"object\", time = 4), \"...\", rep(\"category\", times = 4), \"...\", rep(\"object\", time = 4), \"...\", rep(\"category\", times = 4)),\n  auditory_cue = c(\"lavender\", \"lilac\", \"lemon\", \"pear\", \"...\", \"flower\", \"flower\", \"fruit\", \"fruit\", \"...\", \"lavender\", \"lilac\", \"lemon\", \"pear\", \"...\", \"flower\", \"flower\", \"fruit\", \"fruit\"),\n  target = c(\"lavender\", \"lavender\", \"lemon\", \"lemon\", \"...\", \"lavender\", \"pear\", \"lemon\", \"lilac\", \"...\", \"lavender\", \"lavender\", \"lemon\", \"lemon\", \"...\", \"lavender\", \"pear\", \"lemon\", \"lilac\"),\n  reaction_time = c(564, 740, 602, 557, \"...\", 471, 649, 668, 519, \"...\", 1121, 1576, 1844, 1343, \"...\", 1876, 1265, 1721, 1846)\n  )\n# display fake dataframe with nice kable styling\nfaketable %&gt;%\n  kbl(caption = \"Example dataframe\") %&gt;%\n  kable_classic(full_width = F, html_font = \"Cambria\")\n\n\nExample dataframe\n\n\nrow\nsubject\nmodality\ncongruency\ncue_type\nauditory_cue\ntarget\nreaction_time\n\n\n\n\n1\n1\nvisual\ncongruent\nobject\nlavender\nlavender\n564\n\n\n2\n1\nvisual\nincongruent\nobject\nlilac\nlavender\n740\n\n\n3\n1\nvisual\ncongruent\nobject\nlemon\nlemon\n602\n\n\n4\n1\nvisual\nincongruent\nobject\npear\nlemon\n557\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n44\n1\nvisual\ncongruent\ncategory\nflower\nlavender\n471\n\n\n45\n1\nvisual\nincongruent\ncategory\nflower\npear\n649\n\n\n46\n1\nvisual\ncongruent\ncategory\nfruit\nlemon\n668\n\n\n47\n1\nvisual\nincongruent\ncategory\nfruit\nlilac\n519\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n82\n1\nolfactory\ncongruent\nobject\nlavender\nlavender\n1121\n\n\n83\n1\nolfactory\nincongruent\nobject\nlilac\nlavender\n1576\n\n\n84\n1\nolfactory\ncongruent\nobject\nlemon\nlemon\n1844\n\n\n85\n1\nolfactory\nincongruent\nobject\npear\nlemon\n1343\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n127\n1\nolfactory\ncongruent\ncategory\nflower\nlavender\n1876\n\n\n128\n1\nolfactory\nincongruent\ncategory\nflower\npear\n1265\n\n\n129\n1\nolfactory\ncongruent\ncategory\nfruit\nlemon\n1721\n\n\n130\n1\nolfactory\nincongruent\ncategory\nfruit\nlilac\n1846"
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#load-data",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#load-data",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "Load Data",
    "text": "Load Data\nThe data I am using is a single .csv file from our previous experiment. These data were pre-processed in a separate R script that took each individual participants’ data and combined them into a single dataframe. The data are not aggregated, so they still represent the participants’ raw data. However, 5 participants were removed for having very low accuracy in the task. Additionally, we were only interested in trials where participants’ correctly determined whether the cue and target matched/did not match. Thus, these data only represent “correct” trials. Additionally, all participants’ in this dataset had at least 80% accuracy across the study.\n\n# load data\ndf &lt;- read.csv(file = \"C:/Users/STPI0560/Desktop/Archieve/Stat 2.5/assignment/data/object_category.csv\", header = TRUE)\n# glimpse first few rows\nhead(df)\n\n  participant modality  congruency cue_type      cue   target reaction_time\n1         101   visual incongruent   object     Pear Lavender     1933.3277\n2         101   visual   congruent   object     Pear     Pear      400.3761\n3         101   visual   congruent   object    Lemon    Lemon      500.3686\n4         101   visual incongruent   object    Lilac     Pear      833.7295\n5         101   visual   congruent   object    Lilac    Lilac      533.7733\n6         101   visual   congruent   object Lavender Lavender      883.7940\n\n\nSome columns need to be changed to factors for the analysis.\n\n# Columns to convert to factors\ncols_to_factor &lt;- c(\"participant\", \"modality\", \"congruency\", \"cue_type\", \"cue\", \"target\")\n# Convert specified columns to factors\ndf[cols_to_factor] &lt;- lapply(df[cols_to_factor], as.factor)\n\nFirst, I wanted to plot the distribution of the dependent variable (reaction time) for both visual and olfactory target trials. This is because reaction time is often skewed. If the distributions are indeed skewed, I may want to model them using an Exgaussian distribution.\n\n# Add mean lines\nggplot(df, aes(x=reaction_time, fill = modality)) +\n  geom_histogram(bins = 100)+\n  theme(legend.position=\"top\") +\n  scale_fill_manual(values = c(colors[2], colors[5]))\n\n\n\n\n\n\n\n\nThey definitely appear skewed. Thus, I will take that into account with my model. However, I want to try both an Exgaussian and Gaussian model. I will then see how well each model recovers the distribution of the dependent variable using a Posterior Predictive Check (PPC)."
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#gaussian-model",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#gaussian-model",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "Gaussian model",
    "text": "Gaussian model\n\nPrior Predictive Check.\nI want to use informative priors for my model as I have already conducted several other similar studies and have several ideas about how reaction times will differ between different conditions. My original plan was to conduct a Prior Predictive Check to see how my informative priors would generate reaction time data. However, this proved too difficult and time consuming. The Prior Predictive Check gave estimates of some pararmeters in the millions, while also having very low effective sample sizes (ess). Some of the ess values were as low as 20, even with 4 chains running for 10,000 iterations. I think the model is simply to complex for the number of iterations I would need to run for stable estimates. Therefore, I will be going ahead without a Prior Predictive Check.\n\n\nInformative Priors\nI decided to use informative priors as I have run several studies looking at modality and congruency regarding vision and olfaction. Those have been outlined in the Notation section above. I did not put informative priors on the interaction terms however, because it is very hard to predict exactly how they will turn out.\n\n\nFitting Gaussian Model in brm\nFirst, I estimated the 3-way factorial model using a Gaussian distribution.\n\n# run Gaussian model in brm\ngaussian_model &lt;- brm(\n  reaction_time ~ modality*congruency*cue_type + (target|participant),\n  data = df,\n  family = gaussian(),\n  prior = c(prior(normal(1200, 200), class = Intercept),\n            prior(normal(500, 100), class = b, coef = \"modalityvisual\"),\n            prior(normal(200, 50), class = b, coef = \"congruencyincongruent\"),\n            prior(normal(100, 50), class = b, coef = \"cue_typeobject\"),\n            prior(cauchy(0, 2), class = sd),\n            prior(cauchy(0, 2), class = sigma),\n            prior(lkj(2), class = cor)),\n  iter  = 6000,\n  warmup = 2000,\n  file = \"C:/Users/STPI0560/Desktop/Archieve/Stat 2.5/assignment/models/gaussian_model\"\n  )"
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#exgaussian-model",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#exgaussian-model",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "Exgaussian Model",
    "text": "Exgaussian Model\nNext, I run an Exgaussian model. Everything is identical to the Gaussian model otherwise.\n\n# run Exgaussian model in brm\nexgaussian_model &lt;- brm(\n  reaction_time ~ modality*congruency*cue_type + (target|participant),\n  data = df,\n  family = exgaussian(),\n  prior = c(prior(normal(1200, 200), class = Intercept),\n            prior(normal(500, 100), class = b, coef = \"modalityvisual\"),\n            prior(normal(200, 50), class = b, coef = \"congruencyincongruent\"),\n            prior(normal(100, 50), class = b, coef = \"cue_typeobject\"),\n            prior(cauchy(0, 2), class = sd),\n            prior(cauchy(0, 2), class = sigma),\n            prior(lkj(2), class = cor)),\n  iter  = 6000,\n  warmup = 2000, \n  file = \"C:/Users/STPI0560/Desktop/Archieve/Stat 2.5/assignment/models/exgaussian_model\",\n  )\n\nUsing informative priors with the Exgaussian model led to sever errors, with R-hat values over 3 and ess values as low as 5. Not shown here, I ran another Exgaussian model where I used the default priors brm gives you. This model did well, so I will use it from here."
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#model-comparison",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#model-comparison",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "Model Comparison",
    "text": "Model Comparison\nMy plan was to first compare these models using the loo function. However, due to their complexity, I would need to redo both models and save the parameters as the models go. I have done this before and know it would take at least twice as long to run (sometimes longer). Given that the Exgaussian model took more than a day to complete, I just don’t have time. Instead I will let the PPC below guide my model selection."
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#mcmc-traceplots",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#mcmc-traceplots",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "MCMC Traceplots",
    "text": "MCMC Traceplots\n\nmcmc_trace(gaussian_model, pars = c(\"b_Intercept\", \"b_modalityvisual\", \"b_congruencyincongruent\", \"b_cue_typeobject\", \"b_modalityvisual:congruencyincongruent\", \"b_modalityvisual:cue_typeobject\", \"b_congruencyincongruent:cue_typeobject\", \"b_modalityvisual:congruencyincongruent:cue_typeobject\", \"sigma\"), \n           facet_args = list(ncol = 2, strip.position = \"left\"))\n\n\n\n\n\n\n\n\nAll chains had Rhat values of 1, so I know they converged. This just gives a bit more visual evidence of that."
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#fixed-effects",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#fixed-effects",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "Fixed Effects",
    "text": "Fixed Effects\nHere I am taking all draws from all markov chains for all parameters and plotting a histogram of them. I will also take the model estimates and credible intervals and plot those under the histogram.\n\n# make posterior draws dataframe\ndraws_posterior &lt;- gaussian_model |&gt;\n  # select coefficients\n  spread_draws(b_Intercept, b_modalityvisual, b_congruencyincongruent, b_cue_typeobject, `b_modalityvisual:congruencyincongruent`, `b_modalityvisual:congruencyincongruent:cue_typeobject`) |&gt;\n  # new column called \"posterior\"\n  mutate(distribution = \"posterior\")\n\n\nMain Effects\nBelow I plot the posterior distributions for the main fixed effects.\n\n# graph of modality\nmodality_main_graph &lt;- ggplot(draws_posterior, aes(x = b_modalityvisual)) +\n  geom_histogram(binwidth = 0.75, position = \"identity\", color = colors[3], fill = colors[3]) +\n  geom_point(aes(x = fixef(gaussian_model)[2, 1], y = 0), colour = \"black\", size = 3) +\n  geom_segment(aes(x = fixef(gaussian_model)[2, 3], y = 0, xend = fixef(gaussian_model)[2, 4], yend = 0), size = 1, color = \"black\") +\n  ggtitle(\"Main Effect: Modality\") +\n  labs(x = \"Vision - Olfaction\",y = \"\") +\n  theme(axis.title = element_text(size = 9, face = \"bold\"),\n        plot.title = element_text(size = 11))\n\n# graph of congruency\ncongruency_main_graph &lt;- ggplot(draws_posterior, aes(x = b_congruencyincongruent)) +\n  geom_histogram(binwidth = 0.75, position = \"identity\", color = colors[3], fill = colors[3]) +\n  geom_point(aes(x = fixef(gaussian_model)[3, 1], y = 0), colour = \"black\", size = 3) +\n  geom_segment(aes(x = fixef(gaussian_model)[3, 3], y = 0, xend = fixef(gaussian_model)[3, 4], yend = 0), size = 1, color = \"black\") +\n  ggtitle(\"Main Effect: Congruency\") +\n  labs(x = \"Incongruent - Congruent\",y = \"\") +\n  theme(axis.title = element_text(size = 9, face = \"bold\"),\n        plot.title = element_text(size = 11))\n\n# graph of cue-type\ncuetype_main_graph &lt;- ggplot(draws_posterior, aes(x = b_cue_typeobject)) +\n  geom_histogram(binwidth = 0.75, position = \"identity\", color = colors[3], fill = colors[3]) +\n  geom_point(aes(x = fixef(gaussian_model)[4, 1], y = 0), colour = \"black\", size = 3) +\n  geom_segment(aes(x = fixef(gaussian_model)[4, 3], y = 0, xend = fixef(gaussian_model)[4, 4], yend = 0), size = 1, color = \"black\") +\n  ggtitle(\"Main Effect: Cue Type\") +\n  labs(x = \"Object-Cue - Category-Cue\",y = \"\") +\n  theme(axis.title = element_text(size = 9, face = \"bold\"),\n        plot.title = element_text(size = 11))\n\n# arrange graphs beside one another\nggarrange(modality_main_graph, congruency_main_graph, cuetype_main_graph, ncol = 3)\n\n\n\n\n\n\n\n\nFirst, visual trials are 1176ms faster than olfactory trials. Because olfactory trials are the intercept (1764ms), visual trials are estimated to be approximately 588ms. This is a very big difference, but not surprising as it takes longer to process an odor compared to a visual stimulus. Next, incongruent trials are 109ms slower than congruent trials. So people tend to respond more slowly when the auditory cue and target do not match. Finally, people are 118ms faster at responding to targets when the cue is object-based rather than category-based.\nCentral to our main hypothesis, we were interested in whether the congruency effect (people responding slower when the cue and target did not match) was larger for olfactory target trials compared to visual target trials.\n\n# graph of modality x congruency posterior\ncongruency_modality_graph &lt;- ggplot(draws_posterior, aes(x = `b_modalityvisual:congruencyincongruent`)) +\n  geom_histogram(binwidth = 0.75, position = \"identity\", color = colors[3], fill = colors[3]) +\n  geom_point(aes(x = fixef(gaussian_model)[5, 1], y = 0), colour = \"black\", size = 3) +\n  geom_segment(aes(x = fixef(gaussian_model)[5, 3], y = 0, xend = fixef(gaussian_model)[5, 4], yend = 0), size = 1, color = \"black\") +\n  ggtitle(\"Interaction: Modality x Congruency\") +\n  xlab(\"\") +\n  ylab(\"\") +\n  theme(axis.title = element_text(size = 9, face = \"bold\"),\n        plot.title = element_text(size = 11))\n\ncongruency_modality_cuetype_graph &lt;- ggplot(draws_posterior, aes(x = `b_modalityvisual:congruencyincongruent:cue_typeobject`)) +\n  geom_histogram(binwidth = 0.75, position = \"identity\", color = colors[3], fill = colors[3]) +\n  geom_point(aes(x = fixef(gaussian_model)[8, 1], y = 0), colour = \"black\", size = 3) +\n  geom_segment(aes(x = fixef(gaussian_model)[8, 3], y = 0, xend = fixef(gaussian_model)[8, 4], yend = 0), size = 1, color = \"black\") +\n  ggtitle(\"Interaction: Modality x Congruency x Cue-Type\") +\n  xlab(\"\") +\n  ylab(\"\") +\n  theme(axis.title = element_text(size = 9, face = \"bold\"),\n        plot.title = element_text(size = 11))\n\n# arrange graphs beside one another\nggarrange(congruency_modality_graph, congruency_modality_cuetype_graph, ncol = 2)\n\n\n\n\n\n\n\n\nThis can be interpreted like this: people respond more slowly to incongruent cue target presentations, but this difference is greater when the target is olfactory compared to when it is visual. We could also say they are 53ms slower at responding to incongruent olfactory targets compared to incongruent visual targets. In addition, the 95% credible intervals do not overlap with zero (-92.02, -15.15). All of the 95% most probable reaction times for this interaction are negative, so I think we can say this difference is likely negative too. For comparison, this interaction was statistically significant in the original paper (p = 0.02). I actually think a p-value that close to the threshold is not amazingly convincing, so it kind of matches the interpretation of the credible interval here. The plot on the right represents the 3-way interaction. This lets us see whether the disparity in congruent and incongruent reaction times, which is larger in olfaction, occurs when object-cues preceed the olfactory target. The model suggests this is not the case.\nThere are other interactions as well, but they were not central to our main hypotheses so I won’t go into them here. In addition, I’m not a fan of 3-way interactions as they are hard to interpret and usually very underpowered to detect, so I don’t see much value in looking at the 3-way interaction here."
  },
  {
    "objectID": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#modality-random-effects",
    "href": "content/projects/1-jneuro-behavioural/1-jneuro-behavioural.html#modality-random-effects",
    "title": "Journal Of Neuroscience: Bayesian Reanalysis",
    "section": "Modality random effects",
    "text": "Modality random effects\nBelow is some pre-processing for displaying main random-effects estimates.\n\n# temporary dataframe to be filled in loop\ntemp_df &lt;- data.frame(\"participant\" = factor(),\n                      \"empirical_olfactory_rt\" = numeric(),\n                      \"estimated_olfactory_rt\" = numeric(),\n                      \"empicial_visual_rt\" = numeric(),\n                      \"estimated_visual_rt\" = numeric())\n# for each unique participant:\nfor (i in unique(df$participant)) { \n  # ith participants' reaction time random effect for olfaction\n  olfaction_rt_i &lt;- fixef(gaussian_model)[1]  + ranef(gaussian_model)$participant[i, 1, 1] + ranef(gaussian_model)$participant[i, 1, 2] + ranef(gaussian_model)$participant[i, 1, 3] + ranef(gaussian_model)$participant[i, 1, 4]\n  # ith participants' reaction time random effect for vision\n  visual_rt_i &lt;- fixef(gaussian_model)[1] + (fixef(gaussian_model)[2]) + ranef(gaussian_model)$participant[i, 1, 1] + ranef(gaussian_model)$participant[i, 1, 2] + ranef(gaussian_model)$participant[i, 1, 3] + ranef(gaussian_model)$participant[i, 1, 4]\n  # dataframe of fixed and random modality effect estimates for ith person\n  participant_df &lt;- data.frame(\"participant\" = i,\n                      \"empirical_olfactory_rt\" = fixef(gaussian_model)[1],\n                      \"estimated_olfactory_rt\" = olfaction_rt_i,\n                      \"empicial_visual_rt\" = fixef(gaussian_model)[1] + (fixef(gaussian_model)[2]),\n                      \"estimated_visual_rt\" = fixef(gaussian_model)[1] + (fixef(gaussian_model)[2]) + ranef(gaussian_model)$participant[i, 1, 1] + ranef(gaussian_model)$participant[i, 1, 2] + ranef(gaussian_model)$participant[i, 1, 3] + ranef(gaussian_model)$participant[i, 1, 4])\n  # here all participant fixed and random modality effect estimates are combined in a single dataframe\n  temp_df &lt;- rbind(temp_df, participant_df)\n}\n\n\n# reshape from wide to long\nmodality_df &lt;- temp_df %&gt;% pivot_longer(cols = c('empirical_olfactory_rt', 'estimated_olfactory_rt', 'empicial_visual_rt', 'estimated_visual_rt'),\n                    names_to = 'coefficient',\n                    values_to = 'rt')\n# create new column\nmodality_df$group &lt;- factor(ifelse(modality_df$coefficient == \"empirical_olfactory_rt\", \"empirical\",\n                            ifelse(modality_df$coefficient == \"empicial_visual_rt\", \"empirical\", \"estimated\")))\n# create new column\nmodality_df$group2 &lt;- factor(ifelse(modality_df$coefficient == \"empirical_olfactory_rt\", \"olfactory\",\n                            ifelse(modality_df$coefficient == \"estimated_olfactory_rt\", \"olfactory\", \"visual\")))\n# rename columns\ncolnames(modality_df) &lt;- c(\"participant\", \"coefficient\", \"rt\", \"estimate\", \"modality\")\n\nmodality_df_estimates &lt;- modality_df[modality_df$estimate == \"estimated\", ]\nmodality_df_estimates &lt;- aggregate(modality_df$rt, list(modality_df$participant, modality_df$modality), mean)\ncolnames(modality_df_estimates) &lt;- c(\"participant\", \"modality\", \"rt\")\n\n# Calculate mean rt for each modality\nmean_values &lt;- modality_df_estimates %&gt;%\n  group_by(modality) %&gt;%\n  summarize(mean_rt = mean(rt))\n\nmean_values &lt;- data.frame(\"participant\" = c(101, 101),\n                          \"modality\" = c(\"olfactory\", \"visual\"),\n                          \"rt\" = c(1837, 612))\nmean_values$participant &lt;- as.factor(mean_values$participant)\nmean_values$modality &lt;- as.factor(mean_values$modality)\n\n\n# graph random effects for modality\nggplot(modality_df_estimates, aes(x = modality, y = rt, group = participant)) +\n  geom_point(color = \"grey\") +\n  geom_line(color = \"grey\")  +\n  geom_point(data = mean_values, aes(x = modality, y = rt), color = \"black\", size = 3) +\n  geom_line(data = mean_values, aes(x = modality, y = rt, group = 1), color = \"black\", size = 1.5) +\n  ggtitle(\"Modality Random Effects\")\n\n\n\n\n\n\n\n\nAn alternate way to view this is to put each participants’ random effect estimate on a plot with the fixed effect estimate, and plot each of these on individual panels. Maybe not as intuitive as the previous plot, but it still makes sense to look at it like this.\n\n# empty list where each runner's graph will be saved.\ntemp_list &lt;- list()  \n# loop through runners, grab their specific intercepts/slope from previous dataframe, and save graph to list\nfor (i in unique(modality_df$participant)) {\n  # runner-specific graph\n  temp_graph &lt;- ggplot(modality_df[modality_df$participant == i, ], aes(x = modality, y = rt, color = estimate, group = estimate)) +\n  geom_point() +\n  geom_line() +\n    ylim(0, 2800) +\n    ggtitle(paste0(\"Subject \", i)) +\n    theme(legend.position = \"none\")\n  # save ith runner graph to temp_list\n  temp_list[[i]] &lt;- temp_graph\n}\n\narg_list &lt;- c(temp_list, list(nrow = 13, ncol = 5))\n# Use do.call to pass all elements of graph_list to ggarrange\narranged_plots &lt;- do.call(\"ggarrange\", arg_list)\n# Print or display the arranged plots\nprint(arranged_plots)"
  },
  {
    "objectID": "content/about.html",
    "href": "content/about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "content/posts/1-eyeball-test/1-eyeball-test.html",
    "href": "content/posts/1-eyeball-test/1-eyeball-test.html",
    "title": "Why You Should Pre-specify Exploratory Analyses",
    "section": "",
    "text": "# load libraries\nlibrary(tidyverse)\nlibrary(tidyr)\nlibrary(lsr)\nlibrary(ggpubr)"
  },
  {
    "objectID": "content/posts/1-eyeball-test/1-eyeball-test.html#how-does-a-simulation-work",
    "href": "content/posts/1-eyeball-test/1-eyeball-test.html#how-does-a-simulation-work",
    "title": "Why You Should Pre-specify Exploratory Analyses",
    "section": "How Does a Simulation Work?",
    "text": "How Does a Simulation Work?\nThis simulation will assume the null hypthesis is true. Therefore, there won’t be any difference between the groups at the population level. There may, however, be difference at the sample level. In fact, there almost always will be. Because I prefer linear regression, I will simulate data from a linear model:\n\\(Y_{i} \\mid \\beta_{0}, \\beta_{1}, \\sigma \\sim N (\\mu_{i}, \\sigma^{2})\\) with \\(\\mu_{i} = \\beta_{0} + \\beta_{1}X_{i}\\)\nHowever, because the slope will always be cancelled out by zero, this model can be simplified to this:\n\\(Y_{i} \\mid \\beta_{0}, \\sigma \\sim N (\\mu_{i}, \\sigma^{2})\\) with \\(\\mu_{i} = \\beta_{0}\\)\nFirst, I make an indicator for the independent variable. One group will have a zero, and the other a one. This also means the sample size is going to be n = 100.\n\nx &lt;- rep(c(0, 1), each = 50)\nx\n\n  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nTo make the dependent variable, one would need to add and multiply the model coefficients with the independent variable(s). That is what I will do here. No measurement is perfect though, so every sample will be measured with some error. I am simulating this error with the rnorm() function. Because there is no difference at the population level between the two groups, both groups are sampled from a normal distribution with a mean of 350 and a standard deviation of 30. To calculate the difference between groups, one would add a slope to the intercept. Here, the slope is zero and cancels out the influence of the independent variable.\n\nset.seed(1234)\ny &lt;- rnorm(100, mean = 350, sd = 30) + 0*x\ny\n\n  [1] 313.7880 358.3229 382.5332 279.6291 362.8737 365.1817 332.7578 333.6010\n  [9] 333.0664 323.2989 335.6842 320.0484 326.7124 351.9338 378.7848 346.6914\n [17] 334.6697 322.6641 324.8848 422.4751 354.0226 335.2794 336.7836 363.7877\n [25] 329.1884 306.5539 367.2427 319.2903 349.5459 321.9215 383.0689 335.7322\n [33] 328.7168 334.9623 301.1272 314.9714 284.5988 309.7702 341.1712 336.0231\n [41] 393.4849 317.9407 324.3391 341.5813 320.1698 320.9446 316.7805 312.4404\n [49] 334.2852 335.0945 295.8191 332.5377 316.7333 319.5511 345.1307 366.8917\n [57] 399.4345 326.7994 398.1773 315.2657 369.6977 426.4697 348.9572 329.9110\n [65] 349.7719 403.3125 315.8418 391.0348 389.8869 360.0942 350.2068 336.3359\n [73] 339.0043 369.4486 412.1081 345.3980 308.2790 328.2925 357.7479 340.4882\n [81] 344.6663 344.9002 308.8309 344.7864 375.5070 370.9283 366.4999 337.9180\n [89] 344.2522 314.1642 348.4052 357.6559 401.1789 380.0454 335.1325 360.6665\n [97] 315.9618 376.3461 379.1875 413.6335\n\n\nNow the data can be put in a dataframe\n\nsim_df &lt;- data.frame(x, y)\nhead(sim_df)\n\n  x        y\n1 0 313.7880\n2 0 358.3229\n3 0 382.5332\n4 0 279.6291\n5 0 362.8737\n6 0 365.1817\n\n\nFinally, a linear regression can be performed on the sample. Remember, their is no difference between the two groups at the pupulation level, but there almost certainlt will be differences at the sample level (due to sampling error).\n\nmodel &lt;-  lm(y ~ x, data = sim_df)\nsummary(model)\n\n\nCall:\nlm(formula = y ~ x, data = sim_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-58.367 -17.301  -3.815  15.830  86.067 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  336.408      4.090  82.242  &lt; 2e-16 ***\nx             17.777      5.785   3.073  0.00274 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 28.92 on 98 degrees of freedom\nMultiple R-squared:  0.0879,    Adjusted R-squared:  0.07859 \nF-statistic: 9.444 on 1 and 98 DF,  p-value: 0.002743\n\n\nAbove I can see the slope coefficient (x) is actually statistically significant. This is likely due to the dact that the Intercept estimate is so low. Both groups were sampled from the same distribution centered at 350. THe Intercept is 336, and the slope is 18. This means the mean of the second group is 336 + 18 = 354. In frequentist statistics, probabilities are conceptualized in reference to long-term frequencies. For instance, we know a fair coin has a 50% probability of coming up heads because if we flipped that coin a theoretically infinite number of times, approximately 50% of those flips would land heads. P-values can be thought of the same way: If you were to run the same experiment an infinite number of times, fixing the sample size and collecting a new sample with each experiment, how many p-values would be below your threshold (in most cases in science, the threshold is 0.05)? When the null hypothesis is true, only 5% of experiments will yield a p-value below 0.05."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "",
    "text": "Is increased COVID-19 threat over time associated with increased altruism?"
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#data-collection",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#data-collection",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Data Collection",
    "text": "Data Collection\nData for this analysis came from a study conducted online between March 24th and April 14th of 2020. Each week, 150 different people from the United States were surveyed about a range of self-reported behaviours and psychological states. Therefore, a total of 600 people were included in the study, collected over 4 data acquisition periods. For the purposes of this analysis, only the measurements directly associated with the Bayesian model will be discussed. The dependent measure for this study was each participants’ self-reported altruism (SRA) score. The main predictors we collected and had hypotheses related to were: COVID-19 Risk Perception (RP), Percieved Stress Score (PSS), Anxiety, and Depression. We also collected each participants’ age, gender, employment status, and financial situation. These latter 4 predictors had no prior hypothesis tied to them, but we thought each could contribute to predicting SRA. Later, each predictor will be very briefly described as it relates to the hypothesis."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#covid-19-data-aquisition",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#covid-19-data-aquisition",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "COVID-19 Data Aquisition",
    "text": "COVID-19 Data Aquisition\nTo get a sense of where the United States was in terms of overall COVID-19 cases during our data acquisition period, I obtained COVID-19 related data from github for those 4 weeks. I then created a dataframe that contains only the weeks for which the data for the experiment took place. The code chunk below puts this dataframe together.\n\n# Load libraries\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(gghighlight)\nlibrary(plyr)\nlibrary(readr)\nlibrary(plotly)\nlibrary(ggpubr)\nlibrary(dplyr)\nlibrary(bayesplot)\nlibrary(rethinking)\nlibrary(ggmcmc)\nlibrary(brms)\nlibrary(broom)\nlibrary(ggrepel)\n\n# Here, we load .csv files from github. These are updated daily, so everytime this analysis is run, it uses the\n# most up to date information.\n\n# Total Global Cases Data\nCOVID_US_Wide&lt;-read_csv(url(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\"))\n\n# Total Global Deaths Data\nCOVID_US_Deaths_Wide &lt;-read_csv(url(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv\"))\n\n\n# Total global cases data in long format.\nCOVID_US_Long_Date &lt;- gather(COVID_US_Wide, date, cases, 12:ncol(COVID_US_Wide), factor_key=TRUE)\n\n# Total global deaths data in long format\nCOVID_US_Deaths_Long_Date &lt;- gather(COVID_US_Deaths_Wide, date, cases, 13:ncol(COVID_US_Deaths_Wide),\n                                    factor_key=TRUE)\n\n\n# Filter States as the  cases dataset also includes groups (American Samoa) and boats (Diamond Cruise ship).\nCovid_US_Filter &lt;- COVID_US_Long_Date %&gt;% dplyr::filter(\n  `Province_State` %in% c(\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\",\n                          \"Colorado\", \"Connecticut\", \"Delaware\", \"District of Columbia\", \"Florida\", \"Georgia\",\n                          \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\",\n                          \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\",\n                          \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\",\n                          \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\",\n                          \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\",\n                          \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\",\n                          \"West Virginia\", \"Wisconsin\", \"Wyoming\"))\n\n# Filter data to only include dates starting from March 1st.\nCovid_US_Filter &lt;- Covid_US_Filter[126558:nrow(Covid_US_Filter), ]\n\n# Further reduce columns to only include states, dates, and cases.\nCovid_US_Filter &lt;- ddply(Covid_US_Filter, c(\"`Province_State`\", \"date\"), summarise,\n                            cases = sum(cases))\n\n# Filter States as the deaths dataset also includes groups (American Samoa) and boats (Diamond Cruise ship).\nCovid_US_Deaths_Filter &lt;- COVID_US_Deaths_Long_Date %&gt;% dplyr::filter(\n  `Province_State` %in% c(\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\",\n                          \"Connecticut\", \"Delaware\", \"District of Columbia\", \"Florida\", \"Georgia\", \"Hawaii\",\n                          \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\",\n                          \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\",\n                          \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\",\n                          \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\",\n                          \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\",\n                          \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\",\n                          \"Wisconsin\", \"Wyoming\"))\n\n# Filter States as the dataset also includes groups (American Samoa) and boats (Diamond Cruise ship).\nCovid_US_Deaths_Filter &lt;- Covid_US_Deaths_Filter[126558:nrow(Covid_US_Deaths_Filter), ]\n\n# Filter States as the dataset also includes groups (American Samoa) and boats (Diamond Cruise ship).\nCovid_US_Deaths_Filter &lt;- ddply(Covid_US_Deaths_Filter, c(\"`Province_State`\", \"date\"), summarise,\n                            deaths = sum(cases))\n\n# Bind cases and deaths dataframes.\nCovid_Cases_Deaths &lt;- cbind(Covid_US_Filter, Covid_US_Deaths_Filter)\n\n# Change column names.\ncolnames(Covid_Cases_Deaths) &lt;- c(\"State\", \"Date\", \"Total_State_Cases\", \"Null1\", \"Null2\", \"Total_State_Deaths\")\n\n# Subset combined dataframe to reduce redundant features.\nCovid_Cases_Deaths &lt;- subset(Covid_Cases_Deaths, select = c(\"State\", \"Date\", \"Total_State_Cases\", \"Total_State_Deaths\"))\n\n# Create column indicating each week of Joana's data collection.\nCovid_Cases_Deaths$Week &lt;- ifelse(Covid_Cases_Deaths$Date == \"3/23/20\", \"Week 1\", \n                                  ifelse(Covid_Cases_Deaths$Date == \"3/30/20\", \"Week 2\",\n                                  ifelse(Covid_Cases_Deaths$Date == \"4/6/20\", \"Week 3\",\n                                  ifelse( Covid_Cases_Deaths$Date == \"4/13/20\", \"Week 4\", \"NA\"))))\n\n# Remove certain rows so the dataset only contains days from the weeks Joana collected data.\nCovid_Cases_Deaths &lt;- Covid_Cases_Deaths[!(Covid_Cases_Deaths$Week==\"NA\"), ]\n\n# New dataframe, summarising cases by week of data collection.\nCovid_Cases &lt;- ddply(Covid_Cases_Deaths, c(\"State\", \"Week\"), summarise,\n               N    = length(Total_State_Cases),\n               Total_State_Cases = sum(Total_State_Cases))\n\n# New dataframe, summarising deaths by week of data collection.\nCovid_Deaths &lt;- ddply(Covid_Cases_Deaths, c(\"State\", \"Week\"), summarise,\n               N    = length(Total_State_Deaths),\n               Total_State_Deaths = sum(Total_State_Deaths))\n\n# Dataframe combining summarised cases and deaths dataframes.\nTotal_Cases_And_Deaths &lt;- cbind(Covid_Cases, Covid_Deaths)\n\n# Change column names.\ncolnames(Total_Cases_And_Deaths) &lt;- c(\"State\", \"Week\", \"N\", \"Total_State_Cases\", \"Null1\", \"Mull2\", \"Null3\", \"Total_State_Deaths\")\n\n# Filter out redundant columns.\nTotal_Cases_And_Deaths &lt;- subset(Total_Cases_And_Deaths, select = c(\"State\", \"Week\", \"N\", \"Total_State_Cases\", \"Total_State_Deaths\"))\n\nTotal_Cases_And_Deaths$Total_US_Cases &lt;- ifelse(Total_Cases_And_Deaths$Week == \"Week 1\", sum(Total_Cases_And_Deaths$Total_State_Cases[Total_Cases_And_Deaths$Week == \"Week 1\"]),\n                                         ifelse(Total_Cases_And_Deaths$Week == \"Week 2\", sum(Total_Cases_And_Deaths$Total_State_Cases[Total_Cases_And_Deaths$Week == \"Week 2\"]),\n                                         ifelse(Total_Cases_And_Deaths$Week == \"Week 3\", sum(Total_Cases_And_Deaths$Total_State_Cases[Total_Cases_And_Deaths$Week == \"Week 3\"]),\n                                         ifelse(Total_Cases_And_Deaths$Week == \"Week 4\", sum(Total_Cases_And_Deaths$Total_State_Cases[Total_Cases_And_Deaths$Week == \"Week 4\"]), \"None\"))))\n\n# Total\nTotal_Cases_And_Deaths$Total_US_Cases &lt;- as.double(Total_Cases_And_Deaths$Total_US_Cases)\n\n\n\nTotal_Cases_And_Deaths$Total_US_Deaths &lt;- ifelse(Total_Cases_And_Deaths$Week == \"Week 1\",     sum(Total_Cases_And_Deaths$Total_State_Deaths[Total_Cases_And_Deaths$Week == \"Week 1\"]),\n                                         ifelse(Total_Cases_And_Deaths$Week == \"Week 2\", sum(Total_Cases_And_Deaths$Total_State_Deaths[Total_Cases_And_Deaths$Week == \"Week 2\"]),\n                                         ifelse(Total_Cases_And_Deaths$Week == \"Week 3\", sum(Total_Cases_And_Deaths$Total_State_Deaths[Total_Cases_And_Deaths$Week == \"Week 3\"]),\n                                         ifelse(Total_Cases_And_Deaths$Week == \"Week 4\", sum(Total_Cases_And_Deaths$Total_State_Deaths[Total_Cases_And_Deaths$Week == \"Week 4\"]), \"None\"))))\n\n# Total\nTotal_Cases_And_Deaths$Total_US_Deaths &lt;- as.double(Total_Cases_And_Deaths$Total_US_Deaths)\n\n# Add state abbreviations.\nTotal_Cases_And_Deaths$State_Abb &lt;- case_when(\nTotal_Cases_And_Deaths$State == \"Alabama\" ~ \"AL\",\nTotal_Cases_And_Deaths$State == \"Alaska\" ~ \"AK\",\nTotal_Cases_And_Deaths$State == \"Arizona\" ~ \"AZ\",\nTotal_Cases_And_Deaths$State == \"Arkansas\" ~ \"AR\",\nTotal_Cases_And_Deaths$State == \"California\" ~ \"CA\",\nTotal_Cases_And_Deaths$State == \"Colorado\" ~ \"CO\",\nTotal_Cases_And_Deaths$State == \"Connecticut\" ~ \"CT\",\nTotal_Cases_And_Deaths$State == \"Delaware\" ~ \"DE\",\nTotal_Cases_And_Deaths$State == \"District of Columbia\" ~ \"DC\",      \nTotal_Cases_And_Deaths$State == \"Florida\" ~ \"FL\",\nTotal_Cases_And_Deaths$State == \"Georgia\" ~ \"GA\",\nTotal_Cases_And_Deaths$State == \"Hawaii\" ~ \"HI\",\nTotal_Cases_And_Deaths$State == \"Idaho\" ~ \"ID\",\nTotal_Cases_And_Deaths$State == \"Illinois\" ~ \"IL\",\nTotal_Cases_And_Deaths$State == \"Indiana\" ~ \"IN\",\nTotal_Cases_And_Deaths$State == \"Iowa\" ~ \"IA\",\nTotal_Cases_And_Deaths$State == \"Kansas\" ~ \"KA\",\nTotal_Cases_And_Deaths$State == \"Kentucky\" ~ \"KY\",\nTotal_Cases_And_Deaths$State == \"Louisiana\" ~ \"LA\",\nTotal_Cases_And_Deaths$State == \"Maine\" ~ \"ME\",\nTotal_Cases_And_Deaths$State == \"Maryland\" ~ \"MD\",\nTotal_Cases_And_Deaths$State == \"Massachusetts\" ~ \"MA\",\nTotal_Cases_And_Deaths$State == \"Michigan\" ~ \"MI\",\nTotal_Cases_And_Deaths$State == \"Minnesota\" ~ \"MN\",\nTotal_Cases_And_Deaths$State == \"Mississippi\" ~ \"MS\",\nTotal_Cases_And_Deaths$State == \"Missouri\" ~ \"MO\",\nTotal_Cases_And_Deaths$State == \"Montana\" ~ \"MT\",\nTotal_Cases_And_Deaths$State == \"Nebraska\" ~ \"NE\",\nTotal_Cases_And_Deaths$State == \"Nevada\" ~ \"NV\",\nTotal_Cases_And_Deaths$State == \"New Hampshire\" ~ \"NH\",\nTotal_Cases_And_Deaths$State == \"New Jersey\" ~ \"NJ\",\nTotal_Cases_And_Deaths$State == \"New Mexico\" ~ \"NM\",\nTotal_Cases_And_Deaths$State == \"New York\" ~ \"NY\",\nTotal_Cases_And_Deaths$State == \"North Carolina\" ~ \"NC\",\nTotal_Cases_And_Deaths$State == \"North Dakota\" ~ \"ND\",\nTotal_Cases_And_Deaths$State == \"Ohio\" ~ \"OH\",\nTotal_Cases_And_Deaths$State == \"Oklahoma\" ~ \"OK\",\nTotal_Cases_And_Deaths$State == \"Oregon\" ~ \"OR\",\nTotal_Cases_And_Deaths$State == \"Pennsylvania\" ~ \"PA\",\nTotal_Cases_And_Deaths$State == \"Rhode Island\" ~ \"RI\",\nTotal_Cases_And_Deaths$State == \"South Carolina\" ~ \"SC\",\nTotal_Cases_And_Deaths$State == \"South Dakota\" ~ \"SD\",\nTotal_Cases_And_Deaths$State == \"Tennessee\" ~ \"TN\",\nTotal_Cases_And_Deaths$State == \"Texas\" ~ \"TX\",\nTotal_Cases_And_Deaths$State == \"Utah\" ~ \"UT\",\nTotal_Cases_And_Deaths$State == \"Vermont\" ~ \"VT\",\nTotal_Cases_And_Deaths$State == \"Virginia\" ~ \"VA\",\nTotal_Cases_And_Deaths$State == \"Washington\" ~ \"WA\",\nTotal_Cases_And_Deaths$State == \"West Virginia\" ~ \"WV\",\nTotal_Cases_And_Deaths$State == \"Wisconsin\" ~ \"WI\",\nTotal_Cases_And_Deaths$State == \"Wyoming\" ~ \"WY\",\n    TRUE ~ as.character(Total_Cases_And_Deaths$State)\n)\n\n# Add column with per capity cases (per 10,000 citizens).\nTotal_Cases_And_Deaths$Cases_Per_10000 &lt;- case_when(\nTotal_Cases_And_Deaths$State == \"Alabama\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/4908621) * 10000,\nTotal_Cases_And_Deaths$State == \"Alaska\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/734002) * 10000,\nTotal_Cases_And_Deaths$State == \"Arizona\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/7378494) * 10000,\nTotal_Cases_And_Deaths$State == \"Arkansas\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/3038999) * 10000,\nTotal_Cases_And_Deaths$State == \"California\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/39937489) * 10000,\nTotal_Cases_And_Deaths$State == \"Colorado\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/5845526) * 10000,\nTotal_Cases_And_Deaths$State == \"Connecticut\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/3563077) * 10000,\nTotal_Cases_And_Deaths$State == \"Delaware\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/982895) * 10000,\nTotal_Cases_And_Deaths$State == \"District of Columbia\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/    720687) * 10000,\nTotal_Cases_And_Deaths$State == \"Florida\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/21992985) * 10000,\nTotal_Cases_And_Deaths$State == \"Georgia\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/10736059) * 10000,\nTotal_Cases_And_Deaths$State == \"Hawaii\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1412687) * 10000,\nTotal_Cases_And_Deaths$State == \"Idaho\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1826156) * 10000,\nTotal_Cases_And_Deaths$State == \"Illinois\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/12659682) * 10000,\nTotal_Cases_And_Deaths$State == \"Indiana\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/6745354) * 10000,\nTotal_Cases_And_Deaths$State == \"Iowa\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/3179849) * 10000,\nTotal_Cases_And_Deaths$State == \"Kansas\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/2910357) * 10000,\nTotal_Cases_And_Deaths$State == \"Kentucky\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/4499692) * 10000,\nTotal_Cases_And_Deaths$State == \"Louisiana\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/4645184) * 10000,\nTotal_Cases_And_Deaths$State == \"Maine\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1345790) * 10000,\nTotal_Cases_And_Deaths$State == \"Maryland\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/6083116) * 10000,\nTotal_Cases_And_Deaths$State == \"Massachusetts\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/6976597) * 10000,\nTotal_Cases_And_Deaths$State == \"Michigan\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/10045029) * 10000,\nTotal_Cases_And_Deaths$State == \"Minnesota\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/5700671) * 10000,\nTotal_Cases_And_Deaths$State == \"Mississippi\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/2989260) * 10000,\nTotal_Cases_And_Deaths$State == \"Missouri\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/6169270) * 10000,\nTotal_Cases_And_Deaths$State == \"Montana\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1086759) * 10000,\nTotal_Cases_And_Deaths$State == \"Nebraska\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1952570) * 10000,\nTotal_Cases_And_Deaths$State == \"Nevada\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/3139658) * 10000,\nTotal_Cases_And_Deaths$State == \"New Hampshire\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1371246) * 10000,\nTotal_Cases_And_Deaths$State == \"New Jersey\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/8936574) * 10000,\nTotal_Cases_And_Deaths$State == \"New Mexico\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/2096640) * 10000,\nTotal_Cases_And_Deaths$State == \"New York\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/19440469) * 10000,\nTotal_Cases_And_Deaths$State == \"North Carolina\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/10611862) * 10000,\nTotal_Cases_And_Deaths$State == \"North Dakota\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/761723) * 10000,\nTotal_Cases_And_Deaths$State == \"Ohio\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/11747694) * 10000,\nTotal_Cases_And_Deaths$State == \"Oklahoma\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/3954821) * 10000,\nTotal_Cases_And_Deaths$State == \"Oregon\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/4301089) * 10000,\nTotal_Cases_And_Deaths$State == \"Pennsylvania\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/12820878) * 10000,\nTotal_Cases_And_Deaths$State == \"Rhode Island\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1056161) * 10000,\nTotal_Cases_And_Deaths$State == \"South Carolina\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/5210095) * 10000,\nTotal_Cases_And_Deaths$State == \"South Dakota\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/903027) * 10000,\nTotal_Cases_And_Deaths$State == \"Tennessee\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/6897576) * 10000,\nTotal_Cases_And_Deaths$State == \"Texas\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/29472295) * 10000,\nTotal_Cases_And_Deaths$State == \"Utah\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/3282115) * 10000,\nTotal_Cases_And_Deaths$State == \"Vermont\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/628061) * 10000,\nTotal_Cases_And_Deaths$State == \"Virginia\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/8626207) * 10000,\nTotal_Cases_And_Deaths$State == \"Washington\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/7797095) * 10000,\nTotal_Cases_And_Deaths$State == \"West Virginia\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1778070) * 10000,\nTotal_Cases_And_Deaths$State == \"Wisconsin\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/5851754) * 10000,\nTotal_Cases_And_Deaths$State == \"Wyoming\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/567025) * 10000,\n    TRUE ~ as.double(Total_Cases_And_Deaths$State))\n\n# Add column with per capity cases (per 100,000 citizens).\nTotal_Cases_And_Deaths$Cases_Per_100000 &lt;- case_when(\nTotal_Cases_And_Deaths$State == \"Alabama\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/4908621) * 100000,\nTotal_Cases_And_Deaths$State == \"Alaska\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/734002) * 100000,\nTotal_Cases_And_Deaths$State == \"Arizona\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/7378494) * 100000,\nTotal_Cases_And_Deaths$State == \"Arkansas\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/3038999) * 100000,\nTotal_Cases_And_Deaths$State == \"California\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/39937489) * 100000,\nTotal_Cases_And_Deaths$State == \"Colorado\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/5845526) * 100000,\nTotal_Cases_And_Deaths$State == \"Connecticut\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/3563077) * 100000,\nTotal_Cases_And_Deaths$State == \"Delaware\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/982895) * 100000,\nTotal_Cases_And_Deaths$State == \"District of Columbia\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/    720687) * 100000,\nTotal_Cases_And_Deaths$State == \"Florida\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/21992985) * 100000,\nTotal_Cases_And_Deaths$State == \"Georgia\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/10736059) * 100000,\nTotal_Cases_And_Deaths$State == \"Hawaii\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1412687) * 100000,\nTotal_Cases_And_Deaths$State == \"Idaho\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1826156) * 100000,\nTotal_Cases_And_Deaths$State == \"Illinois\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/12659682) * 100000,\nTotal_Cases_And_Deaths$State == \"Indiana\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/6745354) * 100000,\nTotal_Cases_And_Deaths$State == \"Iowa\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/3179849) * 100000,\nTotal_Cases_And_Deaths$State == \"Kansas\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/2910357) * 100000,\nTotal_Cases_And_Deaths$State == \"Kentucky\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/4499692) * 100000,\nTotal_Cases_And_Deaths$State == \"Louisiana\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/4645184) * 100000,\nTotal_Cases_And_Deaths$State == \"Maine\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1345790) * 100000,\nTotal_Cases_And_Deaths$State == \"Maryland\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/6083116) * 100000,\nTotal_Cases_And_Deaths$State == \"Massachusetts\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/6976597) * 100000,\nTotal_Cases_And_Deaths$State == \"Michigan\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/10045029) * 100000,\nTotal_Cases_And_Deaths$State == \"Minnesota\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/5700671) * 100000,\nTotal_Cases_And_Deaths$State == \"Mississippi\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/2989260) * 100000,\nTotal_Cases_And_Deaths$State == \"Missouri\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/6169270) * 100000,\nTotal_Cases_And_Deaths$State == \"Montana\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1086759) * 100000,\nTotal_Cases_And_Deaths$State == \"Nebraska\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1952570) * 100000,\nTotal_Cases_And_Deaths$State == \"Nevada\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/3139658) * 100000,\nTotal_Cases_And_Deaths$State == \"New Hampshire\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1371246) * 100000,\nTotal_Cases_And_Deaths$State == \"New Jersey\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/8936574) * 100000,\nTotal_Cases_And_Deaths$State == \"New Mexico\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/2096640) * 100000,\nTotal_Cases_And_Deaths$State == \"New York\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/19440469) * 100000,\nTotal_Cases_And_Deaths$State == \"North Carolina\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/10611862) * 100000,\nTotal_Cases_And_Deaths$State == \"North Dakota\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/761723) * 100000,\nTotal_Cases_And_Deaths$State == \"Ohio\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/11747694) * 100000,\nTotal_Cases_And_Deaths$State == \"Oklahoma\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/3954821) * 100000,\nTotal_Cases_And_Deaths$State == \"Oregon\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/4301089) * 100000,\nTotal_Cases_And_Deaths$State == \"Pennsylvania\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/12820878) * 100000,\nTotal_Cases_And_Deaths$State == \"Rhode Island\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1056161) * 100000,\nTotal_Cases_And_Deaths$State == \"South Carolina\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/5210095) * 100000,\nTotal_Cases_And_Deaths$State == \"South Dakota\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/903027) * 100000,\nTotal_Cases_And_Deaths$State == \"Tennessee\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/6897576) * 100000,\nTotal_Cases_And_Deaths$State == \"Texas\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/29472295) * 100000,\nTotal_Cases_And_Deaths$State == \"Utah\" ~ \n  (Total_Cases_And_Deaths$Total_State_Cases/3282115) * 100000,\nTotal_Cases_And_Deaths$State == \"Vermont\" ~ \n  (Total_Cases_And_Deaths$Total_State_Cases/628061) * 100000,\nTotal_Cases_And_Deaths$State == \"Virginia\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/8626207) * 100000,\nTotal_Cases_And_Deaths$State == \"Washington\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/7797095) * 100000,\nTotal_Cases_And_Deaths$State == \"West Virginia\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/1778070) * 100000,\nTotal_Cases_And_Deaths$State == \"Wisconsin\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/5851754) * 100000,\nTotal_Cases_And_Deaths$State == \"Wyoming\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/567025) * 100000,\n    TRUE ~ as.double(Total_Cases_And_Deaths$State))\n\n# Add column with per capity deaths (per 10,000 citizens).\nTotal_Cases_And_Deaths$Deaths_Per_10000 &lt;- case_when(\nTotal_Cases_And_Deaths$State == \"Alabama\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/4908621) * 10000,\nTotal_Cases_And_Deaths$State == \"Alaska\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/734002) * 10000,\nTotal_Cases_And_Deaths$State == \"Arizona\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/7378494) * 10000,\nTotal_Cases_And_Deaths$State == \"Arkansas\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/3038999) * 10000,\nTotal_Cases_And_Deaths$State == \"California\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/39937489) * 10000,\nTotal_Cases_And_Deaths$State == \"Colorado\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/5845526) * 10000,\nTotal_Cases_And_Deaths$State == \"Connecticut\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/3563077) * 10000,\nTotal_Cases_And_Deaths$State == \"Delaware\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/982895) * 10000,\nTotal_Cases_And_Deaths$State == \"District of Columbia\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/    720687) * 10000,\nTotal_Cases_And_Deaths$State == \"Florida\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/21992985) * 10000,\nTotal_Cases_And_Deaths$State == \"Georgia\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/10736059) * 10000,\nTotal_Cases_And_Deaths$State == \"Hawaii\" ~ \n  (Total_Cases_And_Deaths$Total_State_Deaths/1412687) * 10000,\nTotal_Cases_And_Deaths$State == \"Idaho\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/1826156) * 10000,\nTotal_Cases_And_Deaths$State == \"Illinois\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/12659682) * 10000,\nTotal_Cases_And_Deaths$State == \"Indiana\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/6745354) * 10000,\nTotal_Cases_And_Deaths$State == \"Iowa\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/3179849) * 10000,\nTotal_Cases_And_Deaths$State == \"Kansas\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/2910357) * 10000,\nTotal_Cases_And_Deaths$State == \"Kentucky\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/4499692) * 10000,\nTotal_Cases_And_Deaths$State == \"Louisiana\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/4645184) * 10000,\nTotal_Cases_And_Deaths$State == \"Maine\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/1345790) * 10000,\nTotal_Cases_And_Deaths$State == \"Maryland\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/6083116) * 10000,\nTotal_Cases_And_Deaths$State == \"Massachusetts\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/6976597) * 10000,\nTotal_Cases_And_Deaths$State == \"Michigan\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/10045029) * 10000,\nTotal_Cases_And_Deaths$State == \"Minnesota\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/5700671) * 10000,\nTotal_Cases_And_Deaths$State == \"Mississippi\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/2989260) * 10000,\nTotal_Cases_And_Deaths$State == \"Missouri\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/6169270) * 10000,\nTotal_Cases_And_Deaths$State == \"Montana\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/1086759) * 10000,\nTotal_Cases_And_Deaths$State == \"Nebraska\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/1952570) * 10000,\nTotal_Cases_And_Deaths$State == \"Nevada\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/3139658) * 10000,\nTotal_Cases_And_Deaths$State == \"New Hampshire\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/1371246) * 10000,\nTotal_Cases_And_Deaths$State == \"New Jersey\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/8936574) * 10000,\nTotal_Cases_And_Deaths$State == \"New Mexico\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/2096640) * 10000,\nTotal_Cases_And_Deaths$State == \"New York\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/19440469) * 10000,\nTotal_Cases_And_Deaths$State == \"North Carolina\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/10611862) * 10000,\nTotal_Cases_And_Deaths$State == \"North Dakota\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/761723) * 10000,\nTotal_Cases_And_Deaths$State == \"Ohio\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/11747694) * 10000,\nTotal_Cases_And_Deaths$State == \"Oklahoma\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/3954821) * 10000,\nTotal_Cases_And_Deaths$State == \"Oregon\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/4301089) * 10000,\nTotal_Cases_And_Deaths$State == \"Pennsylvania\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/12820878) * 10000,\nTotal_Cases_And_Deaths$State == \"Rhode Island\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/1056161) * 10000,\nTotal_Cases_And_Deaths$State == \"South Carolina\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/5210095) * 10000,\nTotal_Cases_And_Deaths$State == \"South Dakota\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/903027) * 10000,\nTotal_Cases_And_Deaths$State == \"Tennessee\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/6897576) * 10000,\nTotal_Cases_And_Deaths$State == \"Texas\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/29472295) * 10000,\nTotal_Cases_And_Deaths$State == \"Utah\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/3282115) * 10000,\nTotal_Cases_And_Deaths$State == \"Vermont\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/628061) * 10000,\nTotal_Cases_And_Deaths$State == \"Virginia\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/8626207) * 10000,\nTotal_Cases_And_Deaths$State == \"Washington\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/7797095) * 10000,\nTotal_Cases_And_Deaths$State == \"West Virginia\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/1778070) * 10000,\nTotal_Cases_And_Deaths$State == \"Wisconsin\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/5851754) * 10000,\nTotal_Cases_And_Deaths$State == \"Wyoming\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/567025) * 10000,\n    TRUE ~ as.double(Total_Cases_And_Deaths$State))\n\n# Add column with per capity deaths (per 100,000 citizens).\nTotal_Cases_And_Deaths$Deaths_Per_100000 &lt;- case_when(\nTotal_Cases_And_Deaths$State == \"Alabama\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/4908621) * 100000,\nTotal_Cases_And_Deaths$State == \"Alaska\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/734002) * 100000,\nTotal_Cases_And_Deaths$State == \"Arizona\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/7378494) * 100000,\nTotal_Cases_And_Deaths$State == \"Arkansas\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/3038999) * 100000,\nTotal_Cases_And_Deaths$State == \"California\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/39937489) * 100000,\nTotal_Cases_And_Deaths$State == \"Colorado\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/5845526) * 100000,\nTotal_Cases_And_Deaths$State == \"Connecticut\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/3563077) * 100000,\nTotal_Cases_And_Deaths$State == \"District of Columbia\" ~\n  (Total_Cases_And_Deaths$Total_State_Cases/    720687) * 100000,\nTotal_Cases_And_Deaths$State == \"Delaware\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/982895) * 100000,\nTotal_Cases_And_Deaths$State == \"Florida\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/21992985) * 100000,\nTotal_Cases_And_Deaths$State == \"Georgia\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/10736059) * 100000,\nTotal_Cases_And_Deaths$State == \"Hawaii\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/1412687) * 100000,\nTotal_Cases_And_Deaths$State == \"Idaho\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/1826156) * 100000,\nTotal_Cases_And_Deaths$State == \"Illinois\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/12659682) * 100000,\nTotal_Cases_And_Deaths$State == \"Indiana\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/6745354) * 100000,\nTotal_Cases_And_Deaths$State == \"Iowa\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/3179849) * 100000,\nTotal_Cases_And_Deaths$State == \"Kansas\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/2910357) * 100000,\nTotal_Cases_And_Deaths$State == \"Kentucky\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/4499692) * 100000,\nTotal_Cases_And_Deaths$State == \"Louisiana\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/4645184) * 100000,\nTotal_Cases_And_Deaths$State == \"Maine\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/1345790) * 100000,\nTotal_Cases_And_Deaths$State == \"Maryland\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/6083116) * 100000,\nTotal_Cases_And_Deaths$State == \"Massachusetts\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/6976597) * 100000,\nTotal_Cases_And_Deaths$State == \"Michigan\" ~ \n  (Total_Cases_And_Deaths$Total_State_Deaths/10045029) * 100000,\nTotal_Cases_And_Deaths$State == \"Minnesota\" ~ \n  (Total_Cases_And_Deaths$Total_State_Deaths/5700671) * 100000,\nTotal_Cases_And_Deaths$State == \"Mississippi\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/2989260) * 100000,\nTotal_Cases_And_Deaths$State == \"Missouri\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/6169270) * 100000,\nTotal_Cases_And_Deaths$State == \"Montana\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/1086759) * 100000,\nTotal_Cases_And_Deaths$State == \"Nebraska\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/1952570) * 100000,\nTotal_Cases_And_Deaths$State == \"Nevada\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/3139658) * 100000,\nTotal_Cases_And_Deaths$State == \"New Hampshire\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/1371246) * 100000,\nTotal_Cases_And_Deaths$State == \"New Jersey\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/8936574) * 100000,\nTotal_Cases_And_Deaths$State == \"New Mexico\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/2096640) * 100000,\nTotal_Cases_And_Deaths$State == \"New York\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/19440469) * 100000,\nTotal_Cases_And_Deaths$State == \"North Carolina\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/10611862) * 100000,\nTotal_Cases_And_Deaths$State == \"North Dakota\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/761723) * 100000,\nTotal_Cases_And_Deaths$State == \"Ohio\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/11747694) * 100000,\nTotal_Cases_And_Deaths$State == \"Oklahoma\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/3954821) * 100000,\nTotal_Cases_And_Deaths$State == \"Oregon\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/4301089) * 100000,\nTotal_Cases_And_Deaths$State == \"Pennsylvania\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/12820878) * 100000,\nTotal_Cases_And_Deaths$State == \"Rhode Island\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/1056161) * 100000,\nTotal_Cases_And_Deaths$State == \"South Carolina\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/5210095) * 100000,\nTotal_Cases_And_Deaths$State == \"South Dakota\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/903027) * 100000,\nTotal_Cases_And_Deaths$State == \"Tennessee\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/6897576) * 100000,\nTotal_Cases_And_Deaths$State == \"Texas\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/29472295) * 100000,\nTotal_Cases_And_Deaths$State == \"Utah\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/3282115) * 100000,\nTotal_Cases_And_Deaths$State == \"Vermont\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/628061) * 100000,\nTotal_Cases_And_Deaths$State == \"Virginia\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/8626207) * 100000,\nTotal_Cases_And_Deaths$State == \"Washington\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/7797095) * 100000,\nTotal_Cases_And_Deaths$State == \"West Virginia\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/1778070) * 100000,\nTotal_Cases_And_Deaths$State == \"Wisconsin\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/5851754) * 100000,\nTotal_Cases_And_Deaths$State == \"Wyoming\" ~\n  (Total_Cases_And_Deaths$Total_State_Deaths/567025) * 100000,\n    TRUE ~ as.double(Total_Cases_And_Deaths$State))\n\n# Remove Full State name column.\nTotal_Cases_And_Deaths2 &lt;- select(Total_Cases_And_Deaths, -(State))\n\n# Add State Abbreviations as State instead.\nTotal_Cases_And_Deaths2$State &lt;- Total_Cases_And_Deaths2$State_Abb\n\n# Remove redundant State_Abb column.\nTotal_Cases_And_Deaths2 &lt;- select(Total_Cases_And_Deaths2, -(State_Abb))\n\nhead(Total_Cases_And_Deaths2)\n\n    Week N Total_State_Cases Total_State_Deaths Total_US_Cases Total_US_Deaths\n1 Week 1 1               224                  0          45952             786\n2 Week 2 1              1001                 10         165282            4270\n3 Week 3 1              2079                 49         384281           14959\n4 Week 4 1              3870                 99         597539           30151\n5 Week 1 1                39                  0          45952             786\n6 Week 2 1               119                  3         165282            4270\n  Cases_Per_10000 Cases_Per_100000 Deaths_Per_10000 Deaths_Per_100000 State\n1       0.4563400         4.563400       0.00000000         0.0000000    AL\n2       2.0392693        20.392693       0.02037232         0.2037232    AL\n3       4.2354054        42.354054       0.09982437         0.9982437    AL\n4       7.8840880        78.840880       0.20168597         2.0168597    AL\n5       0.5313337         5.313337       0.00000000         0.0000000    AK\n6       1.6212490        16.212490       0.04087182         0.4087182    AK\n\n\nThe dataframe above shows just the first 6 rows. Each row contains the total COVID-19 cases and deaths (and some per capita information) in a specific State during one of the four Weeks we collected data. Later, I will plot some of this information for interests sake."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#survey-data-pre-processing",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#survey-data-pre-processing",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Survey Data Pre-processing",
    "text": "Survey Data Pre-processing\nBelow I read in the raw survey data from our study, and then combined/removed some data. The steps taken and data removed can be looked at more closely in the code chunk below. Some of the data are recoded as well and consists of variables that are used in the study but not used in this assignment.\nPlease note that the data are available on the osf page for this study: https://osf.io/8w6x2/\nThe file on the osf page is called “CVA_full.csv”.\n\n## Load dataset\nCVA &lt;- read.csv(\"C:/Users/STPI0560/Desktop/R Projects/Covid-19-Altruism-Bayesian-Analysis/data/raw/cva.csv\")\n\n#Remove one participant with repeated data\nCVA &lt;- filter(CVA, !(SubID == \"294b\"))\n\n## Questionnaire scoring \n\n# Self-reported altruism scale (SRA) Scoring\nCVA$SRA &lt;- (CVA$SRA1+CVA$SRA2+CVA$SRA3+CVA$SRA4+CVA$SRA5+CVA$SRA6+CVA$SRA7+CVA$SRA8+CVA$SRA9+CVA$SRA10+CVA$SRA11+CVA$SRA12+CVA$SRA13+CVA$SRA14+CVA$SRA15+CVA$SRA16+CVA$SRA17+CVA$SRA18+CVA$SRA19+CVA$SRA20)\n\n# Donations Scoring\nCVA$donations &lt;- CVA$SRA4+CVA$SRA5+CVA$SRA6+CVA$SRA7+CVA$SRA8\n\n# Risk Perception (RP) Scoring\nCVA$RP &lt;- CVA$RP1+CVA$RP2+CVA$RP3+CVA$RP4+CVA$RP5+CVA$RP6+CVA$RP7+CVA$RP8+CVA$RP9+CVA$RP10\n\n# Prosocial behavioral intentions scoring\nCVA$PBI &lt;- (CVA$PSI1+CVA$PSI2+CVA$PSI3+CVA$PSI4)/4\nCVA$PBI_S &lt;- (CVA$PSI2+CVA$PSI4)/2\nCVA$PBI_R &lt;- (CVA$PSI1+CVA$PSI3)/2\n\n## Perceived Stress scale Recoding\n# Reverse scored items (4, 5, 7, 8) for:\n\n# PS4\nCVA$PS4R &lt;- ifelse(CVA$PS4 == \"0\", 4,\n                    ifelse(CVA$PS4 == \"1\", 3,\n                           ifelse(CVA$PS4 == \"2\", 2,\n                                  ifelse(CVA$PS4 == \"3\", 1, 0))))\n\n#PS5\nCVA$PS5R &lt;- ifelse(CVA$PS5 == \"0\", 4,\n                    ifelse(CVA$PS5 == \"1\", 3,\n                           ifelse(CVA$PS5 == \"2\", 2,\n                                  ifelse(CVA$PS5 == \"3\", 1, 0))))\n# PS7 \nCVA$PS7R &lt;- ifelse(CVA$PS7 == \"0\", 4,\n                    ifelse(CVA$PS7 == \"1\", 3,\n                           ifelse(CVA$PS7 == \"2\", 2,\n                                  ifelse(CVA$PS7 == \"3\", 1, 0)))) \n# PS8\nCVA$PS8R &lt;- ifelse(CVA$PS8 == \"0\", 4,\n                    ifelse(CVA$PS8 == \"1\", 3,\n                           ifelse(CVA$PS8 == \"2\", 2,\n                                  ifelse(CVA$PS8 == \"3\", 1, 0)))) \n\n#Calculate PSS score\nCVA$PSS &lt;- CVA$PS1 + CVA$PS2 + CVA$PS3+ CVA$PS4R+ CVA$PS5R+ CVA$PS6+ CVA$PS7R+ CVA$PS8R+ CVA$PS9+ CVA$PS10\n\n \n## DASS-21\n# Depression: 3, 5, 10, 13, 16, 17, 21; Anxiety: 2, 4, 7, 9, 15, 19, 20; Stress: 1, 6, 8, 11, 12, 14, 18\nCVA$Depression &lt;- (CVA$D3 + CVA$D5+ CVA$D10+ CVA$D13+ CVA$D16+ CVA$D17+ CVA$D21)*2\nCVA$Anxiety &lt;- (CVA$D2 + CVA$D4+ CVA$D7+ CVA$D9+ CVA$D15+ CVA$D19+ CVA$D20)*2\nCVA$Stress &lt;- (CVA$D1 + CVA$D6+ CVA$D8+ CVA$D11+ CVA$D12+ CVA$D14+ CVA$D18)*2\n\n## Convert Timepoint to Week\nCVA$Week &lt;- ifelse(CVA$Timepoint == \"1\", \"Week 1\", \n                 ifelse(CVA$Timepoint == \"2\", \"Week 2\", \n                        ifelse(CVA$Timepoint == \"3\", \"Week 3\", \"Week 4\")))\n\n## Recode categorical variables\n# Employment Recoding\nCVA$Employment &lt;- ifelse(CVA$Emp == \"1\", \"Employed\",\n                         ifelse(CVA$Emp == \"2\", \"Unemployed\", \"Student\"))\n\n# Gender Recoding\nCVA$Gender2 &lt;- ifelse(CVA$Gender == \"1\", \"Male\", \n                      ifelse(CVA$Gender == \"2\", \"Female\", \"Other\"))\n\n# Education Recoding\nCVA$Education &lt;- ifelse(CVA$Edu == \"1\", \"High school or below\", \n                      ifelse(CVA$Gender == \"2\", \"University degree\", \"Graduate degree\"))\n\n## Remove unnecessary variables before joining with Covid-19 data\nCVA_new &lt;- select(CVA, -c(Timepoint, SRA1, SRA2, SRA3, SRA4, SRA5, SRA6, SRA7, SRA8, SRA9, SRA10, SRA11, SRA12, SRA13, SRA14, SRA15, SRA16,SRA17, SRA18, SRA19, SRA20, Emp, Edu, Gender, D1, D2, D3, D4, D5, D6, D7, D8, D9, D10, D11, D12, D13, D14, D15, D16, D17, D18, D19, D20, D21, PS1, PS2, PS3, PS4, PS5, PS6, PS7, PS8, PS9, PS10, PS4R, PS5R, PS7R, PS8R, PSI1, PSI2, PSI3, PSI4, RP1, RP2, RP3, RP4, RP5, RP6, RP7, RP8, RP9, RP10, VAR029, VAR033, VAR039, VAR050, VAR072, VAR083, VAR089, VAR094))\n\nNext, the COVID-19 data and survey data were combined to form a single dataframe. A bit later, I will plot both total cases per State, as well as self-reported altruism score per State over the course of each Week that data acquisition took place.\n\n# Join COVID survey and COVID U.S.A data.\nCVA_full &lt;- full_join(CVA_new, Total_Cases_And_Deaths2, by=NULL)\n\n# Remove NA Subjects\nCVA_full &lt;- filter(CVA_full, !(SubID == \"NA\"))\n\n# Display dataframe form analysis\nhead(CVA_full)\n\n  SubID  ID               ProlificID Age SEL Country State relative friend\n1   287 139 5d288c5cc3c61e001781c77d  19   2       2    AK       NA     NA\n2   384  85 5c802d06948f9c00017b3eb2  35   4       2    AK        3      3\n3    87 196 58af423e6590840001566cc7  32   3       2    AL       NA     NA\n4   198  48 5e72665f88152e1aecef02ff  20   4       2    AL       NA     NA\n5   240  90 5cbdc86714b3cb0001f035bb  38   2       2    AL       NA     NA\n6   333  34 5dab9bb23dd8f50015d256d5  46   1       2    AL        4      4\n  acquaint stranger ingroup outgroup ownn othern political identify help\n1       NA       NA      NA       NA    3      3         2        2    3\n2        1        1       2        1    1      3         1        1    1\n3       NA       NA      NA       NA    3      4         1        3    3\n4       NA       NA      NA       NA    2      3         1        3    1\n5       NA       NA      NA       NA    3      3         3        3    3\n6        4        4       4        4    3      3         3        3    3\n  socialm personalcom mainnews indnews personalexp alc1 alc2 alc3 control SRA\n1       4           3        5       1           1    4    5    3       4  47\n2       1           4        3       1           3    3    2    1       4  56\n3       5           5        5       3           1    4    3    3       4  45\n4       4           2        5       3           1    1    1    1       4  36\n5       3           3        1       1           1    1    1    1       4  38\n6       3           3        4       4           2    2    2    1       4  77\n  donations RP  PBI PBI_S PBI_R PSS Depression Anxiety Stress   Week Employment\n1        12 40 5.75     6   5.5  29         16       8     18 Week 2    Student\n2        14 49 5.75     5   6.5  25         10       2     16 Week 3 Unemployed\n3        10 28 7.00     7   7.0  12          0       0      2 Week 1   Employed\n4         9 58 4.75     4   5.5  28         14       0      8 Week 2    Student\n5        10 41 7.00     7   7.0  21         14       4     10 Week 2   Employed\n6        17 48 7.00     7   7.0  34         24      14     34 Week 3 Unemployed\n  Gender2            Education N Total_State_Cases Total_State_Deaths\n1  Female High school or below 1               119                  3\n2    Male      Graduate degree 1               193                  6\n3    Male High school or below 1               224                  0\n4  Female High school or below 1              1001                 10\n5  Female High school or below 1              1001                 10\n6  Female High school or below 1              2079                 49\n  Total_US_Cases Total_US_Deaths Cases_Per_10000 Cases_Per_100000\n1         165282            4270        1.621249         16.21249\n2         384281           14959        2.629421         26.29421\n3          45952             786        0.456340          4.56340\n4         165282            4270        2.039269         20.39269\n5         165282            4270        2.039269         20.39269\n6         384281           14959        4.235405         42.35405\n  Deaths_Per_10000 Deaths_Per_100000\n1       0.04087182         0.4087182\n2       0.08174365         0.8174365\n3       0.00000000         0.0000000\n4       0.02037232         0.2037232\n5       0.02037232         0.2037232\n6       0.09982437         0.9982437\n\n\nThe dataframe consists of 601 columns, and is what I will use for my Bayesian analysis. Each row is data collected from one participant, and also contains data about the number of cases and deaths for the week the data was collected for the State each participant comes from. There are many additional variables as well that are not important for the current analysis."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#measurement-scales",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#measurement-scales",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Measurement Scales",
    "text": "Measurement Scales\nTheir were 5 major scales that make up the dependent and independent measures used in the survey study, and they will briefly be discussed here. The Self-Reported Altruism Scale (SRA; Rushton et al., 1981) asks participants to rate the frequency with which they engaged in various altruistic acts. COVID-19 Risk Perception (RP) was assessed using a modified scale from Wise et al. (2020) and asks participants about their percieved risk of COVID-19 related infection and related personal/financial worries. Defensive emotions were indexed via the Percieved Stress Scale (PSS-10; Cohen et al., 1983) and the Depression Anxiety Stress Scale (DASS-21; Lovibond & Lovibond, 1995). The PSS-10 asks participants about experiences of stress related to unpredictable and uncontrollable events in their lives. The DASS-21 contains an anxiety scale related to acute anxiety/panic and autonomic arrousal. The DASS-21 also contains questons related to experienced depressive episodes, and these depression-related questions are also included as a seperate predictor in the model.\nBelow, I created some graphs to help visualise the distribution of scores for each measure. These are simply to help visualise how participants responded, and contain the responses from all 600 individuals.\n\n# Filter questionnaires only.\nCVA_Subset &lt;- CVA[, c(\"PS1\", \"PS2\", \"PS3\", \"PS4\", \"PS5\", \"PS6\", \"PS7\", \"PS8\", \"PS9\", \"PS10\", \"D1\", \"D2\", \"D4\", \"D6\", \"D7\", \"D8\", \"D9\", \"D11\", \"D12\", \"D14\", \"D15\", \"D18\", \"D19\", \"D20\", \"RP1\", \"RP2\", \"RP3\", \"RP4\", \"RP5\", \"RP6\", \"RP7\", \"RP8\", \"RP9\", \"RP10\", \"SRA1\", \"SRA2\", \"SRA3\", \"SRA4\", \"SRA5\", \"SRA6\", \"SRA7\", \"SRA8\", \"SRA9\", \"SRA10\", \"SRA11\", \"SRA12\", \"SRA13\", \"SRA14\", \"SRA15\", \"SRA16\", \"SRA17\", \"SRA18\", \"SRA19\", \"SRA20\")]\n\n#Reverse scored item PS4.\nCVA_Subset$PS4 &lt;- ifelse(CVA_Subset$PS4 == \"0\", 4,\n                    ifelse(CVA_Subset$PS4 == \"1\", 3,\n                           ifelse(CVA_Subset$PS4 == \"2\", 2,\n                                  ifelse(CVA_Subset$PS4 == \"3\", 1, 0))))\n\n#Reverse scored item PS5.\nCVA_Subset$PS5 &lt;- ifelse(CVA_Subset$PS5 == \"0\", 4,\n                    ifelse(CVA_Subset$PS5 == \"1\", 3,\n                           ifelse(CVA_Subset$PS5 == \"2\", 2,\n                                  ifelse(CVA_Subset$PS5 == \"3\", 1, 0))))\n \n#Reverse scored item PS7.\nCVA_Subset$PS7 &lt;- ifelse(CVA_Subset$PS7 == \"0\", 4,\n                    ifelse(CVA_Subset$PS7 == \"1\", 3,\n                           ifelse(CVA_Subset$PS7 == \"2\", 2,\n                                  ifelse(CVA_Subset$PS7 == \"3\", 1, 0)))) \n\n#Reverse scored item PS8.\nCVA_Subset$PS8 &lt;- ifelse(CVA_Subset$PS8 == \"0\", 4,\n                    ifelse(CVA_Subset$PS8 == \"1\", 3,\n                           ifelse(CVA_Subset$PS8 == \"2\", 2,\n                                  ifelse(CVA_Subset$PS8 == \"3\", 1, 0))))\n\nCVA_PS &lt;- CVA_Subset[, 1:10]\nCVA_D &lt;- CVA_Subset[, 11:24]\nCVA_RP &lt;- CVA_Subset[, 25:34]\nCVA_SRA &lt;- CVA_Subset[, 35:54]\n\nCVA_PS_Long &lt;- gather(CVA_PS, key = PS, value = \"Measure\", PS1:PS10)\nCVA_D_Long &lt;- gather(CVA_D, key = D, value = \"Measure\", D1:D20)\nCVA_RP_Long &lt;- gather(CVA_RP, key = RP, value = \"Measure\", RP1:RP10)\nCVA_SRA_Long &lt;- gather(CVA_SRA, key = SRA, value = \"Measure\", SRA1:SRA20)\n\n# PSS graphing dataframe.\nCVA_PS_Long$Question &lt;- case_when(\nCVA_PS_Long$PS == \"PS1\" ~ \"How often have you been upset because of something that happened unexpectedly?\",\nCVA_PS_Long$PS == \"PS2\" ~ \"how often have you felt you were unable to control the important things in your life?\",\nCVA_PS_Long$PS == \"PS3\" ~ \"how often have you felt nervous and stressed?\",\nCVA_PS_Long$PS == \"PS4\" ~ \"how often have you felt confident about your ability to handle your personal problems?\",\nCVA_PS_Long$PS == \"PS5\" ~ \"how often have you felt that things were going your way?\",\nCVA_PS_Long$PS == \"PS6\" ~ \"how often have you found that you could not cope with all the things you had to do?\",\nCVA_PS_Long$PS == \"PS7\" ~ \"how often have you been able to control irritations in your life?\",\nCVA_PS_Long$PS == \"PS8\" ~ \"how often have you felt that you were on top of things?\",\nCVA_PS_Long$PS == \"PS9\" ~ \"how often have you been angered because of things that were outside your control?\",\nCVA_PS_Long$PS == \"PS10\" ~ \"how often have you felt difficulties were pilling up so high that you could not overcome them?\",\nTRUE ~ as.character(CVA_PS_Long$PS)\n)\n\nCVA_PS_Long$Answer &lt;- case_when(\nCVA_PS_Long$Measure == 0 ~ \"1. Never\",\nCVA_PS_Long$Measure == 1 ~ \"2. Almost Never\",\nCVA_PS_Long$Measure == 2 ~ \"3. Sometimes\",\nCVA_PS_Long$Measure == 3 ~ \"4. Fairly Often\",\nCVA_PS_Long$Measure == 4 ~ \"5. Very Often\",\nTRUE ~ as.character(CVA_PS_Long$Measure)\n)\n\n# Depression graphing dataframe.\nCVA_D_Long$Question &lt;- case_when(\nCVA_D_Long$D == \"D1\" ~ \"I found it hard to wind down\",\nCVA_D_Long$D == \"D2\" ~ \"I was aware of dryness of my mouth\",\nCVA_D_Long$D == \"D4\" ~ \"I experienced breathing difficulty\",\nCVA_D_Long$D == \"D6\" ~ \"I tended to overreact to situations\",\nCVA_D_Long$D == \"D7\" ~ \"I experienced trembling\",\nCVA_D_Long$D == \"D8\" ~ \"I felt I was using a lot of nervous energy\",\nCVA_D_Long$D == \"D9\" ~ \"I was worried about situations where I might panic and make a fool of myself\",\nCVA_D_Long$D == \"D11\" ~ \"I found myself getting agitated\",\nCVA_D_Long$D == \"D12\" ~ \"I found it difficult to relax\",\nCVA_D_Long$D == \"D14\" ~ \"I was intolerant of anything that kept me from getting on with what I was doing\",\nCVA_D_Long$D == \"D15\" ~ \"I felt I was close to panic\",\nCVA_D_Long$D == \"D18\" ~ \"I felt I was rather touchy\",\nCVA_D_Long$D == \"D19\" ~ \"I was aware of the action of my heart in the absence of physical exertion\",\nCVA_D_Long$D == \"D20\" ~ \"I felt scared without any good reason\",\nTRUE ~ as.character(CVA_D_Long$D)\n)\n\nCVA_D_Long$Answer &lt;- case_when(\nCVA_D_Long$Measure == 0 ~ \"1. Did not apply to me at all\",\nCVA_D_Long$Measure == 1 ~ \"2. Applied to me to some degree\",\nCVA_D_Long$Measure == 2 ~ \"3. Applied to me to a great degree\",\nCVA_D_Long$Measure == 3 ~ \"4. Applied to me most of the time\",\nTRUE ~ as.character(CVA_D_Long$Measure)\n)\n\n# Risk Perception graphing dataframe.\nCVA_RP_Long$Question &lt;- case_when(\nCVA_RP_Long$RP == \"RP1\" ~ \"How likely do you think you are to catch the virus?\",\nCVA_RP_Long$RP == \"RP2\" ~ \"How badly do you think your health will be affected if you do catch the virus?\",\nCVA_RP_Long$RP == \"RP3\" ~ \"How badly do you think you will be affected economically if you specifically catch the virus?\",\nCVA_RP_Long$RP == \"RP4\" ~ \"How badly do you think you will be affected by the global effects of the virus?\",\nCVA_RP_Long$RP == \"RP5\" ~ \"How likely do you think it is that a loved one will become infected?\",\nCVA_RP_Long$RP == \"RP6\" ~ \"How likely do you think the average person in your neighbourhood is to become infected?\",\nCVA_RP_Long$RP == \"RP7\" ~ \" How likely do you think the average person in your state is to become infected?\",\nCVA_RP_Long$RP == \"RP8\" ~ \"How likely do you think the average person in your country is to become infected?\",\nCVA_RP_Long$RP == \"RP9\" ~ \"If you do contract the virus, how likely do you think it is that you will pass it on to someone else?\",\nCVA_RP_Long$RP == \"RP10\" ~ \"If you do contract the virus and pass it on to someone else, how badly do you think they would be affected?\",\nTRUE ~ as.character(CVA_RP_Long$RP)\n)\n\nCVA_RP_Long$Answer &lt;- case_when(\nCVA_RP_Long$Measure == 1 ~ \"1 - Min\",\nCVA_RP_Long$Measure == 2 ~ \"2\",\nCVA_RP_Long$Measure == 3 ~ \"3\",\nCVA_RP_Long$Measure == 4 ~ \"4\",\nCVA_RP_Long$Measure == 5 ~ \"5\",\nCVA_RP_Long$Measure == 6 ~ \"6\",\nCVA_RP_Long$Measure == 7 ~ \"7 - Max\",\nTRUE ~ as.character(CVA_RP_Long$Measure)\n)\n\n# Self-Reported Altruism graphing dataframe.\nCVA_SRA_Long$Question &lt;- case_when(\nCVA_SRA_Long$SRA == \"SRA1\" ~ \"I have helped push a stranger’s car out of the snow\",\nCVA_SRA_Long$SRA == \"SRA2\" ~ \"I have given directions to a stranger\",\nCVA_SRA_Long$SRA == \"SRA3\" ~ \"I have made change for a stranger\",\nCVA_SRA_Long$SRA == \"SRA4\" ~ \"I have given money to a charity\",\nCVA_SRA_Long$SRA == \"SRA5\" ~ \"I have given money to a stranger who needed it\",\nCVA_SRA_Long$SRA == \"SRA6\" ~ \"I have donated goods or clothes to a charity\",\nCVA_SRA_Long$SRA == \"SRA7\" ~ \"I have done volunteer work for a charity\",\nCVA_SRA_Long$SRA == \"SRA8\" ~ \"I have donated blood\",\nCVA_SRA_Long$SRA == \"SRA9\" ~ \"I have helped carry a stranger’s belongings\",\nCVA_SRA_Long$SRA == \"SRA10\" ~ \"I have delayed an elevator and held the door open for a stranger\",\nCVA_SRA_Long$SRA == \"SRA11\" ~ \"I have allowed someone to go ahead of me in a lineup\",\nCVA_SRA_Long$SRA == \"SRA12\" ~ \"I have given a stranger a lift in my car\",\nCVA_SRA_Long$SRA == \"SRA13\" ~ \"I have pointed out a clerk’s error in undercharging me for an item\",\nCVA_SRA_Long$SRA == \"SRA14\" ~ \"I have let a neighbour whom I didn’t know too well borrow an item of some value to me\",\nCVA_SRA_Long$SRA == \"SRA15\" ~ \"I have bought ‘charity” Christmas cards deliberately because I knew it was a good cause.\",\nCVA_SRA_Long$SRA == \"SRA16\" ~ \"I have helped a classmate who I did not know that well with a homework assignment when my knowledge was greater\",\nCVA_SRA_Long$SRA == \"SRA17\" ~ \"I have before being asked, voluntarily looked after a neighbour’s pets or children without being paid for it\",\nCVA_SRA_Long$SRA == \"SRA18\" ~ \"I have offered to help a handicapped or elderly stranger across a street\",\nCVA_SRA_Long$SRA == \"SRA19\" ~ \"I have offered my seat on a bus or train to a stranger who was standing\",\nCVA_SRA_Long$SRA == \"SRA20\" ~ \"I have helped an acquaintance to move households\",\nTRUE ~ as.character(CVA_SRA_Long$SRA)\n)\n\nCVA_SRA_Long$Answer &lt;- case_when(\nCVA_SRA_Long$Measure == 1 ~ \"1. Never\",\nCVA_SRA_Long$Measure == 2 ~ \"2. Once\",\nCVA_SRA_Long$Measure == 3 ~ \"3. More Than Once\",\nCVA_SRA_Long$Measure == 4 ~ \"4. Often\",\nCVA_SRA_Long$Measure == 5 ~ \"5. Very Often\",\nTRUE ~ as.character(CVA_SRA_Long$Measure)\n)\n\n\nggplot(CVA_PS_Long, aes(x = PS, fill = Answer, na.rm = TRUE)) +\n  geom_bar(position = position_fill(reverse = TRUE), na.rm = TRUE) +\n  theme(text = element_text(size=11)) +\n  coord_flip() + \n  xlab(\"\") +\n  ylab(\"Number of responses\")+\n  scale_fill_brewer(type = \"div\")+ \n  labs(fill = \"Answer\") +\n  ggtitle(\"Perceived Stress Scale\")\n\n\n\n\n\n\n\n\n\nggplot(CVA_D_Long, aes(x = D, fill = Answer, na.rm = TRUE)) +\n  geom_bar(position = position_fill(reverse = TRUE), na.rm = TRUE) +\n  theme(text = element_text(size=11)) +\n  coord_flip() + \n  xlab(\"\") +\n  ylab(\"Number of responses\")+\n  scale_fill_brewer(type = \"div\")+ \n  labs(fill = \"Answer\") +\n  ggtitle(\"Depression, Anxiety, and Stress Scale\")\n\n\n\n\n\n\n\n\nThis graph contains scores for both acute anxiety related questions, and depression related questions.\n\nggplot(CVA_RP_Long, aes(x = RP, fill = Answer, na.rm = TRUE)) +\n  geom_bar(position = position_fill(reverse = TRUE), na.rm = TRUE) +\n  theme(text = element_text(size=11)) +\n  coord_flip() + \n  xlab(\"\") +\n  ylab(\"Number of responses\")+\n  scale_fill_brewer(type = \"div\")+ \n  labs(fill = \"Answer\") +\n  ggtitle(\"COVID-19 Risk Perception Questionnaire\")\n\n\n\n\n\n\n\n\n\nggplot(CVA_SRA_Long, aes(x = SRA, fill = Answer, na.rm = TRUE)) +\n  geom_bar(position = position_fill(reverse = TRUE), na.rm = TRUE) +\n  theme(text = element_text(size=11)) +\n  coord_flip() + \n  xlab(\"\") +\n  ylab(\"Number of responses\")+\n  scale_fill_brewer(type = \"div\")+ \n  labs(fill = \"Answer\") +\n  ggtitle(\"Self-Reported Altruism Scale\")"
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#distribution-of-main-variables",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#distribution-of-main-variables",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Distribution of main variables",
    "text": "Distribution of main variables\nI have included histograms of the dependent and independent variables to help get a sense of how they are distributed, and whether the variables could be considered for transformation.\n\n# Histograms main variables\n\nSRA_Hist &lt;- ggplot(data=CVA_full, aes(x=SRA, fill = Week)) + \n  geom_histogram(aes(y = ..density..), binwidth = 8)+\n  geom_density(alpha=.2, fill=\"white\")+\n  scale_fill_brewer(palette = \"Pastel2\")+\n  facet_wrap(~Week, nrow = 1)+\n  theme_pubr()+\n  ggtitle(\"Self-reported Altruism Scale\")+\n    theme(legend.position = \"none\") +\n      theme(text = element_text(size=10))\n\nRP_Hist &lt;- ggplot(data=CVA_full, aes(x=RP, fill = Week)) + \n  geom_histogram(aes(y = ..density..), binwidth = 8)+\n  geom_density(alpha=.2, fill=\"white\")+\n  scale_fill_brewer(palette = \"Pastel2\")+\n  facet_wrap(~Week, nrow = 1)+\n  theme_pubr()+\n  ggtitle(\"Covid-19 Risk Perception\")+\n    theme(legend.position = \"none\") +\n      theme(text = element_text(size=10))\n  \nPSS_Hist &lt;- ggplot(data=CVA_full, aes(x=PSS, fill = Week)) + \n  geom_histogram(aes(y = ..density..), binwidth = 8)+\n  geom_density(alpha=.2, fill=\"white\")+\n  scale_fill_brewer(palette = \"Pastel2\")+\n  facet_wrap(~Week, nrow = 1)+\n  theme_pubr()+\n  ggtitle(\"Perceived Stress Scale\")+\n    theme(legend.position = \"none\") +\n      theme(text = element_text(size=10))\n \nAnxiety_Hist &lt;- ggplot(data=CVA_full, aes(x=Anxiety, fill = Week)) +\n  geom_histogram(aes(y = ..density..), binwidth = 8)+\n  geom_density(alpha=.2, fill=\"white\")+\n  scale_fill_brewer(palette = \"Pastel2\")+\n  facet_wrap(~Week, nrow = 1)+\n  theme_pubr()+\n  ggtitle(\"DASS-21 Anxiety\")+\n    theme(legend.position = \"none\") +\n      theme(text = element_text(size=10))\n \nDepression_Hist &lt;- ggplot(data=CVA_full, aes(x=Depression, fill = Week)) + \n  geom_histogram(aes(y = ..density..), binwidth = 1)+\n  geom_density(alpha=.2, fill=\"white\")+\n  scale_fill_brewer(palette = \"Pastel2\")+\n  facet_wrap(~Week, nrow = 1)+\n  theme_pubr()+\n  ggtitle(\"Depression Scale\")+\n    theme(legend.position = \"none\") +\n      theme(text = element_text(size=10))\n  \nggarrange(SRA_Hist, RP_Hist, PSS_Hist, Anxiety_Hist, Depression_Hist, nrow = 5)\n\n\n\n\n\n\n\n\nAs can be seen, some distributions are relatively normal (e.g. SRA, RP), while others are relatively skewed (Anxiety, Depression). Because the original study transformed all of these variables (justification provided later), that’s the strategy I will use too in order to keep my analysis consistent with the original."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#altruism-and-risk-perception-over-4-weeks",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#altruism-and-risk-perception-over-4-weeks",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Altruism and Risk Perception over 4 weeks",
    "text": "Altruism and Risk Perception over 4 weeks\nI first wanted to see whether Self-Reported Altrusim (SRA) was affected by the week it was collected. We hypothesized that SRA would increase linearly from week 1 to week 4 in accordance to increasing COVID-19 threat. As can be seen below however, this was not the case. While I considered making very simple models to assess how week predicted SRA and Risk Perception (RP), I will forego that here as these measures were clearly unaffected.\n\n#Plot main variables over 4 week period\n\n#create function to have mean estimate and sd in a point plot\ndata_summary &lt;- function(x) {\n   m &lt;- mean(x)\n   ymin &lt;- m-sd(x)/2\n   ymax &lt;- m+sd(x)/2\n   return(c(y=m,ymin=ymin,ymax=ymax))\n} \n\n#SRA&lt;- ggplot(CVA_full, aes(x=Week, y = SRA, color = Week)) +\n # geom_point()+\n #geom_jitter(aes(color = Week), width = 0.18)+\n #stat_summary(fun.data=data_summary, color=\"black\")+\n  #scale_color_brewer(palette = \"Pastel2\")+\n  #  theme_bw()+\n # theme(legend.position = \"none\")+\n  #  theme(text = element_text(size=18))+\n #  labs(y = \"SRA\")\n# SRA\n\n\n#create dataframes per variable to plot line connecting means\nSRA_week &lt;- group_by(CVA_full, Week) %&gt;% summarise(SRA = mean(SRA))\nSRA_week &lt;- data.frame(SRA_week)\n\nRP_week &lt;- group_by(CVA_full, Week) %&gt;% summarise(RP = mean(RP))\nRP_week &lt;- data.frame(RP_week)\n\nPSS_week &lt;- group_by(CVA_full, Week) %&gt;% summarise(PSS = mean(PSS))\nPSS_week &lt;- data.frame(PSS_week)\n\n# na.rm removes Pacific Northwest person. Otherwise, Week 2 estimate is NA in Cases_week dataframe.\nCases_week &lt;- group_by(CVA_full, Week) %&gt;% summarise(Total_State_Cases = mean(Total_State_Cases, na.rm = TRUE))\nCases_week &lt;- data.frame(Cases_week)\n \nCases_state &lt;- ggplot(Cases_week, aes(x=Week, y = Total_State_Cases, group = 1)) +\n  geom_line() +\n  geom_point() +\n  ylab(\"Total Cases\")+\n  theme_pubr()+\ntheme(text = element_text(size=18))\n\n RP_line &lt;- ggplot(CVA_full, aes(x=Week, y = RP, color = SubID)) +\n    geom_jitter(aes(color = Week), width = 0.18)+\n    geom_line(data=RP_week, aes(x=Week, y=RP, group = 1), color='black', size = 1, alpha = 0.5) + \n  geom_point(data=RP_week, aes(x=Week, y=RP), color='black', size = 2, alpha = 0.5) +\n   scale_color_brewer(palette = \"Pastel2\")+\n   theme_pubr()+\n    theme(legend.position = \"none\")+\n    theme(text = element_text(size=18))\n\nSRA_line &lt;- ggplot(CVA_full, aes(x=Week, y = SRA, color = SubID)) +\n    geom_jitter(aes(color = Week), width = 0.18)+\n    geom_line(data=SRA_week, aes(x=Week, y=SRA, group = 1), color='black', size = 1, alpha = 0.5) + \n  geom_point(data=SRA_week, aes(x=Week, y=SRA), color='black', size = 2, alpha = 0.5) +\n   scale_color_brewer(palette = \"Pastel2\")+\n   theme_pubr()+\n    theme(legend.position = \"none\")+\n    theme(text = element_text(size=18))\n \n ggarrange(RP_line, SRA_line, Cases_state)\n\n\n\n\n\n\n\n\nThe bottom graph shows that average COVID-19 cases clearly increased from week to week, exponentially so when we include the final week. Both COVID-19 Risk Perception and Self-Reported Altruism did not change over this time course. It may be the case that people really weren’t concerned enough with the magnitude of the threat of the virus, and this may be why Self-Reported Altruism did not change either. It may also be the case that we did not collect data for a long enough time, or that we picked a time when COVID-19 threat was too recent."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#altruism-and-risk-perception",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#altruism-and-risk-perception",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Altruism and Risk Perception",
    "text": "Altruism and Risk Perception\n\n## Plot the correlation between SRA and RP per week\n\nggplot(CVA_full, aes(x = RP, y = SRA, color = Week))+\n  geom_point()+\n  geom_smooth(method = lm, se=FALSE, color = \"black\", size = 0.5)+\n  facet_wrap(~Week, nrow = 1)+\n  scale_color_brewer(palette = \"Pastel2\")+\n  theme_pubr()+\n  theme(text = element_text(size=18))+\n  theme(legend.position = \"none\") +\n      theme(text = element_text(size=10))\n\n\n\n\n\n\n\n\nIt looks like risk perception might be a good predictor of SRA as it linearly increases regardless of the week it was collected."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#altruism-and-perceived-stress-score-pss",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#altruism-and-perceived-stress-score-pss",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Altruism and Perceived Stress Score (PSS)",
    "text": "Altruism and Perceived Stress Score (PSS)\n\n## Plot the correlation between SRA and RP per week\n\nggplot(CVA_full, aes(x = PSS, y = SRA, color = Week))+\n  geom_point()+\n  geom_smooth(method = lm, se=FALSE, color = \"black\", size = 0.5)+\n  facet_wrap(~Week, nrow = 1)+\n  scale_color_brewer(palette = \"Pastel2\")+\n  theme_pubr()+\n  theme(text = element_text(size=18))+\n  theme(legend.position = \"none\") +\n      theme(text = element_text(size=10))\n\n\n\n\n\n\n\n\nNo strong relationship between SRA and PSS is apparent here. PSS indexes more generalised stress, and we predicted that it would not be associated with SRA."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#altruism-and-dass-21-anxiety",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#altruism-and-dass-21-anxiety",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Altruism and DASS-21 Anxiety",
    "text": "Altruism and DASS-21 Anxiety\n\n## Plot the correlation between SRA and RP per week\n\nggplot(CVA_full, aes(x = Anxiety, y = SRA, color = Week))+\n  geom_point()+\n  geom_smooth(method = lm, se=FALSE, color = \"black\", size = 0.5)+\n  facet_wrap(~Week, nrow = 1)+\n  scale_color_brewer(palette = \"Pastel2\")+\n  theme_pubr()+\n  theme(text = element_text(size=18))+\n  theme(legend.position = \"none\") +\n      theme(text = element_text(size=10))\n\n\n\n\n\n\n\n\nOur hypothesis was that anxiety about unpredictable/proximal threats would predict SRA, and that appears to be the case here."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#altruism-and-dass-21-depression",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#altruism-and-dass-21-depression",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Altruism and DASS-21 Depression",
    "text": "Altruism and DASS-21 Depression\n\n## Plot the correlation between SRA and RP per week\n\nggplot(CVA_full, aes(x = Depression, y = SRA, color = Week))+\n  geom_point()+\n  geom_smooth(method = lm, se=FALSE, color = \"black\", size = 0.5)+\n  facet_wrap(~Week, nrow = 1)+\n  scale_color_brewer(palette = \"Pastel2\")+\n  theme_pubr()+\n  theme(text = element_text(size=18))+\n  theme(legend.position = \"none\") +\n      theme(text = element_text(size=10))\n\n\n\n\n\n\n\n\nDepression does not seem to be associated with SRA."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#spatial-variability-state",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#spatial-variability-state",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Spatial Variability (State)?",
    "text": "Spatial Variability (State)?\nFor interest sake, I am including plots of total COVID cases, and SRA scores per State during the 4 weeks we collected data. This might give a better sense of the trajectory of the virus at this time.\n\nState &lt;- group_by(CVA_full, State, Week) %&gt;% summarise(mean = mean(Total_State_Cases))\nState &lt;- filter(State,  !(State == \"Pacific Northwest\"))\n  \n ggplot(State, aes(x=Week, y = mean, color = State, group)) +\n  #geom_jitter(aes(color = Week))+\n  geom_line(aes(x=Week, y = mean, group = State, color = State), size = 1) +\n  #geom_point(aes(x=Week, y = mean, group = State, color = State)) +\n   facet_wrap(~State)+\n  ylab(\"Total COVID-19 Cases\")+\n  theme_pubr()+\ntheme(text = element_text(size=8))+\n  theme(legend.position = \"none\")+\n  gghighlight()\n\n\n\n\n\n\n\nSRA_state &lt;- group_by(CVA_full, Week, State) %&gt;% summarise(SRA = mean(SRA))\nSRA_state &lt;- filter(SRA_state, !(State == \"Pacific Northwest\"))\n\nggplot(SRA_state, aes(x=Week, y = SRA, group = State, color = State)) +\n  #geom_jitter(aes(color = Week))+\n  geom_line(aes(x=Week, y = SRA, group = State, color = State), size = 1) +\n  #geom_point(aes(x=Week, y = mean, group = State, color = State)) +\n   facet_wrap(~State)+\n  ylab(\"Self-Reported Altruism\")+\n  theme_pubr()+\ntheme(text = element_text(size=8))+\n  theme(legend.position = \"none\")+\n  gghighlight()"
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#centering-the-data",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#centering-the-data",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Centering the Data",
    "text": "Centering the Data\nDuring the original frequentist analysis, the models being tested were not converging. Centering all continuous data fixed the issue. In keeping with the spirit of the initial analysis, I have also opted to center all variable. I have also tested this model without centering, and the posterior estimates are very similar (albeit of a different scale). However, uncentered estimates come with a huge swath of divergent transitions anyway, and centering the data reduced this effect substantially. Therefore, it makes sense to center everything before building the model.\n\nCVA_Bayes$SRA_C &lt;- scale(CVA_Bayes$SRA, center = TRUE, scale = TRUE)\nCVA_Bayes$RP_C &lt;- scale(CVA_Bayes$RP, center = TRUE, scale = TRUE)\nCVA_Bayes$PSS_C &lt;- scale(CVA_Bayes$PSS, center = TRUE, scale = TRUE) # Distal\nCVA_Bayes$Anxiety_C &lt;- scale(CVA_Bayes$Anxiety, center = TRUE, scale = TRUE) # Proximal\nCVA_Bayes$Depression_C &lt;- scale(CVA_Bayes$Depression, center = TRUE, scale = TRUE)\nCVA_Bayes$Age_C &lt;- scale(CVA_Bayes$Age, center = TRUE, scale = TRUE)"
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#a-note-about-my-priors",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#a-note-about-my-priors",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "A Note About My Priors",
    "text": "A Note About My Priors\nBecause I did not have a lot of prior knowledge about the measures used in the study, I wanted to keep my priors as uncertain as possible. Becuase we collected a lot of data, I figured that the priors would probably be drowned out by the likelihood anyway. Of special note, the prior I chose for correlations between elements in the variance-covarince matrix (lkj_corr_cholesky) is set to 1, meaning extreme correlations are more likely a priori. While it might make sense to set this higher (because maybe extreme correlations are actually less likely a priori), the examples I have seen that use this prior set it to 1, and it does not seem to change anything if I set it higher."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#initial-model-in-mathematical-notation",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#initial-model-in-mathematical-notation",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Initial Model In Mathematical Notation",
    "text": "Initial Model In Mathematical Notation\nHere is the initial model I fit. The model contains parameters for the intercept (SRA), Risk Perception (RP), Perceived Stress (PSS), Anxiety (A), and Depression (D). The model also has a random intercept accounting for SRA scores for each of the four weeks, and a random slope for each of the four predictors accounting for changes per each of the four weeks. State was also initially considered as a random effect, but the model became too complicated and would crash R if it was run. Removing the random effect of State fixed the issue. We would likely require more data from each State to use it in the model.\n\\[SRA_{i} \\sim Normal(\\mu_{i}, \\sigma)\\] \\[\\mu_{i} \\sim \\alpha_{week[i]} + \\beta RP_{week[i]}RP_{i} + \\beta PSS_{week[i]}PSS_{i} + \\beta A_{week[i]}A_{i} + \\beta D_{week[i]}D_{i}\\] \\[\\begin{bmatrix}\\alpha_{week}\\\\ \\beta_{week} \\end{bmatrix} \\sim MVNormal \\begin{pmatrix}\\begin{bmatrix}\\alpha\\\\ \\beta_{i} \\end{bmatrix} , S\n\\end{pmatrix}\\] \\[S = \\begin{pmatrix}\\sigma_{\\alpha} & 0\\\\\n0 & \\sigma_{\\beta}\n\\end{pmatrix}\nR \\begin{pmatrix}\\sigma_{\\alpha} & 0\\\\\n0 & \\sigma_{\\beta}\n\\end{pmatrix} \\] \\[\\alpha \\sim Normal(0, 1)\\] \\[\\beta \\sim Normal(0, 1)\\] \\[\\sigma \\sim Cauchy(0, 1)\\] \\[\\sigma_{\\alpha} \\sim Cauchy(0, 1)\\] \\[\\sigma_{\\beta} \\sim Cauchy(0, 1)\\] \\[R \\sim LKJ_{corr}(1)\\] \\[LKJ_{corr} = \\begin{bmatrix}1 & \\rho_{\\beta_{RP}\\alpha} & \\rho_{\\beta_{PSS}\\alpha} & \\rho_{\\beta_{A}\\alpha} & \\rho_{\\beta_{D}\\alpha}\\\\\n\\rho_{\\alpha\\beta_{RP}} & 1 & \\rho_{\\beta_{PSS}\\beta_{RP}} & \\rho_{\\beta_{A}\\beta_{RP}} & \\rho_{\\beta_{D}\\beta_{RP}}\\\\\n\\rho_{\\alpha\\beta_{PSS}} & \\rho_{\\beta_{RP}\\beta_{PSS}} & 1 & \\rho_{\\beta_{A}\\beta_{PSS}} & \\rho_{\\beta_{D}\\beta_{PSS}}\\\\\n\\rho_{\\alpha\\beta_{A}} & \\rho_{\\beta_{RP}\\beta_{A}} & \\rho_{\\beta_{PSS}\\beta_{A}} & 1 & \\rho_{\\beta_{D}\\beta_{A}}\\\\\n\\rho_{\\alpha\\beta_{D}} & \\rho_{\\beta_{RP}\\beta_{D}} & \\rho_{\\beta_{PSS}\\beta_{D}} & \\rho_{\\beta_{A}\\beta_{D}} & 1\\\\\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#initial-statistical-model",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#initial-statistical-model",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Initial Statistical Model",
    "text": "Initial Statistical Model\nBelow I tested the main model used in the original frequestist analysis. Unseen here, my initial model had a very large proportion of samples flagged as divergent. Therefore, I increased the adapt_delta parameter, starting at 0.96. This parameter affects the step-size of the Hamiltonian MCMC algorithm, and increasing it is akin to decreasing the size of a step taken by the algorithm during optimisation. While this action lowers the number of transitions that result in the energy of the Hamiltonian system not being constant (i.e. divergency), it can also make it less likely that the algorithm samples from harder to reach places of the posterior (like the tails for instance). Therefore, I increased the number of samples to 25,000 and the number of chains to 4. Once I identify the best adapt_delta configuration, the samples will be increased for the final model, and only one chain will be used.\n\n# Full COVID model.\nCOVID_Bayes_0.96 &lt;- brm(SRA_C~ 1 + RP_C + PSS_C + Anxiety_C + Depression_C  + (1+ RP_C + PSS_C + Anxiety_C + Depression_C|Week), data=CVA_Bayes,\n           family = gaussian(),\n           prior = c(\nprior(normal(0, 1), class = Intercept),\nprior(normal(0, 1), class = b, coef = \"RP_C\"),\nprior(normal(0, 1), class = b, coef = \"PSS_C\"),\nprior(normal(0, 1), class = b, coef = \"Anxiety_C\"),\nprior(normal(0, 1), class = b, coef = \"Depression_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = Intercept),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"RP_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"PSS_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Anxiety_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Depression_C\"),\nprior(cauchy(0,2), class = sd),\nprior(lkj_corr_cholesky(1), class = cor),\nprior(cauchy(0, 1), class = sigma)),\nfile = \"C:/Users/STPI0560/Desktop/Website/content/projects/2-covid19-altruism/models/COVID_Bayes_0.96.rds\",\niter = 25000, warmup = 2000, cores = 4, chains =4, seed = 123, control = list(adapt_delta = 0.96))\n\nThere are 525 divergent transitions with adapt_delta = 0.96, and I wonder if this can be improved.\n\nCOVID_Bayes_m1_Summary &lt;- tidyMCMC(COVID_Bayes_0.96$fit, conf.int = TRUE, rhat = TRUE, ess = TRUE, conf.level = 0.95,\n              conf.method = \"quantile\", pars = c(\"b_Intercept\", \"b_RP_C\", \"b_PSS_C\",\n                                                 \"b_Anxiety_C\", \"b_Depression_C\", \"sigma\"))\n\nCOVID_Bayes_m1_Summary\n\n# A tibble: 6 × 7\n  term           estimate std.error conf.low conf.high  rhat    ess\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;int&gt;\n1 b_Intercept    -0.00368    0.156   -0.321      0.323  1.00  23002\n2 b_RP_C          0.169      0.0980  -0.0180     0.365  1.00  22234\n3 b_PSS_C        -0.145      0.140   -0.410      0.131  1.00   6291\n4 b_Anxiety_C     0.306      0.0995   0.108      0.494  1.00  23620\n5 b_Depression_C -0.168      0.131   -0.418      0.105  1.00  19236\n6 sigma           0.949      0.0278   0.897      1.01   1.00 101914\n\n\nI am plotting some of the output, but am not yet interested in the parameter estimates. I only want to look at statistics related to the Hamiltonian MCMC algorithm right now. The rhat values with adapt_delta = 0.96 are all 1, and the ess seems decent. Still, I tried adapt_delta 0.97, 0.98, and 0.99 to see how it affected divergency.\n\n# Full COVID model: adaptive delta = 0.97.\nCOVID_Bayes_0.97 &lt;- brm(SRA_C~ 1 + RP_C + PSS_C + Anxiety_C + Depression_C  + (1+ RP_C + PSS_C + Anxiety_C + Depression_C|Week), data=CVA_Bayes,\n           family = gaussian(),\n           prior = c(\nprior(normal(0, 1), class = Intercept),\nprior(normal(0, 1), class = b, coef = \"RP_C\"),\nprior(normal(0, 1), class = b, coef = \"PSS_C\"),\nprior(normal(0, 1), class = b, coef = \"Anxiety_C\"),\nprior(normal(0, 1), class = b, coef = \"Depression_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = Intercept),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"RP_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"PSS_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Anxiety_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Depression_C\"),\nprior(cauchy(0,2), class = sd),\nprior(lkj_corr_cholesky(1), class = cor),\nprior(cauchy(0, 1), class = sigma)),\nfile = \"C:/Users/STPI0560/Desktop/Website/content/projects/2-covid19-altruism/models/COVID_Bayes_0.97.rds\",\niter = 25000, warmup = 2000, cores = 4, chains =4, seed = 123, control = list(adapt_delta = 0.97))\n\n\n# Full COVID model: adaptive delta = 0.98.\nCOVID_Bayes_0.98 &lt;- brm(SRA_C~ 1 + RP_C + PSS_C + Anxiety_C + Depression_C  + (1+ RP_C + PSS_C + Anxiety_C + Depression_C|Week), data=CVA_Bayes,\n           family = gaussian(),\n           prior = c(\nprior(normal(0, 1), class = Intercept),\nprior(normal(0, 1), class = b, coef = \"RP_C\"),\nprior(normal(0, 1), class = b, coef = \"PSS_C\"),\nprior(normal(0, 1), class = b, coef = \"Anxiety_C\"),\nprior(normal(0, 1), class = b, coef = \"Depression_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = Intercept),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"RP_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"PSS_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Anxiety_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Depression_C\"),\nprior(cauchy(0,2), class = sd),\nprior(lkj_corr_cholesky(1), class = cor),\nprior(cauchy(0, 1), class = sigma)),\nfile = \"C:/Users/STPI0560/Desktop/Website/content/projects/2-covid19-altruism/models/COVID_Bayes_0.98.rds\",\niter = 25000, warmup = 2000, cores = 4, chains =4, seed = 123, control = list(adapt_delta = 0.98))\n\n\n# Full COVID model: adaptive delta = 0.99.\nCOVID_Bayes_0.99 &lt;- brm(SRA_C~ 1 + RP_C + PSS_C + Anxiety_C + Depression_C  + (1+ RP_C + PSS_C + Anxiety_C + Depression_C|Week), data=CVA_Bayes,\n           family = gaussian(),\n           prior = c(\nprior(normal(0, 1), class = Intercept),\nprior(normal(0, 1), class = b, coef = \"RP_C\"),\nprior(normal(0, 1), class = b, coef = \"PSS_C\"),\nprior(normal(0, 1), class = b, coef = \"Anxiety_C\"),\nprior(normal(0, 1), class = b, coef = \"Depression_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = Intercept),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"RP_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"PSS_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Anxiety_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Depression_C\"),\nprior(cauchy(0,2), class = sd),\nprior(lkj_corr_cholesky(1), class = cor),\nprior(cauchy(0, 1), class = sigma)),\nfile = \"C:/Users/STPI0560/Desktop/Website/content/projects/2-covid19-altruism/models/COVID_Bayes_0.99.rds\",\niter = 25000, warmup = 2000, cores = 4, chains =4, seed = 123, control = list(adapt_delta = 0.99))\n\nIn the end, adapt_delta = 0.99 produced the lowest number of divergent transitions. This to me seems adaquate. While I have not shown it here, the estimates and credibility intervals are esentially identical for all adapt_delta values I tried. Before running the model again with a larger sample, I decided to see if there were any patterns to the divergencies that could be addressed when adapt_delta = 0.99 was used."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#divergency",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#divergency",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Divergency",
    "text": "Divergency\nFirst, The model estimates 42 parameters to account for variances and correlations between random effects. However, 1 parameter (__lp) is of a substantially different scale than the others. All other parameters are between -1 and +1, while __lp is near 1000. Therefore, visualising divergency is not possible with this parameter, so I will remove only it and look at the output.\n\nposterior_cp &lt;- as.array(COVID_Bayes_0.99)\nposterior_cp &lt;- posterior_cp[, , 1:41]\nnp_cp &lt;- nuts_params(COVID_Bayes_0.99)\n#head(np_cp)\nlp_cp &lt;- log_posterior(COVID_Bayes_0.99)\n#head(lp_cp)\n\n\ncolor_scheme_set(\"darkgray\")\nmcmc_parcoord(posterior_cp, np = np_cp)\n\n\n\n\n\n\n\n\nEach line shows the joint parameter estimate for a single transition. Red lines show the occurances of divergency somewhere in that transition, meaning on that particular transition there was a divergent sample somewhere. If 1 parameter is causing pathological behaviour, it should be clear such that the red lines concentrate around a specific value for that parameter. Here it is less clear, and may not matter much since the number of divergent transitions is small and they are discarded from the model estimate anyway. Additionally, since most divergent transitions occur closer to the peak of each posterior, they may be caused by the peaks themselves being too steep. For the sake of completeness however, I decided to look only at the fixed parameters entered into the model.\n\nposterior_cp_Fixed &lt;- as.array(COVID_Bayes_0.99)\n\n# Select all chains, but only for the intercept, RP, PSS, Anxiety, and Depression.\nposterior_cp_Fixed &lt;- posterior_cp_Fixed[, , 1:5]\n\n\ncolor_scheme_set(\"darkgray\")\nmcmc_parcoord(posterior_cp_Fixed, np = np_cp)\n\n\n\n\n\n\n\n\nNone of the divergent transitions seem very concentrated to any 1 parameter. Because I have decent control over these parameters via priors and data transformation, I can make some adjustments that could help the model. I cannot do much about the random effects parameters though, even if they are pathological. While the fixed affects do not seem to get stuck at any particularly difficult areas of the posterior, I stil wonder whether any of the specific chains contributed to this effect. Below I plot the marginal densities to assess this this.\n\nmcmc_pairs(posterior_cp_Fixed, np = np_cp)\n\n\n\n\n\n\n\n\nThis plot displays the marginal probability of each coefficient averaged over all other coefficient on the diagonal. The off-diagonal plots represent the joint probability of two parameters. Additionally, each off-diagnal side (left and right) displays 2 of the 4 chains I used. Usually these are mirror images of each other, but here they represent different chain estimates of the joint posterior. Each red point represents a sample taken during a divergent transition. Again, these do not concentrate anywhere on any posterior space, so the divergent transitions do not seem affected by one parameter."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#trace-plot-diagnostics",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#trace-plot-diagnostics",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Trace-plot diagnostics",
    "text": "Trace-plot diagnostics\nThis next diagnostic not only displays the usual MCMC traceplot, it also highlights each instance of a divergent transition. Each red tick on the x-axis below indicates the timepoint a divergent transition took place.\n\ncolor_scheme_set(\"mix-brightblue-gray\")\nmcmc_trace(posterior_cp_Fixed,, np = np_cp) +\n  xlab(\"Post-warmup iteration\")\n\n\n\n\n\n\n\n\nIt does not appear that the chains are divergent because they get hung up in a difficult part of the posterior, at least for the predictors. If they did, we would expect to see divergent transitions clustered at particular timepoints."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#mcmc-nuts-divergence",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#mcmc-nuts-divergence",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "MCMC Nuts Divergence",
    "text": "MCMC Nuts Divergence\nIt is also possible to assess how divergency interacts with the model at a global (full model) scale.\n\ncolor_scheme_set(\"red\")\nmcmc_nuts_divergence(np_cp, lp_cp)\n\n\n\n\n\n\n\n\nThe top panel shows the distribution of the log-posterior when there was no divergence (left) compared to when there was divergence (right). Divergence can mean that some part of the posterior is not being explored, and that does seem to be the case with the right plot. The bottom plot shows the NUTS acceptance statistic, which is essentially the same thing. However, based on examples I have seen, these do not indicate that there is much of an issue with unexplored areas of the posterior, just that divergent transitions occur in more concentrated areas of the posterior."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#mcmc-summary-diagnostics",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#mcmc-summary-diagnostics",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "MCMC Summary Diagnostics",
    "text": "MCMC Summary Diagnostics\nWhile the rhat and ess seem good based on what I learned about them in Statistical Rethinking, I decided to apply some further visualisations to ensure the posteriors are well-estimated."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#rhat-visualisation",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#rhat-visualisation",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Rhat Visualisation",
    "text": "Rhat Visualisation\nI find that visualising rhat values for all parameter estimates gives a much clearer sense of whether the chains converged or not, and can help determine whether the chains reached equalibrium.\n\nrhats_fixed &lt;- rhat(COVID_Bayes_0.99, pars = c(\"b_Intercept\", \"b_RP_C\", \"b_PSS_C\", \"b_Anxiety_C\", \"b_Depression_C\"))\n\nrhats_all &lt;- rhat(COVID_Bayes_0.99)\n\n\ncolor_scheme_set(\"brightblue\") # see help(\"color_scheme_set\")\nmcmc_rhat(rhats_fixed) + yaxis_text(hjust = 1)\n\n\n\n\n\n\n\nmcmc_rhat(rhats_all) + yaxis_text(hjust = 1)\n\n\n\n\n\n\n\n\nI have plotted rhat values for only the fixed effects, as well as for all parameter values. It is obvious that all 4 chains reached equalibrium, and thus, the algorithm converged on the target distribution. If it did not, the chains would contain unequal variances between them, and the rhat value would be different from 1. This makes me confident that the final model that uses only 1 chain will converge."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#effective-sample-size-ratio-test",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#effective-sample-size-ratio-test",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Effective Sample Size Ratio Test",
    "text": "Effective Sample Size Ratio Test\nESS tells us the number of independent samples our samples drawn from a non-random dependent sampler are worth. The central limit theorum bounds uncertainty to the sample size, provided the sampling procedure is random. Hamiltonian MCMC conditions each sample on the previous sample, and so the sampling procedure is not truly random. The less random a sampling procedure is, the less independent samples your depedently drawn samples will be worth. Therefore, looking at the ration between ess and samples drawn is a good diagnistic to assess how bad autocorrelation (non-randomness) is. This is important here, as random effects models can greatly increase autocorrelation.\n\nratios_cp_fixed &lt;- neff_ratio(COVID_Bayes_0.99, pars = c(\"b_Intercept\", \"b_RP_C\", \"b_PSS_C\", \"b_Anxiety_C\", \"b_Depression_C\"))\nratios_cp_all &lt;- neff_ratio(COVID_Bayes_0.99)\nmcmc_neff(ratios_cp_fixed, size = 2) + yaxis_text(hjust = 1)\n\n\n\n\n\n\n\nmcmc_neff(ratios_cp_all, size = 2) + yaxis_text(hjust = 1)\n\n\n\n\n\n\n\n\nOverall, these seem ok. I remember Andrew Gelman saying that anything over .1 is fine, although larger ratios are obviously better as it indicates the process is closer to random. This may contribute to autocorrelation (or may be the result of it), but I will look at that in the final model as autocorrelation can be assessed from a single chain."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#final-model",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#final-model",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Final Model",
    "text": "Final Model\nHere I will follow the advice from Statistical Rethinking and only run a single chain for a larger number of samples. I will also not perform the diagnostics above (unless there are serious issues).\n\n# Full COVID model: adaptive delta = 0.99.\nCOVID_Bayes_Model &lt;- brm(SRA_C~ 1 + RP_C + PSS_C + Anxiety_C + Depression_C  + (1+ RP_C + PSS_C + Anxiety_C + Depression_C|Week), data=CVA_Bayes,\n           family = gaussian(),\n           prior = c(\nprior(normal(0, 1), class = Intercept),\nprior(normal(0, 1), class = b, coef = \"RP_C\"),\nprior(normal(0, 1), class = b, coef = \"PSS_C\"),\nprior(normal(0, 1), class = b, coef = \"Anxiety_C\"),\nprior(normal(0, 1), class = b, coef = \"Depression_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = Intercept),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"RP_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"PSS_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Anxiety_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Depression_C\"),\nprior(cauchy(0,2), class = sd),\nprior(lkj_corr_cholesky(1), class = cor),\nprior(cauchy(0, 1), class = sigma)),\nfile = \"C:/Users/STPI0560/Desktop/Website/content/projects/2-covid19-altruism/models/COVID_Bayes_Model.rds\",\niter = 40000, warmup = 2000, cores = 4, chains =1, seed = 123, control = list(adapt_delta = 0.99))\n\nThere appears to be only 34 divergent transitions out of 40,000 samples, which seems excellent."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#autocorrelation",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#autocorrelation",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Autocorrelation",
    "text": "Autocorrelation\nThe lower rhat ratio displayed earlier might indicate some level of autocorrelation that is unwanted. Because each sample from each chain is dependent upon the previous sample, each second draw from the sampling algorithm will obviously be more correlated with the first draw than the third draw is with the first. This should drop off considerably as the distance increases.\n\nmcmc_acf(posterior_cp, pars = c(\"b_Intercept\", \"b_RP_C\", \"b_PSS_C\", \"b_Anxiety_C\", \"b_Depression_C\"), lags = 10)\n\n\n\n\n\n\n\n\nEach row above is a chain, and each column a parameter. Each sample is perfectly correlated with itself (1), and then about 50% correlated with the second dependent draw. This seems to drop off to nearly zero at the 9th or 10th lagged sample. While this is not perfect, I believe that with a large number of samples this should not effect my estimates too much."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#non-hypothesized-predictors-model",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#non-hypothesized-predictors-model",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Non-hypothesized predictors model",
    "text": "Non-hypothesized predictors model\nNext, I wanted to create a model with the other predictors that were collected but not hypothesized: age, gender, employment, and financial situation. My strategy was to fit them in their own model as predictors of SRA, and pull out the predictors that seemed to predict it well. I kept adapt_delta at 0.99 as this worked well in the initial model.\n\n# Full COVID model: adaptive delta = 0.99.\nCOVID_Bayes_2nd_0.99 &lt;- brm(SRA_C~ 1 + Age_C + Gender2 +  Employment  + financ + (1 + Age_C + Gender2 +  Employment  + financ|Week), data=CVA_Bayes,\n           family = gaussian(),\n           prior = c(\nprior(normal(0, 1), class = Intercept),\nprior(cauchy(0, 1), class = sigma)),\nfile = \"C:/Users/STPI0560/Desktop/Website/content/projects/2-covid19-altruism/models/COVID_Bayes_2nd_0.99.rds\",\niter = 25000, warmup = 2000, cores = 4, chains =4, seed = 123, control = list(adapt_delta = 0.99))\n\nAs this is exploratory, I decided to let brm find most priors for me during optimisation. There were also 320 divergent transitions, but because these are discarded anyway, I decided to just see which parameter estimates might be strong enough to warrent inclusion in the final model.\n\n# Create object-cue Markov array for each chain.\nposterior_COVID &lt;- as.array(COVID_Bayes_2nd_0.99$fit)\n\n\ncolor_scheme_set(\"red\")\nmcmc_intervals(  posterior_COVID,\n  pars = c(\"b_Age_C\", \"b_Gender2Male\", \"b_Gender2Other\", \"b_EmploymentStudent\",\"b_EmploymentUnemployed\",\"b_financJustmeetbasicexpenses\",\"b_financLivecomfortably\",\"b_financMeetneedswithsomeleft\", \"sigma\"),\n  prob = 0.95, # 80% intervals\n  prob_outer = 0.99, # 99%\n  point_est = \"mean\"\n)\n\n\n\n\n\n\n\n\nIt is hard to tell here, but age does not overlap with zero. All other parameter estimates seem far more uncertain. Therefore, I decided to include age only in the final model as well."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#final-model-2",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#final-model-2",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Final Model 2",
    "text": "Final Model 2\nUnfortunately, the model became too complex with age as a fixed and random effect. It kept crashing R, and without a more powerful computer to test the model on, I was forced to remove the random effect portion of the age predictor.\n\n# Full COVID model: adaptive delta = 0.99.\nCOVID_Bayes_Model_2 &lt;- brm(SRA_C~ 1 + RP_C + PSS_C + Anxiety_C + Depression_C  + Age_C + (1+ RP_C + PSS_C + Anxiety_C + Depression_C|Week), data=CVA_Bayes,\n           family = gaussian(),\n           prior = c(\nprior(normal(0, 1), class = Intercept),\nprior(normal(0, 1), class = b, coef = \"RP_C\"),\nprior(normal(0, 1), class = b, coef = \"PSS_C\"),\nprior(normal(0, 1), class = b, coef = \"Anxiety_C\"),\nprior(normal(0, 1), class = b, coef = \"Depression_C\"),\n#prior(normal(0, 1), class = b, coef = \"Age_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = Intercept),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"RP_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"PSS_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Anxiety_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Depression_C\"),\nprior(cauchy(0,2), class = sd),\nprior(lkj_corr_cholesky(5), class = cor),\nprior(cauchy(0, 1), class = sigma)),\nfile = \"C:/Users/STPI0560/Desktop/Website/content/projects/2-covid19-altruism/models/COVID_Bayes_Model_2.rds\",\niter = 25000, warmup = 2000, cores = 4, chains =4, seed = 123, control = list(adapt_delta = 0.99))\n\nWith 320 divergent transitions, I decided to increase adapt_delta beyond 0.99 to see if that reduces divergencies.\n\n# Full COVID model: adaptive delta = 0.99.\nCOVID_Bayes_Model_2 &lt;- brm(SRA_C~ 1 + RP_C + PSS_C + Anxiety_C + Depression_C  + Age_C + (1+ RP_C + PSS_C + Anxiety_C + Depression_C|Week), data=CVA_Bayes,\n           family = gaussian(),\n           prior = c(\nprior(normal(0, 1), class = Intercept),\nprior(normal(0, 1), class = b, coef = \"RP_C\"),\nprior(normal(0, 1), class = b, coef = \"PSS_C\"),\nprior(normal(0, 1), class = b, coef = \"Anxiety_C\"),\nprior(normal(0, 1), class = b, coef = \"Depression_C\"),\n#prior(normal(0, 1), class = b, coef = \"Age_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = Intercept),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"RP_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"PSS_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Anxiety_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Depression_C\"),\nprior(cauchy(0,2), class = sd),\nprior(lkj_corr_cholesky(5), class = cor),\nprior(cauchy(0, 1), class = sigma)),\nfile = \"C:/Users/STPI0560/Desktop/Website/content/projects/2-covid19-altruism/models/COVID_Bayes_Model_2.rds\",\niter = 25000, warmup = 2000, cores = 4, chains =4, seed = 123, control = list(adapt_delta = 0.995))\n\nThis seems to have fixed the issue. I’m not going to analyse the source of these divergent transitions as they are low enough to likely be caused by random sharp features of the multivariate parameter space. Below I run the final single-chain model.\n\n# Full COVID model: adaptive delta = 0.99.\nCOVID_Bayes_Model_2_Final &lt;- brm(SRA_C~ 1 + RP_C + PSS_C + Anxiety_C + Depression_C  + Age_C + (1+ RP_C + PSS_C + Anxiety_C + Depression_C|Week), data=CVA_Bayes,\n           family = gaussian(),\n           prior = c(\nprior(normal(0, 1), class = Intercept),\nprior(normal(0, 1), class = b, coef = \"RP_C\"),\nprior(normal(0, 1), class = b, coef = \"PSS_C\"),\nprior(normal(0, 1), class = b, coef = \"Anxiety_C\"),\nprior(normal(0, 1), class = b, coef = \"Depression_C\"),\n#prior(normal(0, 1), class = b, coef = \"Age_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = Intercept),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"RP_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"PSS_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Anxiety_C\"),\nprior(cauchy(0,2), class = sd, group = Week, coef = \"Depression_C\"),\nprior(cauchy(0,2), class = sd),\nprior(lkj_corr_cholesky(5), class = cor),\nprior(cauchy(0, 1), class = sigma)),\nfile = \"C:/Users/STPI0560/Desktop/Website/content/projects/2-covid19-altruism/models/COVID_Bayes_Model_2.rds\",\niter = 40000, warmup = 2000, cores = 4, chains =1, seed = 123, control = list(adapt_delta = 0.995))\n\n\nCOVID_Bayes_Model_Summary &lt;- tidyMCMC(COVID_Bayes_Model_2_Final$fit, conf.int = TRUE, rhat = TRUE, ess = TRUE, conf.level = 0.95,\n              conf.method = \"quantile\", pars = c(\"b_Intercept\", \"b_RP_C\", \"b_PSS_C\",\n                                                 \"b_Anxiety_C\", \"b_Depression_C\", \"b_Age_C\", \"sigma\"))\n\nCOVID_Bayes_Model_Summary\n\n# A tibble: 7 × 7\n  term           estimate std.error conf.low conf.high  rhat   ess\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 b_Intercept    -0.00282    0.158   -0.308     0.313   1.00  8165\n2 b_RP_C          0.150      0.0944  -0.0309    0.330   1.00  8819\n3 b_PSS_C        -0.118      0.106   -0.317     0.0895  1.00 10225\n4 b_Anxiety_C     0.304      0.0932   0.114     0.473   1.00  9984\n5 b_Depression_C -0.136      0.116   -0.353     0.0869  1.00 10093\n6 b_Age_C         0.282      0.0383   0.207     0.357   1.00 32508\n7 sigma           0.908      0.0266   0.858     0.962   1.00 41679\n\n\nWe have very high ess, and rhat values close to 1. Each parameter estimate has changed a bit, but all interpretations remain the same. Age also seems to be an excellent predictor of SRA.\n\n# Create object-cue Markov array for each chain.\nposterior_COVID &lt;- as.array(COVID_Bayes_Model_2_Final$fit)\n\n\ncolor_scheme_set(\"red\")\nmcmc_intervals(  posterior_COVID,\n  pars = c(\"b_RP_C\", \"b_PSS_C\", \"b_Anxiety_C\", \"b_Depression_C\",\"b_Age_C\", \"sigma\"),\n  prob = 0.95, # 80% intervals\n  prob_outer = 0.99, # 99%\n  point_est = \"mean\"\n)"
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#mcmc-traceplots",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#mcmc-traceplots",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "MCMC Traceplots",
    "text": "MCMC Traceplots\n\ncolor_scheme_set(\"mix-blue-red\")\nmcmc_trace(COVID_Bayes_Model_2_Final, pars = c(\"b_Intercept\", \"b_RP_C\", \"b_PSS_C\", \"b_Anxiety_C\", \"b_Depression_C\", \"b_Age_C\", \"sigma\"), facet_args = list(ncol = 1, strip.position = \"left\"))\n\n\n\n\n\n\n\n\nI plotted the traceplots to ensure the chains look like they are sampling from the entire posterior parameter space. According to the plots, this seems to be the case."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#posterior-predictive-check-ppc",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#posterior-predictive-check-ppc",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Posterior Predictive Check (PPC)",
    "text": "Posterior Predictive Check (PPC)\nMcElreath introduces PPC’s early in Statistical Rethinking, and I decided to test them out myself on my final model. Briefly, if a model is a good fit for the data, then we should be able to recover the data that generated the model via random sampling of likelihood distributions generated by parameters randomly sampled from the posterior. By drawing random samples from the posterior and then drawing a random data point from a posterior parameter generated likelihood model, a histogram of posterior-generated data should match the actual distribution of the data that generated the posterior model.\n\ny &lt;- as.numeric(CVA_Bayes$SRA_C)\nyrep &lt;- posterior_predict(COVID_Bayes_Model_2_Final, draws = 500)\n\n\ncolor_scheme_set(\"brightblue\")\nppc_stat(y, yrep, stat = \"mean\")\n\n\n\n\n\n\n\n\nFirst, we can see a histogram of all draws from the likelihood distributions generated by each random parameter draw from the posterior model. I have overlayed the mean value from the dependent variable (Self-Reported Altruism score). It’s clear that the mean lines up near perfectly with the peak of the histogram.\n\ncolor_scheme_set(\"brightblue\")\nppc_dens_overlay(y, yrep[1:50, ])\n\n\n\n\n\n\n\n\nHere I have the entire distribution of self-reported altruism scores in dark blue, with randomly created likelihood distributions generated using random parameter draws from the posterior (light blue). Again, the data are recovered quite nicely from the posterior and match the actual distribution of SRA scores."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#model-comparison",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#model-comparison",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Model Comparison",
    "text": "Model Comparison\nTo use a model comparison approach learned in Statistical Rethinking, I decided to see whether the age model was actually better than the model without age. Below I tried to recreated the waic estimates and graphs from Statistical Rethinking as closely as possible.\n\nCOVID_Bayes_Model &lt;- add_criterion(COVID_Bayes_Model, \"waic\")\nCOVID_Bayes_Model_2_Final &lt;- add_criterion(COVID_Bayes_Model_2_Final, \"waic\")\n\n# compare the WAIC estimates\nw &lt;- loo_compare(COVID_Bayes_Model, COVID_Bayes_Model_2_Final,\n                 criterion = \"waic\")\n\ncbind(waic_diff = w[, 1] * -2,\n      se        = w[, 2] * 2)\n\n                          waic_diff       se\nCOVID_Bayes_Model_2_Final   0.00000  0.00000\nCOVID_Bayes_Model          51.82602 15.07536\n\nmodel_weights(COVID_Bayes_Model, COVID_Bayes_Model_2_Final, \n              weights = \"waic\") %&gt;%\n  as_tibble() %&gt;% \n  rename(weight = value) %&gt;% \n  mutate(model  = c(\"COVID_Bayes_Model\", \"COVID_Bayes_Model_2_Final\"),\n         weight = weight %&gt;% round(digits = 2)) %&gt;% \n  select(model, weight) %&gt;% \n  arrange(desc(weight)) %&gt;% \n  knitr::kable()\n\n\n\n\nmodel\nweight\n\n\n\n\nCOVID_Bayes_Model_2_Final\n1\n\n\nCOVID_Bayes_Model\n0\n\n\n\n\n\nAs can be seen, the model that includes age has 100% of the weighting in its favor.\n\nw[, 7:8] %&gt;% \n  data.frame() %&gt;% \n  rownames_to_column(var = \"model_name\") %&gt;% \n  \n  ggplot(aes(x    = model_name, \n             y    = waic, \n             ymin = waic - se_waic, \n             ymax = waic + se_waic)) +\n  geom_pointrange(shape = 21, color = carto_pal(7, \"BurgYl\")[7], fill = carto_pal(7, \"BurgYl\")[5]) +\n  coord_flip() +\n  labs(x = NULL, y = NULL,\n       title = \"My custom WAIC plot\") +\n  theme_classic() +\n  theme(text             = element_text(family = \"Courier\"),\n        axis.ticks.y     = element_blank(),\n        panel.background = element_rect(fill = alpha(carto_pal(7, \"BurgYl\")[3], 1/4)))\n\n\n\n\n\n\n\n\nHere, the waic scores again suggest that the second model is superior. To me this provides some evidence that this model should be used."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#counterfactual-plots",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#counterfactual-plots",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Counterfactual Plots",
    "text": "Counterfactual Plots\nWhile I might not necessarily inlude these in a normal Bayesian analysis, I decided to try and recreate the counterfactual plots Statistical Rethinking liberally uses. Because I used the brm package, I had to use a slightly different approach.\n\nnd &lt;- \n  tibble(RP_C = seq(from = -5, to = 3, length.out = 601),\n         PSS_C = mean(CVA_Bayes$PSS_C),\n         Anxiety_C = mean(CVA_Bayes$Anxiety_C),\n          Depression_C = mean(CVA_Bayes$Depression_C),\n         Week = CVA_Bayes$Week,\n         Age_C = mean(CVA_Bayes$Age_C))\n\naaaa &lt;- fitted(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n  as_tibble() %&gt;% \n  # since `fitted()` and `predict()` name their intervals the same way, \n  # we'll need to `rename()` them to keep them straight\n  rename(f_ll = Q2.5,\n         f_ul = Q97.5) %&gt;% \n  # note how we're just nesting the `predict()` code right inside `bind_cols()`\n  bind_cols(\n    predict(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n      as_tibble() %&gt;% \n      # since we only need the intervals, we'll use `transmute()` rather than `mutate()`\n      transmute(p_ll = Q2.5,\n                p_ul = Q97.5),\n    # now tack on the `nd` data\n    nd)\n\n\n    # we're finally ready to plot\n  RP_Week1 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 1\", ], aes(x = RP_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 1\",\n       y = \"Self-Reported Altruism\",\n       x = \"RP Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n  RP_Week2 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 2\", ], aes(x = RP_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 2\",\n       y = \"Self-Reported Altruism\",\n       x = \"RP Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n  \n    RP_Week3 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 3\", ], aes(x = RP_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 3\",\n       y = \"Self-Reported Altruism\",\n       x = \"RP Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n    \n  RP_Week4 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 4\", ], aes(x = RP_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 4\",\n       y = \"Self-Reported Altruism\",\n       x = \"RP Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n\nRisk Perception Per Week\n\nRP_Plot &lt;- ggarrange(RP_Week1, RP_Week2, RP_Week3, RP_Week4, ncol = 2, nrow = 2)\nannotate_figure(RP_Plot,\n                top = text_grob(\"Risk Perception\", color = \"black\", face = \"bold\", size = 14))\n\n\n\n\n\n\n\n\n\nnd &lt;- \n  tibble(PSS_C = seq(from = -5, to = 5, length.out = 601),\n         RP_C = mean(CVA_Bayes$RP_C),\n         Anxiety_C = mean(CVA_Bayes$Anxiety_C),\n          Depression_C = mean(CVA_Bayes$Depression_C),\n         Week = CVA_Bayes$Week,\n         Age_C = mean(CVA_Bayes$Age_C))\n\naaaa &lt;- fitted(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n  as_tibble() %&gt;% \n  # since `fitted()` and `predict()` name their intervals the same way, \n  # we'll need to `rename()` them to keep them straight\n  rename(f_ll = Q2.5,\n         f_ul = Q97.5) %&gt;% \n  # note how we're just nesting the `predict()` code right inside `bind_cols()`\n  bind_cols(\n    predict(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n      as_tibble() %&gt;% \n      # since we only need the intervals, we'll use `transmute()` rather than `mutate()`\n      transmute(p_ll = Q2.5,\n                p_ul = Q97.5),\n    # now tack on the `nd` data\n    nd)\n\n\n    # we're finally ready to plot\n  PSS_Week1 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 1\", ], aes(x = PSS_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 1\",\n       y = \"Self-Reported Altruism\",\n       x = \"PSS Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n  PSS_Week2 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 2\", ], aes(x = PSS_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 2\",\n       y = \"Self-Reported Altruism\",\n       x = \"PSS Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n  \n  PSS_Week3 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 3\", ], aes(x = PSS_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 3\",\n       y = \"Self-Reported Altruism\",\n       x = \"PSS Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n    \n  PSS_Week4 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 4\", ], aes(x = PSS_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 4\",\n       y = \"Self-Reported Altruism\",\n       x = \"PSS Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n\n\nPerceived Stress Per Week\n\nPSS_Plot &lt;- ggarrange(PSS_Week1, PSS_Week2, PSS_Week3, PSS_Week4, ncol = 2, nrow = 2)\nannotate_figure(PSS_Plot,\n                top = text_grob(\"Perceived Stress\", color = \"black\", face = \"bold\", size = 14))\n\n\n\n\n\n\n\n\n\nnd &lt;- \n  tibble(Anxiety_C = seq(from = -5, to = 5, length.out = 601),\n         RP_C = mean(CVA_Bayes$RP_C),\n         PSS_C = mean(CVA_Bayes$PSS_C),\n          Depression_C = mean(CVA_Bayes$Depression_C),\n         Week = CVA_Bayes$Week,\n         Age_C = mean(CVA_Bayes$Age_C))\n\naaaa &lt;- fitted(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n  as_tibble() %&gt;% \n  # since `fitted()` and `predict()` name their intervals the same way, \n  # we'll need to `rename()` them to keep them straight\n  rename(f_ll = Q2.5,\n         f_ul = Q97.5) %&gt;% \n  # note how we're just nesting the `predict()` code right inside `bind_cols()`\n  bind_cols(\n    predict(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n      as_tibble() %&gt;% \n      # since we only need the intervals, we'll use `transmute()` rather than `mutate()`\n      transmute(p_ll = Q2.5,\n                p_ul = Q97.5),\n    # now tack on the `nd` data\n    nd)\n\n\n    # we're finally ready to plot\n  Anxiety_Week1 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 1\", ], aes(x = Anxiety_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 1\",\n       y = \"Self-Reported Altruism\",\n       x = \"Anxiety Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n  Anxiety_Week2 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 2\", ], aes(x = Anxiety_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 2\",\n       y = \"Self-Reported Altruism\",\n       x = \"Anxiety Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n  \n    Anxiety_Week3 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 3\", ], aes(x = Anxiety_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 3\",\n       y = \"Self-Reported Altruism\",\n       x = \"Anxiety Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n    \n  Anxiety_Week4 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 4\", ], aes(x = Anxiety_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 4\",\n       y = \"Self-Reported Altruism\",\n       x = \"Anxiety Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n\n\nAnxiety Per Week\n\nAnxiety_Plot &lt;- ggarrange(Anxiety_Week1, Anxiety_Week2, Anxiety_Week3, Anxiety_Week4, ncol = 2, nrow = 2)\nannotate_figure(Anxiety_Plot,\n                top = text_grob(\"Anxiety\", color = \"black\", face = \"bold\", size = 14))\n\n\n\n\n\n\n\n\n\nnd &lt;- \n  tibble(Depression_C = seq(from = -5, to = 5, length.out = 601),\n         RP_C = mean(CVA_Bayes$RP_C),\n         PSS_C = mean(CVA_Bayes$PSS_C),\n          Anxiety_C = mean(CVA_Bayes$Depression_C),\n         Week = CVA_Bayes$Week,\n         Age_C = mean(CVA_Bayes$Age_C))\n\naaaa &lt;- fitted(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n  as_tibble() %&gt;% \n  # since `fitted()` and `predict()` name their intervals the same way, \n  # we'll need to `rename()` them to keep them straight\n  rename(f_ll = Q2.5,\n         f_ul = Q97.5) %&gt;% \n  # note how we're just nesting the `predict()` code right inside `bind_cols()`\n  bind_cols(\n    predict(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n      as_tibble() %&gt;% \n      # since we only need the intervals, we'll use `transmute()` rather than `mutate()`\n      transmute(p_ll = Q2.5,\n                p_ul = Q97.5),\n    # now tack on the `nd` data\n    nd)\n\n\n    # we're finally ready to plot\n  Depression_Week1 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 1\", ], aes(x = Depression_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 1\",\n       y = \"Self-Reported Altruism\",\n       x = \"Depression Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n  Depression_Week2 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 2\", ], aes(x = Depression_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 2\",\n       y = \"Self-Reported Altruism\",\n       x = \"Depression Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n  \n  Depression_Week3 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 3\", ], aes(x = Depression_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 3\",\n       y = \"Self-Reported Altruism\",\n       x = \"Depression Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n    \n  Depression_Week4 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 4\", ], aes(x = Depression_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 4\",\n       y = \"Self-Reported Altruism\",\n       x = \"Depression Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n\n\nDepression Per Week\n\nDepression_Plot &lt;- ggarrange(Depression_Week1, Depression_Week2, Depression_Week3, Depression_Week4, ncol = 2, nrow = 2)\nannotate_figure(Depression_Plot,\n                top = text_grob(\"Depression\", color = \"black\", face = \"bold\", size = 14))\n\n\n\n\n\n\n\n\n\nnd &lt;- \n  tibble(Age_C = seq(from = -5, to = 5, length.out = 601),\n         RP_C = mean(CVA_Bayes$RP_C),\n         PSS_C = mean(CVA_Bayes$PSS_C),\n          Anxiety_C = mean(CVA_Bayes$Depression_C),\n         Depression_C = mean(CVA_Bayes$Depression_C),\n         Week = CVA_Bayes$Week)\n\naaaa &lt;- fitted(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n  as_tibble() %&gt;% \n  # since `fitted()` and `predict()` name their intervals the same way, \n  # we'll need to `rename()` them to keep them straight\n  rename(f_ll = Q2.5,\n         f_ul = Q97.5) %&gt;% \n  # note how we're just nesting the `predict()` code right inside `bind_cols()`\n  bind_cols(\n    predict(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n      as_tibble() %&gt;% \n      # since we only need the intervals, we'll use `transmute()` rather than `mutate()`\n      transmute(p_ll = Q2.5,\n                p_ul = Q97.5),\n    # now tack on the `nd` data\n    nd)\n\n\n    # we're finally ready to plot\n  Age_Week1 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 1\", ], aes(x = Age_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 1\",\n       y = \"Self-Reported Altruism\",\n       x = \"Age Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n  Age_Week2 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 2\", ], aes(x = Age_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 2\",\n       y = \"Self-Reported Altruism\",\n       x = \"Age Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n  \n  Age_Week3 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 3\", ], aes(x = Age_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 3\",\n       y = \"Self-Reported Altruism\",\n       x = \"Age Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n    \n  Age_Week4 &lt;- ggplot(data = aaaa[aaaa$Week == \"Week 4\", ], aes(x = Age_C, y = Estimate)) +\n  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 4\",\n       y = \"Self-Reported Altruism\",\n       x = \"Age Coefficient\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n\n\nAge Per Week\n\nAge_Plot &lt;- ggarrange(Age_Week1, Age_Week2, Age_Week3, Age_Week4, ncol = 2, nrow = 2)\nannotate_figure(Age_Plot,\n                top = text_grob(\"Age\", color = \"black\", face = \"bold\", size = 14))\n\n\n\n\n\n\n\n\n\nnd &lt;- \n  tibble(RP_C = seq(from = -5, to = 3, length.out = 601),\n         PSS_C = mean(CVA_Bayes$PSS_C),\n         Anxiety_C = mean(CVA_Bayes$Anxiety_C),\n          Depression_C = mean(CVA_Bayes$Depression_C),\n         Week = CVA_Bayes$Week,\n         Age_C = mean(CVA_Bayes$Age_C))\n\naaaa &lt;- fitted(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n  as_tibble() %&gt;% \n  # since `fitted()` and `predict()` name their intervals the same way, \n  # we'll need to `rename()` them to keep them straight\n  rename(f_ll = Q2.5,\n         f_ul = Q97.5) %&gt;% \n  # note how we're just nesting the `predict()` code right inside `bind_cols()`\n  bind_cols(\n    predict(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n      as_tibble() %&gt;% \n      # since we only need the intervals, we'll use `transmute()` rather than `mutate()`\n      transmute(p_ll = Q2.5,\n                p_ul = Q97.5),\n    # now tack on the `nd` data\n    nd)\n\n    # we're finally ready to plot\n  RP_Graph_AllWeeks &lt;- ggplot(data = aaaa, aes(x = RP_C, y = Estimate)) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 1\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 1\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 2\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 2\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 3\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 3\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 3\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 3\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 1-4\",\n       y = \"SRA\",\n       x = \"Risk Perception\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n\nnd &lt;- \n  tibble(PSS_C = seq(from = -5, to = 5, length.out = 601),\n         RP_C = mean(CVA_Bayes$RP_C),\n         Anxiety_C = mean(CVA_Bayes$Anxiety_C),\n          Depression_C = mean(CVA_Bayes$Depression_C),\n         Week = CVA_Bayes$Week,\n         Age_C = mean(CVA_Bayes$Age_C))\n\naaaa &lt;- fitted(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n  as_tibble() %&gt;% \n  # since `fitted()` and `predict()` name their intervals the same way, \n  # we'll need to `rename()` them to keep them straight\n  rename(f_ll = Q2.5,\n         f_ul = Q97.5) %&gt;% \n  # note how we're just nesting the `predict()` code right inside `bind_cols()`\n  bind_cols(\n    predict(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n      as_tibble() %&gt;% \n      # since we only need the intervals, we'll use `transmute()` rather than `mutate()`\n      transmute(p_ll = Q2.5,\n                p_ul = Q97.5),\n    # now tack on the `nd` data\n    nd)\n\nPSS_Graph_AllWeeks &lt;- ggplot(data = aaaa, aes(x = PSS_C, y = Estimate)) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 1\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 1\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 2\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 2\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 3\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 3\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 3\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 3\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 1-4\",\n       y = \"SRA\",\n       x = \"Stress\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n\nnd &lt;- \n  tibble(Anxiety_C = seq(from = -5, to = 5, length.out = 601),\n         RP_C = mean(CVA_Bayes$RP_C),\n         PSS_C = mean(CVA_Bayes$PSS_C),\n          Depression_C = mean(CVA_Bayes$Depression_C),\n         Week = CVA_Bayes$Week,\n         Age_C = mean(CVA_Bayes$Age_C))\n\naaaa &lt;- fitted(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n  as_tibble() %&gt;% \n  # since `fitted()` and `predict()` name their intervals the same way, \n  # we'll need to `rename()` them to keep them straight\n  rename(f_ll = Q2.5,\n         f_ul = Q97.5) %&gt;% \n  # note how we're just nesting the `predict()` code right inside `bind_cols()`\n  bind_cols(\n    predict(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n      as_tibble() %&gt;% \n      # since we only need the intervals, we'll use `transmute()` rather than `mutate()`\n      transmute(p_ll = Q2.5,\n                p_ul = Q97.5),\n    # now tack on the `nd` data\n    nd)\n\nAnxiety_Graph_AllWeeks &lt;- ggplot(data = aaaa, aes(x = Anxiety_C, y = Estimate)) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 1\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 1\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 2\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 2\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 3\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 3\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 3\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 3\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 1-4\",\n       y = \"SRA\",\n       x = \"Anxiety\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n\nnd &lt;- \n  tibble(Depression_C = seq(from = -5, to = 5, length.out = 601),\n         RP_C = mean(CVA_Bayes$RP_C),\n         PSS_C = mean(CVA_Bayes$PSS_C),\n          Anxiety_C = mean(CVA_Bayes$Depression_C),\n         Week = CVA_Bayes$Week,\n         Age_C = mean(CVA_Bayes$Age_C))\n\naaaa &lt;- fitted(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n  as_tibble() %&gt;% \n  # since `fitted()` and `predict()` name their intervals the same way, \n  # we'll need to `rename()` them to keep them straight\n  rename(f_ll = Q2.5,\n         f_ul = Q97.5) %&gt;% \n  # note how we're just nesting the `predict()` code right inside `bind_cols()`\n  bind_cols(\n    predict(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n      as_tibble() %&gt;% \n      # since we only need the intervals, we'll use `transmute()` rather than `mutate()`\n      transmute(p_ll = Q2.5,\n                p_ul = Q97.5),\n    # now tack on the `nd` data\n    nd)\n\nDepression_Graph_AllWeeks &lt;- ggplot(data = aaaa, aes(x = Depression_C, y = Estimate)) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 1\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 1\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 2\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 2\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 3\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 3\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 3\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 3\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 1-4\",\n       y = \"SRA\",\n       x = \"Depression\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n\nnd &lt;- \n  tibble(Age_C = seq(from = -5, to = 5, length.out = 601),\n         RP_C = mean(CVA_Bayes$RP_C),\n         PSS_C = mean(CVA_Bayes$PSS_C),\n          Anxiety_C = mean(CVA_Bayes$Depression_C),\n         Week = CVA_Bayes$Week,\n         Depression_C = mean(CVA_Bayes$Depression_C))\n\naaaa &lt;- fitted(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n  as_tibble() %&gt;% \n  # since `fitted()` and `predict()` name their intervals the same way, \n  # we'll need to `rename()` them to keep them straight\n  rename(f_ll = Q2.5,\n         f_ul = Q97.5) %&gt;% \n  # note how we're just nesting the `predict()` code right inside `bind_cols()`\n  bind_cols(\n    predict(COVID_Bayes_Model_2_Final, newdata = nd) %&gt;% \n      as_tibble() %&gt;% \n      # since we only need the intervals, we'll use `transmute()` rather than `mutate()`\n      transmute(p_ll = Q2.5,\n                p_ul = Q97.5),\n    # now tack on the `nd` data\n    nd)\n\nAge_Graph_AllWeeks &lt;- ggplot(data = aaaa, aes(x = Age_C, y = Estimate)) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 1\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 1\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 2\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 2\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 3\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 3\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  geom_ribbon(data = aaaa[aaaa$Week == \"Week 3\", ],aes(ymin = p_ll, ymax = p_ul),\n              fill = \"firebrick\", alpha = 1/5) +\n  geom_smooth(data = aaaa[aaaa$Week == \"Week 3\", ], aes(ymin = f_ll, ymax = f_ul),\n              stat = \"identity\",\n              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n  coord_cartesian(xlim = range(CVA_Bayes$RP_C),\n                  ylim = c(-3, 4)) +\n  labs(subtitle = \"Counterfactual plot: Week 1-4\",\n       y = \"SRA\",\n       x = \"Age\") +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n\n\nCounterfactual Plots: All Weeks Overlayed\n\nAllWeeksPlot &lt;- ggarrange(RP_Graph_AllWeeks, PSS_Graph_AllWeeks, Anxiety_Graph_AllWeeks, Depression_Graph_AllWeeks, Age_Graph_AllWeeks, ncol = 2, nrow = 3)\nannotate_figure(AllWeeksPlot,\n                top = text_grob(\"All Weeks\", color = \"black\", face = \"bold\", size = 14))\n\n\n\n\n\n\n\n\nHere I have overlayed each of the 4 weeks predictions for each parameter to show that they do not change very much from week to week."
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#no-pooling-model",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#no-pooling-model",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "No pooling model",
    "text": "No pooling model\nFirst, I fit a model that does not account for week. This is a no-pooing model because we are averaging over all clusters (i.e. Week).\n\nm_no_pooled_Week1 &lt;- brm(SRA_C~ 1 + RP_C + PSS_C + Anxiety_C + Depression_C  + Age_C, data=CVA_Bayes[CVA_Bayes$Week == \"Week 1\", ],\n           family = gaussian(),\n           prior = c(\nprior(normal(0, 1), class = Intercept),\nprior(normal(0, 1), class = b, coef = \"RP_C\"),\nprior(normal(0, 1), class = b, coef = \"PSS_C\"),\nprior(normal(0, 1), class = b, coef = \"Anxiety_C\"),\nprior(normal(0, 1), class = b, coef = \"Depression_C\"),\n#prior(normal(0, 1), class = b, coef = \"Age_C\"),\nprior(cauchy(0, 1), class = sigma)),\nfile = \"C:/Users/STPI0560/Desktop/Website/content/projects/2-covid19-altruism/models/m_no_pooled_Week1.rds\",\niter = 40000, warmup = 2000, cores = 4, chains =1, seed = 123, control = list(adapt_delta = 0.995))\n\nm_no_pooled_Week2 &lt;- brm(SRA_C~ 1 + RP_C + PSS_C + Anxiety_C + Depression_C  + Age_C, data=CVA_Bayes[CVA_Bayes$Week == \"Week 2\", ],\n           family = gaussian(),\n           prior = c(\nprior(normal(0, 1), class = Intercept),\nprior(normal(0, 1), class = b, coef = \"RP_C\"),\nprior(normal(0, 1), class = b, coef = \"PSS_C\"),\nprior(normal(0, 1), class = b, coef = \"Anxiety_C\"),\nprior(normal(0, 1), class = b, coef = \"Depression_C\"),\n#prior(normal(0, 1), class = b, coef = \"Age_C\"),\nprior(cauchy(0, 1), class = sigma)),\nfile = \"C:/Users/STPI0560/Desktop/Website/content/projects/2-covid19-altruism/models/m_no_pooled_Week2.rds\",\niter = 40000, warmup = 2000, cores = 4, chains =1, seed = 123, control = list(adapt_delta = 0.995))\n\nm_no_pooled_Week3 &lt;- brm(SRA_C~ 1 + RP_C + PSS_C + Anxiety_C + Depression_C  + Age_C, data=CVA_Bayes[CVA_Bayes$Week == \"Week 3\", ],\n           family = gaussian(),\n           prior = c(\nprior(normal(0, 1), class = Intercept),\nprior(normal(0, 1), class = b, coef = \"RP_C\"),\nprior(normal(0, 1), class = b, coef = \"PSS_C\"),\nprior(normal(0, 1), class = b, coef = \"Anxiety_C\"),\nprior(normal(0, 1), class = b, coef = \"Depression_C\"),\n#prior(normal(0, 1), class = b, coef = \"Age_C\"),\nprior(cauchy(0, 1), class = sigma)),\nfile = \"C:/Users/STPI0560/Desktop/Website/content/projects/2-covid19-altruism/models/m_no_pooled_Week3.rds\",\niter = 40000, warmup = 2000, cores = 4, chains =1, seed = 123, control = list(adapt_delta = 0.995))\n\nm_no_pooled_Week4&lt;- brm(SRA_C~ 1 + RP_C + PSS_C + Anxiety_C + Depression_C  + Age_C, data=CVA_Bayes[CVA_Bayes$Week == \"Week 4\", ],\n           family = gaussian(),\n           prior = c(\nprior(normal(0, 1), class = Intercept),\nprior(normal(0, 1), class = b, coef = \"RP_C\"),\nprior(normal(0, 1), class = b, coef = \"PSS_C\"),\nprior(normal(0, 1), class = b, coef = \"Anxiety_C\"),\nprior(normal(0, 1), class = b, coef = \"Depression_C\"),\n#prior(normal(0, 1), class = b, coef = \"Age_C\"),\nprior(cauchy(0, 1), class = sigma)),\nfile = \"C:/Users/STPI0560/Desktop/Website/content/projects/2-covid19-altruism/models/m_no_pooled_Week4.rds\",\niter = 40000, warmup = 2000, cores = 4, chains =1, seed = 123, control = list(adapt_delta = 0.995))\n\n\ndf_no_pooled_Week1 &lt;- data_frame(\n  Model = \"no pooling\",\n  Week = \"Week 1\",\n  Intercept = fixef(m_no_pooled_Week1)[1], \n  Slope_RP_C = fixef(m_no_pooled_Week1)[2],\n  Slope_PSS_C = fixef(m_no_pooled_Week1)[3],\n  Slope_Anxiety_C = fixef(m_no_pooled_Week1)[4],\n  Slope_Depression_C = fixef(m_no_pooled_Week1)[5],\n  Slope_Age_C = fixef(m_no_pooled_Week1)[6])\n\ndf_no_pooled_Week2 &lt;- data_frame(\n  Model = \"no pooling\",\n  Week = \"Week 2\",\n  Intercept = fixef(m_no_pooled_Week2)[1], \n  Slope_RP_C = fixef(m_no_pooled_Week2)[2],\n  Slope_PSS_C = fixef(m_no_pooled_Week2)[3],\n  Slope_Anxiety_C = fixef(m_no_pooled_Week2)[4],\n  Slope_Depression_C = fixef(m_no_pooled_Week2)[5],\n  Slope_Age_C = fixef(m_no_pooled_Week2)[6])\n\ndf_no_pooled_Week3 &lt;- data_frame(\n  Model = \"no pooling\",\n  Week = \"Week 3\",\n  Intercept = fixef(m_no_pooled_Week3)[1], \n  Slope_RP_C = fixef(m_no_pooled_Week3)[2],\n  Slope_PSS_C = fixef(m_no_pooled_Week3)[3],\n  Slope_Anxiety_C = fixef(m_no_pooled_Week3)[4],\n  Slope_Depression_C = fixef(m_no_pooled_Week3)[5],\n  Slope_Age_C = fixef(m_no_pooled_Week3)[6])\n\ndf_no_pooled_Week4 &lt;- data_frame(\n  Model = \"no pooling\",\n  Week = \"Week 4\",\n  Intercept = fixef(m_no_pooled_Week4)[1], \n  Slope_RP_C = fixef(m_no_pooled_Week4)[2],\n  Slope_PSS_C = fixef(m_no_pooled_Week4)[3],\n  Slope_Anxiety_C = fixef(m_no_pooled_Week4)[4],\n  Slope_Depression_C = fixef(m_no_pooled_Week4)[5],\n  Slope_Age_C = fixef(m_no_pooled_Week4)[6])\n\ndf_no_pooling &lt;- rbind(df_no_pooled_Week1, df_no_pooled_Week2, df_no_pooled_Week3, df_no_pooled_Week4)\n\n\n# Full COVID model: adaptive delta = 0.99.\nm_pooled &lt;- brm(SRA_C~ 1 + RP_C + PSS_C + Anxiety_C + Depression_C  + Age_C, data=CVA_Bayes,\n           family = gaussian(),\n           prior = c(\nprior(normal(0, 1), class = Intercept),\nprior(normal(0, 1), class = b, coef = \"RP_C\"),\nprior(normal(0, 1), class = b, coef = \"PSS_C\"),\nprior(normal(0, 1), class = b, coef = \"Anxiety_C\"),\nprior(normal(0, 1), class = b, coef = \"Depression_C\"),\n#prior(normal(0, 1), class = b, coef = \"Age_C\"),\nprior(cauchy(0, 1), class = sigma)),\nfile = \"C:/Users/STPI0560/Desktop/Website/content/projects/2-covid19-altruism/models/m_pooled.rds\",\niter = 40000, warmup = 2000, cores = 4, chains =1, seed = 123, control = list(adapt_delta = 0.995))\n\n# Repeat the intercept and slope terms for each participant\ndf_pooled &lt;- data_frame(\n  Model = \"complete pooling\",\n  Week = unique(CVA_Bayes$Week),\n  Intercept = fixef(m_pooled)[1], \n  Slope_RP_C = fixef(m_pooled)[2],\n  Slope_PSS_C = fixef(m_pooled)[3],\n  Slope_Anxiety_C = fixef(m_pooled)[4],\n  Slope_Depression_C = fixef(m_pooled)[5],\n  Slope_Age_C = fixef(m_pooled)[6])\n\nhead(df_pooled)\n\nlibrary(dplyr)\n\n# create a vector with letters in the desired order\nx &lt;- c(\"Week 1\", \"Week 2\", \"Week 3\", \"Week 4\")\n\ndf_pooled %&gt;%\n  slice(match(x, Week))\n\n\n# Join the raw data so we can use plot the points and the lines.\ndf_models &lt;- bind_rows(df_pooled, df_no_pooling) %&gt;% \n  left_join(CVA_Bayes, by = \"Week\")\n\np_model_comparison_RP &lt;- ggplot(df_models) + \n  aes(x = RP_C, y = SRA_C) + \n  # Set the color mapping in this layer so the points don't get a color\n  geom_abline(aes(intercept = Intercept, slope = Slope_RP_C, color = Model),\n              size = .75) + \n  geom_point() +\n  facet_wrap(~ Week, ncol = 4) +\n  xlab(\"RP_C\") + \n  ylab(\"SRA_C\") +\n  ggtitle(\"RP\")\n\np_model_comparison_RP\n\n\n\n\n\n\n\n# Join the raw data so we can use plot the points and the lines.\ndf_models &lt;- bind_rows(df_pooled, df_no_pooling) %&gt;% \n  left_join(CVA_Bayes, by = \"Week\")\n\np_model_comparison_PSS &lt;- ggplot(df_models) + \n  aes(x = PSS_C, y = SRA_C) + \n  # Set the color mapping in this layer so the points don't get a color\n  geom_abline(aes(intercept = Intercept, slope = Slope_PSS_C, color = Model),\n              size = .75) + \n  geom_point() +\n  facet_wrap(~ Week, ncol = 4) +\n  xlab(\"PSS_C\") + \n  ylab(\"SRA_C\") +\n  ggtitle(\"PSS\")\n\np_model_comparison_PSS\n\n\n\n\n\n\n\n# Join the raw data so we can use plot the points and the lines.\ndf_models &lt;- bind_rows(df_pooled, df_no_pooling) %&gt;% \n  left_join(CVA_Bayes, by = \"Week\")\n\np_model_comparison_Anxiety &lt;- ggplot(df_models) + \n  aes(x = Anxiety_C, y = SRA_C) + \n  # Set the color mapping in this layer so the points don't get a color\n  geom_abline(aes(intercept = Intercept, slope = Slope_RP_C, color = Model),\n              size = .75) + \n  geom_point() +\n  facet_wrap(~ Week, ncol = 4) +\n  xlab(\"Anxiety_C\") + \n  ylab(\"SRA_C\") +\n  ggtitle(\"Anxiety\")\n\np_model_comparison_Anxiety\n\n\n\n\n\n\n\n# Join the raw data so we can use plot the points and the lines.\ndf_models &lt;- bind_rows(df_pooled, df_no_pooling) %&gt;% \n  left_join(CVA_Bayes, by = \"Week\")\n\np_model_comparison_Depression &lt;- ggplot(df_models) + \n  aes(x = Depression_C, y = SRA_C) + \n  # Set the color mapping in this layer so the points don't get a color\n  geom_abline(aes(intercept = Intercept, slope = Slope_RP_C, color = Model),\n              size = .75) + \n  geom_point() +\n  facet_wrap(~ Week, ncol = 4) +\n  xlab(\"Depression_C\") + \n  ylab(\"SRA_C\") +\n  ggtitle(\"Depression\")\n\np_model_comparison_Depression\n\n\n\n\n\n\n\n\nAbove are the parameters estimated from the complete pooling and no pooing models. The complete pooling estimate will be the same for each Week, while the no pooling will differ from week to week. That appears to be the case here.\nNext, I will plot a partially pooled regression line for each week.\n\n# Make a dataframe with the fitted effects\n#df_partial_pooling &lt;- fixef(COVID_Bayes_Model_2_Final)\n\n\nIntercept1 &lt;- coef(COVID_Bayes_Model_2_Final)$Week[, , 1]\nRP_C1 &lt;- coef(COVID_Bayes_Model_2_Final)$Week[, , 2]\nPSS_C1 &lt;- coef(COVID_Bayes_Model_2_Final)$Week[, , 3]\nAnxiety_C1 &lt;- coef(COVID_Bayes_Model_2_Final)$Week[, , 4]\nDepression_C1 &lt;- coef(COVID_Bayes_Model_2_Final)$Week[, , 5]\nAge_C1 &lt;- coef(COVID_Bayes_Model_2_Final)$Week[, , 6]\n\n\n# Repeat the intercept and slope terms for each participant\ndf_partial_pooling  &lt;- data_frame(\n  Model = \"Partial pooling\",\n  Week = unique(CVA_Bayes$Week),\n  Intercept = Intercept1[,1], \n  Slope_RP_C = RP_C1[,1],\n  Slope_PSS_C = PSS_C1[,1],\n  Slope_Anxiety_C = Anxiety_C1[,1],\n  Slope_Depression_C = Depression_C1[,1],\n  Slope_Age_C = Age_C1[,1])\n\n\ndf_models &lt;- bind_rows(df_pooled, df_no_pooling, df_partial_pooling) %&gt;% \n  left_join(CVA_Bayes, by = \"Week\")\n\n# Replace the data-set of the last plot\n\np_model_comparison_RP %+% df_models\n\n\n\n\n\n\n\np_model_comparison_PSS %+% df_models\n\n\n\n\n\n\n\np_model_comparison_Anxiety %+% df_models\n\n\n\n\n\n\n\np_model_comparison_Depression %+% df_models\n\n\n\n\n\n\n\n\nThe partial pooling model is supposed to be a compromise between the two models, and importantly, should shrink the estimates within each Week closer to the overall average parameter value. To see this, we can do a shrinkage plot similar to what McElreath does.\n\n# Also visualize the point for the fixed effects\ndf_fixef &lt;- data_frame(\n  Model = \"Partial pooling (average)\",\n  Intercept = fixef(m_pooled)[1], \n  Slope_RP_C = fixef(m_pooled)[2],\n  Slope_PSS_C = fixef(m_pooled)[3],\n  Slope_Anxiety_C = fixef(m_pooled)[4],\n  Slope_Depression_C = fixef(m_pooled)[5])\n\n# Complete pooling / fixed effects are center of gravity in the plot\ndf_gravity &lt;- df_pooled %&gt;% \n  distinct(Model, Intercept, Slope_RP_C, Slope_PSS_C, Slope_Anxiety_C, Slope_Depression_C) %&gt;% \n  bind_rows(df_fixef)\n#df_gravity"
  },
  {
    "objectID": "content/projects/2-covid19-altruism/2-covid19-altruism.html#shrinkage-plots",
    "href": "content/projects/2-covid19-altruism/2-covid19-altruism.html#shrinkage-plots",
    "title": "Threat Imminence And Everyday Altruism During The COVID-19 Pandemic",
    "section": "Shrinkage Plots",
    "text": "Shrinkage Plots\nBelow are a number of graphs showing how the partial pooling model estimates for each cluster (week) move closer to the average. It should appear as though gravity is pulling the estimates towards a center mass of the graph. For the most part, the graphs reflect this, although there are some instances where they either don’t shrink closer, or even get further away. I’m not sure why that is the case. Perhaps the models are not optomised properly. Still, there generally does seem to be an advantage for using the partial pooled models. Additionally, I am most interested in seeing the slope parameters shrinking towards the global estimate, which is what I see in almost every arrow (meaning, if we ignore the direction on the x-axis, the arrows point closer to the true estimate on the y-axis most of the time). Or, 13/16 arrows point closer to the pooled parameter estimate than further from it.\n\ndf_pulled &lt;- bind_rows(df_no_pooling, df_partial_pooling)\n\nggplot(df_pulled) + \n  aes(x = Intercept, y = Slope_RP_C, color = Model) + \n  geom_point(size = 2) + \n  geom_point(data = df_gravity, size = 5) + \n  # Draw an arrow connecting the observations between models\n  geom_path(aes(group = Week, color = NULL), \n            arrow = arrow(length = unit(.02, \"npc\"))) + \n  # Use ggrepel to jitter the labels away from the points\n  ggrepel::geom_text_repel(\n    aes(label = Week, color = NULL), \n    data = df_no_pooling) + \n  ggrepel::geom_text_repel(\n    aes(label = Week, color = NULL)) + \n  theme(legend.position = \"bottom\") + \n  ggtitle(\"Pooling of regression parameters\") + \n  xlab(\"Intercept estimate\") + \n  ylab(\"RP estimate\") + \n  scale_color_brewer(palette = \"Dark2\") \n\n\n\n\n\n\n\nggplot(df_pulled) + \n  aes(x = Intercept, y = Slope_PSS_C, color = Model) + \n  geom_point(size = 2) + \n  geom_point(data = df_gravity, size = 5) + \n  # Draw an arrow connecting the observations between models\n  geom_path(aes(group = Week, color = NULL), \n            arrow = arrow(length = unit(.02, \"npc\"))) + \n  # Use ggrepel to jitter the labels away from the points\n  ggrepel::geom_text_repel(\n    aes(label = Week, color = NULL), \n    data = df_no_pooling) + \n  ggrepel::geom_text_repel(\n    aes(label = Week, color = NULL)) + \n  theme(legend.position = \"bottom\") + \n  ggtitle(\"Pooling of regression parameters\") + \n  xlab(\"Intercept estimate\") + \n  ylab(\"PSS estimate\") + \n  scale_color_brewer(palette = \"Dark2\") \n\n\n\n\n\n\n\nggplot(df_pulled) + \n  aes(x = Intercept, y = Slope_Anxiety_C, color = Model) + \n  geom_point(size = 2) + \n  geom_point(data = df_gravity, size = 5) + \n  # Draw an arrow connecting the observations between models\n  geom_path(aes(group = Week, color = NULL), \n            arrow = arrow(length = unit(.02, \"npc\"))) + \n  # Use ggrepel to jitter the labels away from the points\n  ggrepel::geom_text_repel(\n    aes(label = Week, color = NULL), \n    data = df_no_pooling) + \n  ggrepel::geom_text_repel(\n    aes(label = Week, color = NULL)) + \n  theme(legend.position = \"bottom\") + \n  ggtitle(\"Pooling of regression parameters\") + \n  xlab(\"Intercept estimate\") + \n  ylab(\"Anxiety estimate\") + \n  scale_color_brewer(palette = \"Dark2\")\n\n\n\n\n\n\n\nggplot(df_pulled) + \n  aes(x = Intercept, y = Slope_Depression_C, color = Model) + \n  geom_point(size = 2) + \n  geom_point(data = df_gravity, size = 5) + \n  # Draw an arrow connecting the observations between models\n  geom_path(aes(group = Week, color = NULL), \n            arrow = arrow(length = unit(.02, \"npc\"))) + \n  # Use ggrepel to jitter the labels away from the points\n  ggrepel::geom_text_repel(\n    aes(label = Week, color = NULL), \n    data = df_no_pooling) + \n  ggrepel::geom_text_repel(\n    aes(label = Week, color = NULL)) + \n  theme(legend.position = \"bottom\") + \n  ggtitle(\"Pooling of regression parameters\") + \n  xlab(\"Intercept estimate\") + \n  ylab(\"Depression estimate\") + \n  scale_color_brewer(palette = \"Dark2\")"
  }
]