{
  "hash": "d6b7f75c5f6eff6e47b4a7a69bf37907",
  "result": {
    "markdown": "---\ntitle: \"April 4 Homework\"\nauthor: \"Stephen Pierzchajlo\"\nformat: html\neditor: visual\n---\n\n\n# Load Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(bayesrules)\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(broom.mixed) \nlibrary(rethinking)\nlibrary(ggpubr)\nlibrary(lme4)\nlibrary(DiagrammeR)\n```\n:::\n\n\n# Exercise 15.3 (Hierarchical data):\n\nThe sleepstudy data is hierarchical. Draw a diagram in the spirit of Figure 15.8 that captures the hierarchical framework. Think: What are the “groups?”\n\nI am using the grVis function from the DiagrammeR package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDiagrammeR::grViz(\"digraph {\nPopulation -> 'Day 0' -> 'rt_11'\n'Day 0' -> 'rt_21'\nPopulation -> 'Day 1' -> 'rt_12'\n'Day 1' -> 'rt_22'\nPopulation -> 'Day 2' -> 'rt_13'\n'Day 2' -> 'rt_23'\nPopulation -> 'Day 3' -> 'rt_14'\n'Day 3' -> 'rt_24'\nPopulation -> 'Day 4' -> 'rt_15'\n'Day 4' -> 'rt_25'\nPopulation -> 'Day 5' -> 'rt_16'\n'Day 5' -> 'rt_26'\nPopulation -> 'Day 6' -> 'rt_17'\n'Day 6' -> 'rt_27'\nPopulation -> 'Day 7' -> 'rt_18'\n'Day 7' -> 'rt_28'\nPopulation -> 'Day 8' -> 'rt_19'\n'Day 8' -> 'rt_29'\nPopulation -> 'Day 9' -> 'rt_110'\n'Day 9' -> 'rt_210'\n}\")\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"grViz html-widget html-fill-item\" id=\"htmlwidget-11f68e0c439025be708f\" style=\"width:100%;height:216px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-11f68e0c439025be708f\">{\"x\":{\"diagram\":\"digraph {\\nPopulation -> \\\"Day 0\\\" -> \\\"rt_11\\\"\\n\\\"Day 0\\\" -> \\\"rt_21\\\"\\nPopulation -> \\\"Day 1\\\" -> \\\"rt_12\\\"\\n\\\"Day 1\\\" -> \\\"rt_22\\\"\\nPopulation -> \\\"Day 2\\\" -> \\\"rt_13\\\"\\n\\\"Day 2\\\" -> \\\"rt_23\\\"\\nPopulation -> \\\"Day 3\\\" -> \\\"rt_14\\\"\\n\\\"Day 3\\\" -> \\\"rt_24\\\"\\nPopulation -> \\\"Day 4\\\" -> \\\"rt_15\\\"\\n\\\"Day 4\\\" -> \\\"rt_25\\\"\\nPopulation -> \\\"Day 5\\\" -> \\\"rt_16\\\"\\n\\\"Day 5\\\" -> \\\"rt_26\\\"\\nPopulation -> \\\"Day 6\\\" -> \\\"rt_17\\\"\\n\\\"Day 6\\\" -> \\\"rt_27\\\"\\nPopulation -> \\\"Day 7\\\" -> \\\"rt_18\\\"\\n\\\"Day 7\\\" -> \\\"rt_28\\\"\\nPopulation -> \\\"Day 8\\\" -> \\\"rt_19\\\"\\n\\\"Day 8\\\" -> \\\"rt_29\\\"\\nPopulation -> \\\"Day 9\\\" -> \\\"rt_110\\\"\\n\\\"Day 9\\\" -> \\\"rt_210\\\"\\n}\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\nI have made a diagram for the first two people. We draw reaction times from each person on each day. So rt_11 is participant 1 on day 0, and rt_21 is participant 2 on day 1.\n\n# Exercise 15.4 (Complete pooling: Part I)\n\nSuppose that we (incorrectly) took a complete pooling approach to modeling Reaction time (Y) by Days of sleep deprivation (X).\n\n## a)\n\nTo explore the complete pooled behavior of the data points, construct and discuss a plot of Reaction by Days. In doing so, ignore the subjects and include the observed trend in the relationship.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(sleepstudy, aes(y = Reaction, x = Days)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output-display}\n![](April4_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nThis plots Day as a function of reaction time. Here we don't account for the individual, so we are violating the assumption that each observation is independently distributed. The line I have fit should have a slope and intercept that match the OLS estimates. However, each day contains multiple observations from the same individual (thus violating independence). This also inflates my degrees of freedom. If I were calculating a p-value, it would be much lower than if I averaged each person's reaction time per day. All of this considered, there is information about each participant we are likely missing. Their may be idiosyncrasies here that are lost because we are treating all observations as independent.\n\n## b)\n\nDraw a diagram in the spirit of Figure 15.8 that captures the complete pooling framework.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDiagrammeR::grViz(\"digraph {\nPopulation -> 'Day 0' -> 'rt_1'\nPopulation -> 'Day 1' -> 'rt_2'\nPopulation -> 'Day 2' -> 'rt_3'\nPopulation -> 'Day 3' -> 'rt_4'\nPopulation -> 'Day 4' -> 'rt_5'\nPopulation -> 'Day 5' -> 'rt_6'\nPopulation -> 'Day 6' -> 'rt_7'\nPopulation -> 'Day 7' -> 'rt_8'\nPopulation -> 'Day 8' -> 'rt_9'\nPopulation -> 'Day 9' -> 'rt_10'\n}\")\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"grViz html-widget html-fill-item\" id=\"htmlwidget-d87fdb87e6aca7c15ea2\" style=\"width:100%;height:325px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-d87fdb87e6aca7c15ea2\">{\"x\":{\"diagram\":\"digraph {\\nPopulation -> \\\"Day 0\\\" -> \\\"rt_1\\\"\\nPopulation -> \\\"Day 1\\\" -> \\\"rt_2\\\"\\nPopulation -> \\\"Day 2\\\" -> \\\"rt_3\\\"\\nPopulation -> \\\"Day 3\\\" -> \\\"rt_4\\\"\\nPopulation -> \\\"Day 4\\\" -> \\\"rt_5\\\"\\nPopulation -> \\\"Day 5\\\" -> \\\"rt_6\\\"\\nPopulation -> \\\"Day 6\\\" -> \\\"rt_7\\\"\\nPopulation -> \\\"Day 7\\\" -> \\\"rt_8\\\"\\nPopulation -> \\\"Day 8\\\" -> \\\"rt_9\\\"\\nPopulation -> \\\"Day 9\\\" -> \\\"rt_10\\\"\\n}\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\nHere we don't account for people, so each reaction time should just be clustered by day.\n\n## c)\n\nUsing careful notation, write out the structure for the complete pooled model of Y by X.\n\n$Y_{i} \\mid \\beta_{0}, \\beta_{1}, \\sigma \\sim N (\\mu_{i}, \\sigma^{2})$ with $\\mu_{i} = \\beta_{0} + \\beta_{1}X_{i}$\n\nAbove, the complete pooled model is saying that each Reaction Time (Yi), conditional on an intercept (B0, reaction time at Day 0), a slope (change in reaction time each day), and a common standard deviation is identically ad independently distributed. Each observation is a conditional mean (ui) such that it is distributed via a Gaussian distribution where the mean depends on the unique day.\n\n# Exercise 15.6 (No pooling: Part I)\n\nSuppose instead that we (incorrectly) took a no pooling approach in our sleep study analysis.\n\n## a)\n\nTo explore the no pooled behavior of the data points, construct and discuss separate scatterplots of Reaction by Days for each Subject, including subject-specific trend lines.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# renumber participants so that looping is easier.\nsleepstudy$numeric <- as.numeric(sleepstudy$Subject)\n# empty dataframe to store unique intercept and slope for each runner.\ncoef_df <- data.frame(\"Subject\" = \"\",\n                      \"intercept\" = \"\",\n                      \"Day\" = \"\")\nfor (i in unique(sleepstudy$numeric)) {\n  temp <- stan_glm(\n    Reaction ~ Days, \n    data = sleepstudy[sleepstudy$numeric == i,], family = gaussian, \n    #prior_intercept = normal(50, 2.5, autoscale = TRUE),\n    prior_aux = exponential(1, autoscale = TRUE),\n    chains = 4, iter = 5000*2, seed = 84735, refresh = 0)\n  temp_df <- data.frame(\"Subject\" = i,\n                        \"intercept\" = temp$coefficients[1],\n                        \"Day\" = temp$coefficients[2])\n  # add runner i's intercept and slope to the ith row of larger dataframe\n  coef_df <- rbind(coef_df, temp_df)\n}\n# coef_df saved all columns as character. Here I resave them as factors/numeric\nbr_no_pool_coef_df <- data.frame(\"Subject\" = as.factor(coef_df$Subject),\n                                 \"intercept\" = as.numeric(coef_df$intercept),\n                                 \"Day\" = as.numeric(coef_df$Day))\n# remove first row (is empty)\nbr_no_pool_coef_df <-  br_no_pool_coef_df[-1, ]\n# reset rowname index to start at 1\nrow.names(br_no_pool_coef_df) <- NULL\n```\n:::\n\n\n### No pooling graph: stan_glm\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# empty list where each runner's graph will be saved.\ntemp_list <- list()  \n# loop through runners, grab their specific intercepts/slope from previous dataframe, and save graph to list\nfor (i in unique(sleepstudy$numeric)) {\n  # runner-specific graph\n  temp_graph <- ggplot(sleepstudy[sleepstudy$numeric == i, ], aes(x = Days, y = Reaction)) + \n    geom_point() +\n    geom_abline(aes_string(intercept = br_no_pool_coef_df[i, 2], slope = br_no_pool_coef_df[i, 3]), color = \"blue\") +\n    ggtitle(paste0(\"Subject \", i)) +\n    ylim(190, 470)\n  # save ith runner graph to temp_list\n  temp_list[[i]] <- temp_graph\n}\n# Use do.call to pass all elements of graph_list to ggarrange\narranged_plots <- do.call(\"ggarrange\", temp_list)\n# Print or display the arranged plots\nprint(arranged_plots)\n```\n\n::: {.cell-output-display}\n![](April4_files/figure-html/unnamed-chunk-6-1.png){width=3000}\n:::\n:::\n\n\nEach person has a different intercept and slope, and non of these are informed by any of the other participants. This makes it a useless model for prediction in the sense that it isn't clear how to use any of these estimates when predicting a new participant's reaction time.\n\n## b)\n\nDraw a diagram in the spirit of Figure 15.6 that captures the no pooling framework.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDiagrammeR::grViz(\"digraph {\nPopulation -> 'Participant 1' -> 'Day 01' -> 'rt_01'\n'Participant 1' -> 'Day 11' -> 'rt_11'\nPopulation -> 'Participant 2' -> 'Day 02' -> 'rt_02'\n'Participant 2' -> 'Day 12' -> 'rt_12'\n}\")\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"grViz html-widget html-fill-item\" id=\"htmlwidget-de772f470091883402cf\" style=\"width:100%;height:216px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-de772f470091883402cf\">{\"x\":{\"diagram\":\"digraph {\\nPopulation -> \\\"Participant 1\\\" -> \\\"Day 01\\\" -> \\\"rt_01\\\"\\n\\\"Participant 1\\\" -> \\\"Day 11\\\" -> \\\"rt_11\\\"\\nPopulation -> \\\"Participant 2\\\" -> \\\"Day 02\\\" -> \\\"rt_02\\\"\\n\\\"Participant 2\\\" -> \\\"Day 12\\\" -> \\\"rt_12\\\"\\n}\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\nI wasn't sure if there was a single right way to do this. Basically, each participant has a reaction time for each day. I have shown the first two days for the first 2 participants. Everything is separate, meaning all coefficients will be estimated seperately.\n\n## c)\n\nUsing careful notation, write out the structure for the no pooled model of Y by X.\n\n$Y_{i} \\mid \\beta_{0i}, \\beta_{1i}, \\sigma_{i} \\sim N (\\mu_{i}, \\sigma_{i}^{2})$ with $\\mu_{i} = \\beta_{0i} + \\beta_{1i}X_{i}$\n\nI believe this is right. Each person will have their own coefficient estimates, so the model must index the beta coefficients as well. I wasn't sure about the standard deviation, but I decided to index it too given each participant will have a different spread of their reaction times. But if that is wrong, then I would update the equation so it does not index the sigma.\n\n# Exercise 15.8 (Complete vs no vs partial pooling)\n\nSuppose we only had data on the two subjects below. For both, provide a loose sketch of three separate trend lines corresponding to a complete pooled, no pooled, and partial pooled model of Reaction time by Days.\n\nFirst, I fit models for all three scenarios.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Complete pooled\nm.15.8_completepool <- stan_glm(Reaction ~ Days, \n                                data = sleepstudy, family = gaussian,\n                                prior_aux = exponential(1, autoscale = TRUE),\n                                chains = 4, iter = 5000*2, seed = 84735, refresh = 0)\n#tidy(m.15.8_completepool, conf.int = TRUE, conf.level = 0.80)\n\n# No pool participant 308\nno_pool_308 <- stan_glm(Reaction ~ Days, \n                                data = sleepstudy[sleepstudy$Subject == 308, ], family = gaussian, \n                                prior_aux = exponential(1, autoscale = TRUE),\n                                chains = 4, iter = 5000*2, seed = 84735, refresh = 0)\n# No pool participant 335\nno_pool_335 <- stan_glm(Reaction ~ Days, \n                                data = sleepstudy[sleepstudy$Subject == 335, ], family = gaussian, \n                                prior_aux = exponential(1, autoscale = TRUE),\n                                chains = 4, iter = 5000*2, seed = 84735, refresh = 0)\n\n# partial pooling\nm.15.8_partial_pool <- stan_glmer(Reaction ~ Days + (1 | Subject), \n                                data = sleepstudy, family = gaussian, \n                                prior_aux = exponential(1, autoscale = TRUE),\n                                chains = 4, iter = 5000*2, seed = 84735, refresh = 0)\n```\n:::\n\n\n## Complete-pooled Trendline\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# complete pool\nggarrange(\n  ggplot(sleepstudy[sleepstudy$Subject == 308, ], aes(x = Days, y = Reaction)) + \n    geom_point() +\n    ggtitle(\"Subject 308\") +\n    ylim(min(sleepstudy$Reaction[sleepstudy$Subject == 308 | sleepstudy$Subject == 335]), max(sleepstudy$Reaction[sleepstudy$Subject == 308 | sleepstudy$Subject == 335])) +\n    geom_abline(aes(intercept = m.15.8_completepool$coefficients[1], slope = m.15.8_completepool$coefficients[2]), color = \"blue\"),\n  ggplot(sleepstudy[sleepstudy$Subject == 335, ], aes(x = Days, y = Reaction)) + \n    geom_point() +\n    ggtitle(\"Subject 335\") +\n    ylim(min(sleepstudy$Reaction[sleepstudy$Subject == 308 | sleepstudy$Subject == 335]), max(sleepstudy$Reaction[sleepstudy$Subject == 308 | sleepstudy$Subject == 335])) +\n    geom_abline(aes(intercept = m.15.8_completepool$coefficients[1], slope = m.15.8_completepool$coefficients[2]), color = \"blue\"),\n  ggplot(sleepstudy[sleepstudy$Subject == 308 | sleepstudy$Subject == 335, ], aes(x = Days, y = Reaction)) + \n    geom_point() +\n    ggtitle(\"Both Subjects\") +\n    ylim(min(sleepstudy$Reaction[sleepstudy$Subject == 308 | sleepstudy$Subject == 335]), max(sleepstudy$Reaction[sleepstudy$Subject == 308 | sleepstudy$Subject == 335])) +\n    geom_abline(aes(intercept = m.15.8_completepool$coefficients[1], slope = m.15.8_completepool$coefficients[2]), color = \"blue\"),\n  ncol = 3\n)\n```\n\n::: {.cell-output-display}\n![](April4_files/figure-html/unnamed-chunk-9-1.png){width=2400}\n:::\n:::\n\n\nWhen we completely pool the data, then the trend line goes exactly through the middle of the pooled data (right graph). However, if we put this trend line through participant 308 and participant 335 individually, the trend line doesn't fit very well. For participant 335, it is even in the wrong direction.\n\n## No-pooled Trendline\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# complete pool\nggarrange(\n  ggplot(sleepstudy[sleepstudy$Subject == 308, ], aes(x = Days, y = Reaction)) + \n    geom_point() +\n    ggtitle(\"Subject 308\") +\n    ylim(min(sleepstudy$Reaction[sleepstudy$Subject == 308 | sleepstudy$Subject == 335]), max(sleepstudy$Reaction[sleepstudy$Subject == 308 | sleepstudy$Subject == 335])) +\n    geom_abline(aes(intercept = no_pool_308$coefficients[1], slope = no_pool_308$coefficients[2]), color = \"blue\"),\n  ggplot(sleepstudy[sleepstudy$Subject == 335, ], aes(x = Days, y = Reaction)) + \n    geom_point() +\n    ggtitle(\"Subject 335\") +\n    ylim(min(sleepstudy$Reaction[sleepstudy$Subject == 308 | sleepstudy$Subject == 335]), max(sleepstudy$Reaction[sleepstudy$Subject == 308 | sleepstudy$Subject == 335])) +\n    geom_abline(aes(intercept = no_pool_335$coefficients[1], slope = no_pool_335$coefficients[2]), color = \"red\"),\n  ggplot(sleepstudy[sleepstudy$Subject == 308 | sleepstudy$Subject == 335, ], aes(x = Days, y = Reaction)) + \n    geom_point() +\n    ggtitle(\"Both Subjects\") +\n    ylim(min(sleepstudy$Reaction[sleepstudy$Subject == 308 | sleepstudy$Subject == 335]), max(sleepstudy$Reaction[sleepstudy$Subject == 308 | sleepstudy$Subject == 335])) +\n    geom_abline(aes(intercept = no_pool_308$coefficients[1], slope = no_pool_308$coefficients[2]), color = \"blue\") +\n    geom_abline(aes(intercept = no_pool_335$coefficients[1], slope = no_pool_335$coefficients[2]), color = \"red\"),\n  ncol = 3\n)\n```\n\n::: {.cell-output-display}\n![](April4_files/figure-html/unnamed-chunk-10-1.png){width=2400}\n:::\n:::\n\n\nNow we have a really well fitting trend line for each individual participant. However, when we look at the pooled data (right graph) we don't have any group level estimate, making prediction of new data impossible.\n\n## Partial-pooled Trendline\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggarrange(\n  ggplot(sleepstudy[sleepstudy$Subject == 308, ], aes(x = Days, y = Reaction)) + \n    geom_point() +\n    ggtitle(\"Subject 308\") +\n    ylim(200, max(sleepstudy$Reaction[sleepstudy$Subject == 308 | sleepstudy$Subject == 335])) +\n    geom_abline(aes(intercept = m.15.8_partial_pool$coefficients[1] + ranef(m.15.8_partial_pool)$Subject[1,1], slope = m.15.8_partial_pool$coefficients[2]), color = \"blue\"),\n  ggplot(sleepstudy[sleepstudy$Subject == 335, ], aes(x = Days, y = Reaction)) + \n    geom_point() +\n    ggtitle(\"Subject 335\") +\n    ylim(200, max(sleepstudy$Reaction[sleepstudy$Subject == 308 | sleepstudy$Subject == 335])) +\n    geom_abline(aes(intercept = m.15.8_partial_pool$coefficients[1] + ranef(m.15.8_partial_pool)$Subject[2,1], slope = m.15.8_partial_pool$coefficients[2]), color = \"blue\"),\n  ggplot(sleepstudy[sleepstudy$Subject == 308 | sleepstudy$Subject == 335, ], aes(x = Days, y = Reaction)) + \n    geom_point() +\n    ggtitle(\"Both Subjects\") +\n    ylim(200, max(sleepstudy$Reaction[sleepstudy$Subject == 308 | sleepstudy$Subject == 335])) +\n    geom_abline(aes(intercept = m.15.8_partial_pool$coefficients[1], slope = m.15.8_partial_pool$coefficients[2]), color = \"blue\"),\n  ncol = 3\n)\n```\n\n::: {.cell-output-display}\n![](April4_files/figure-html/unnamed-chunk-11-1.png){width=2400}\n:::\n:::\n\n\nAll three panels have different intercepts. The slopes are all the same as this is an intercept only model. But now, we can use the trendline on the right graph to make predictions about new data, and we have also accounted for individual differences (first two panels).\n\n# MN1\n\nDo the tadpole simulation from the book (section 13.2), but for another scenario (other true parameters of your choice), and display result as Fig. 13.1 and Fig 13.3. Briefly compare results of your simulation with McElreath’s simulation.\n\nFirst, I am redoing the example from the book to ensure I understand the process and to make sure I am doing it correctly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulation parameters\na_bar <- 1.5\nsigma <- 1.5\nnponds <- 60\nNi <- as.integer(rep( c(5,10,25,35), each = 15))\n# same seed McElreath uses. For reproducibility\nset.seed(5005)\n# sample log odds of survival\na_pond <- rnorm(nponds, mean = a_bar, sd = sigma)\n# simulation dataframe\ndsim <- data.frame( pond=1:nponds , Ni=Ni , true_a=a_pond )\n# Si = number that survived in nth tank\ndsim$Si <- rbinom(nponds, prob = logistic(dsim$true_a), size = dsim$Ni)\n# proportion that survived in nth tank\ndsim$p_nopool <- dsim$Si/dsim$Ni\n# list for regression\ndat <- list(Si=dsim$Si, Ni=dsim$Ni, pond=dsim$pond)\n```\n:::\n\n\nNow I run his multilevel model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# run McElreath's multilevel model\nm13.3 <- ulam(alist(\n  Si ~ dbinom( Ni , p ),\n  logit(p) <- a_pond[pond],\n  a_pond[pond] ~ dnorm( a_bar , sigma ),\n  a_bar ~ dnorm( 0 , 1.5 ),\n  sigma ~ dexp( 1 )),\n  data = dat, chains = 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 sequential chains, with 1 thread(s) per chain...\n\nChain 1 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 1 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 1 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 1 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 1 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 1 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 1 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 1 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 1 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 1 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 1 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 1 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 1 finished in 0.4 seconds.\nChain 2 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 2 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 2 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 2 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 2 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 2 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 2 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 2 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 2 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 2 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 2 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 2 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 2 finished in 0.3 seconds.\nChain 3 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 3 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 3 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 3 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 3 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 3 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 3 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 3 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 3 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 3 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 3 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 3 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 3 finished in 0.3 seconds.\nChain 4 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 4 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 4 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 4 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 4 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 4 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 4 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 4 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 4 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 4 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 4 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 4 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 4 finished in 0.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.3 seconds.\nTotal execution time: 2.4 seconds.\n```\n:::\n:::\n\n\nNow I calculate various things for plotting\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Smaple posterior for each pond. Each column is a pond, each row is a sample from that pond's posterior\npost <- extract.samples(m13.3)\ndsim$propsurv.est <- logistic( apply( post$a_pond , 2 , mean ) )\n# mean posterior probability of survival in each tank\ndsim$p_partpool <- apply(inv_logit(post$a_pond), 2, mean)\n# true proportion of survival in each tank\ndsim$p_true <- inv_logit(dsim$true_a)\n# difference between no pooling estimates and true survival rate in each tank\nnopool_error <- abs(dsim$p_nopool - dsim$p_true)\n# difference between partial pooling estimates and true survival rate in each tank\npartpool_error <- abs( dsim$p_partpool - dsim$p_true )\n# average no pooling survival per tank group\nnopool_avg <- aggregate(nopool_error,list(dsim$Ni),mean)\n# average partial pooling survival per group\npartpool_avg <- aggregate(partpool_error,list(dsim$Ni),mean)\n```\n:::\n\n\nNote: blue = no pool black = partial pool Now, I plot the error of each tank's estimates (partial pooling average distance from true survival and no pooling average distance from true survival)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# average partial pooling survival per group\npartpool_avg <- aggregate(partpool_error,list(dsim$Ni),mean)\nplot(1:60, ylim = c(0,1), dsim$p_true, xlab=\"pond\", ylab=\"proportion survival\", col = rangi2, pch = 16)\npoints(1:60 , dsim$propsurv.est)\n# mark posterior mean probability across tanks\nabline( h=mean(inv_logit(post$a_bar)) , lty=2 )\nabline(v = 15.5 , lwd = 0.5)\nabline(v = 30.5 , lwd = 0.5)\nabline(v = 45.5 , lwd = 0.5)\n```\n\n::: {.cell-output-display}\n![](April4_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# average partial pooling survival per group\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(1:60, nopool_error, xlab=\"pond\", ylab=\"absolute error\", col = rangi2, pch = 16)\npoints(1:60 , partpool_error)\nabline(v = 15.5 , lwd = 0.5)\nabline(v = 30.5 , lwd = 0.5)\nabline(v = 45.5 , lwd = 0.5)\nsegments(x0 = -2, x1 = 15, y0 = nopool_avg[1,2], y1 = nopool_avg[1,2], lwd = 2, lty = 3, col = rangi2)\nsegments(x0 = -2, x1 = 15, y0 = partpool_avg[1,2], y1 = partpool_avg[1,2], lwd = 2, lty = 3, col = \"black\")\nsegments(x0 = 15, x1 = 30, y0 = nopool_avg[2,2], y1 = nopool_avg[2,2], lwd = 2, lty = 3, col = rangi2)\nsegments(x0 = 15, x1 = 30, y0 = partpool_avg[2,2], y1 = partpool_avg[2,2], lwd = 2, lty = 3, col = \"black\")\nsegments(x0 = 30, x1 = 45, y0 = nopool_avg[3,2], y1 = nopool_avg[3,2], lwd = 2, lty = 3, col = rangi2)\nsegments(x0 = 30, x1 = 45 ,y0 = partpool_avg[3,2], y1 = partpool_avg[3,2], lwd = 2, lty = 3, col = \"black\")\nsegments(x0 = 45 ,x1 = 60, y0 = nopool_avg[4,2], y1 = nopool_avg[4,2], lwd = 2, lty = 3, col = rangi2)\nsegments(x0 = 45 ,x1 = 60, y0 = partpool_avg[4,2], y1 = partpool_avg[4,2], lwd = 2, lty = 3, col = \"black\")\n```\n\n::: {.cell-output-display}\n![](April4_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nNo pooling in blue, partial pooling in black. There is more absolute error in no pooling in the smaller ponds.\n\nNow, I will try with high survival and low variance\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulation parameters\na_bar <- 4\nsigma <- .5\nnponds <- 60\nNi <- as.integer(rep( c(5,10,25,35), each = 15))\n# same seed McElreath uses. For reproducibility\nset.seed(1234)\n# sample log odds of survival\na_pond <- rnorm(nponds, mean = a_bar, sd = sigma)\n# simulation dataframe\ndsim <- data.frame( pond=1:nponds , Ni=Ni , true_a=a_pond )\n# Si = number that survived in nth tank\ndsim$Si <- rbinom(nponds, prob = logistic(dsim$true_a), size = dsim$Ni)\n# proportion that survived in nth tank\ndsim$p_nopool <- dsim$Si/dsim$Ni\n# list for regression\ndat <- list(Si=dsim$Si, Ni=dsim$Ni, pond=dsim$pond)\n```\n:::\n\n\nNow I run his multilevel model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# run McElreath's multilevel model\nhigh_surviv_low_variance <- ulam(alist(\n  Si ~ dbinom( Ni , p ),\n  logit(p) <- a_pond[pond],\n  a_pond[pond] ~ dnorm( a_bar , sigma ),\n  a_bar ~ dnorm( 0 , 1.5 ),\n  sigma ~ dexp( 1 )),\n  data = dat, chains = 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 sequential chains, with 1 thread(s) per chain...\n\nChain 1 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 1 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 1 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 1 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 1 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 1 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 1 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 1 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 1 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 1 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 1 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 1 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 1 finished in 0.3 seconds.\nChain 2 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 2 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 2 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 2 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 2 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 2 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 2 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 2 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 2 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 2 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 2 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 2 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 2 finished in 0.4 seconds.\nChain 3 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 3 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 3 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 3 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 3 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 3 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 3 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 3 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 3 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 3 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 3 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 3 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 3 finished in 0.3 seconds.\nChain 4 Iteration:   1 / 1000 [  0%]  (Warmup) \nChain 4 Iteration: 100 / 1000 [ 10%]  (Warmup) \nChain 4 Iteration: 200 / 1000 [ 20%]  (Warmup) \nChain 4 Iteration: 300 / 1000 [ 30%]  (Warmup) \nChain 4 Iteration: 400 / 1000 [ 40%]  (Warmup) \nChain 4 Iteration: 500 / 1000 [ 50%]  (Warmup) \nChain 4 Iteration: 501 / 1000 [ 50%]  (Sampling) \nChain 4 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 4 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 4 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 4 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 4 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 4 finished in 0.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.3 seconds.\nTotal execution time: 2.4 seconds.\n```\n:::\n:::\n\n\nNow I calculate various things for plotting\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Smaple posterior for each pond. Each column is a pond, each row is a sample from that pond's posterior\npost <- extract.samples(high_surviv_low_variance)\ndsim$propsurv.est <- logistic( apply( post$a_pond , 2 , mean ) )\n# mean posterior probability of survival in each tank\ndsim$p_partpool <- apply(inv_logit(post$a_pond), 2, mean)\n# true proportion of survival in each tank\ndsim$p_true <- inv_logit(dsim$true_a)\n# difference between no pooling estimates and true survival rate in each tank\nnopool_error <- abs(dsim$p_nopool - dsim$p_true)\n# difference between partial pooling estimates and true survival rate in each tank\npartpool_error <- abs( dsim$p_partpool - dsim$p_true )\n# average no pooling survival per tank group\nnopool_avg <- aggregate(nopool_error,list(dsim$Ni),mean)\n# average partial pooling survival per group\npartpool_avg <- aggregate(partpool_error,list(dsim$Ni),mean)\n```\n:::\n\n\nNote: blue = no pool black = partial pool Now, I plot the error of each tank's estimates (partial pooling average distance from true survival and no pooling average distance from true survival)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# average partial pooling survival per group\npartpool_avg <- aggregate(partpool_error,list(dsim$Ni),mean)\ndsim$propsurv.est <- logistic( apply( post$a_bar , 2 , mean ) )\nplot(1:60, ylim = c(0,1), dsim$p_true, xlab=\"pond\", ylab=\"proportion survival\", col = rangi2, pch = 16)\npoints(1:60 , dsim$propsurv.est)\n# mark posterior mean probability across tanks\nabline( h=mean(inv_logit(post$a_bar)) , lty=2 )\nabline(v = 15.5 , lwd = 0.5)\nabline(v = 30.5 , lwd = 0.5)\nabline(v = 45.5 , lwd = 0.5)\n```\n\n::: {.cell-output-display}\n![](April4_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nBecause we have such high survivability and such low variance, most partial pool estimates are very similar to the no pooled estimates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(1:60, nopool_error, xlab=\"pond\", ylab=\"absolute error\", col = rangi2, pch = 16)\npoints(1:60 , partpool_error)\nabline(v = 15.5 , lwd = 0.5)\nabline(v = 30.5 , lwd = 0.5)\nabline(v = 45.5 , lwd = 0.5)\nsegments(x0 = -2, x1 = 15, y0 = nopool_avg[1,2], y1 = nopool_avg[1,2], lwd = 2, lty = 3, col = rangi2)\nsegments(x0 = -2, x1 = 15, y0 = partpool_avg[1,2], y1 = partpool_avg[1,2], lwd = 2, lty = 3, col = \"black\")\nsegments(x0 = 15, x1 = 30, y0 = nopool_avg[2,2], y1 = nopool_avg[2,2], lwd = 2, lty = 3, col = rangi2)\nsegments(x0 = 15, x1 = 30, y0 = partpool_avg[2,2], y1 = partpool_avg[2,2], lwd = 2, lty = 3, col = \"black\")\nsegments(x0 = 30, x1 = 45, y0 = nopool_avg[3,2], y1 = nopool_avg[3,2], lwd = 2, lty = 3, col = rangi2)\nsegments(x0 = 30, x1 = 45 ,y0 = partpool_avg[3,2], y1 = partpool_avg[3,2], lwd = 2, lty = 3, col = \"black\")\nsegments(x0 = 45 ,x1 = 60, y0 = nopool_avg[4,2], y1 = nopool_avg[4,2], lwd = 2, lty = 3, col = rangi2)\nsegments(x0 = 45 ,x1 = 60, y0 = partpool_avg[4,2], y1 = partpool_avg[4,2], lwd = 2, lty = 3, col = \"black\")\n```\n\n::: {.cell-output-display}\n![](April4_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\nBecause we have high survival and low variance, I would expect very similar results between no pooling and partial pooing. The results here show very little variance in the smaller tanks compared to McElreath's example. The difference looks bigger, but the absolute error is smaller (it's just the scale of this y-axis versus the previous one). This shows that when we have smaller variance, the no-pool estimates actually do an ok job.\n",
    "supporting": [
      "April4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\r\n<script src=\"site_libs/viz-1.8.2/viz.js\"></script>\r\n<link href=\"site_libs/DiagrammeR-styles-0.2/styles.css\" rel=\"stylesheet\" />\r\n<script src=\"site_libs/grViz-binding-1.0.11/grViz.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}