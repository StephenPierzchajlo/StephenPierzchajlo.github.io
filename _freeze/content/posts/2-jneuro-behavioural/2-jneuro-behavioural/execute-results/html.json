{
  "hash": "f5389533b3743d2f31109fdfc0ebaf66",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Journal Of Neuroscience: Bayesian Reanalysis\"\nauthor: \"Stephen Pierzchajlo\"\nformat: \n  html:\n    self-contained: true\neditor: visual\n---\n\n\n# Project Overview\n\nThe data I am analysing comes from a paper I recently published in the Journal Of Neuroscience (https://www.jneurosci.org/content/44/22/e1232232024). The paper involves 3 experiments, of which I am only analysing data from the first. I have chosen this study because I actually wanted to do a Bayesian analysis originally, and wanted to do a random effects model as well. We opted for a Frequentist analysis and a 3-way ANOVA. Here I will perform the same analyses using a Bayesian random-effects model.\n\n## Short Introduction\n\nPeople are notoriously bad at identifying odors. Herrick (1993) noted that the olfactory cortex of most species is large, relative to other areas, and it is only in humans that the olfactory epithelium becomes dwarfed by the neocortex. This is likely do to evolution favoring cognitive capabilities, along with senses more important to our lives, like vision. Herrick hypothesized that, because the human olfactory cortex still contains dense interconnectivity with other sensory modalities, that maybe olfaction relies on other senses to help with olfactory identification and localization. Additionally, a recent study found that when people describe different types of sensory stimuli, all but olfaction are described abstractly (i.e. bright). Olfactory stimuli alone Are described as object-based (i.e. lemon).\n\n## Participant Information\n\nAfter removing some participants for poor performance, this dataset includes 63 participants (40 female; age range: 18-65; mean age: 32 years) total.\n\n## Hypotheses\n\nWe developed a behavioural task where people listened to a predictive cue, were presented with a target, and then had to determine whether the cue and target matched or did not match. The cue was delivered by a voice, and the target was either visual or olfactory. The cue could also be object-based (i.e. lemon) or category-based (i.e. fruit). The targets consisted of 4 stimuli: lavender, lilac, lemon, pear. These could be presented both visually and in an olfactory manner. We hypothesized that, if olfaction requires information from another sensory modality, that their would be a large disparity in reaction time between matching (congruent) and non-matching (incongruent) cues and targets. We further hypothesized that this disparity would not be seen when the targets were visual. We also hypothesized that, in olfaction, this disparity would be larger when the cues were object-based, rather than category based.\n\n## Predictions\n\nTheir are several predictions that are important for this assignment. First, we predicted much slower responses to olfactory targets. We also predicted participants would be slower at responding when cues and targets did not match. We further predicted that this slowness in responding to cues and targets that were incongruent would be larger when the targets were olfactory. Finally, we predicted that, in olfaction, people would respond more slowly to incongruent cues/targets whe nthe cues were object-based.\n\n# Set Up Workspace\n\nHere I am just initializing my workspace.\n\n## Load Global Environment\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load variables that are saved outside R\nload(\"C:/Users/STPI0560/Desktop/Archieve/Stat 2.5/assignment/workspace/assignmentworkspace.RData\")\n```\n:::\n\n\n## Load Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load libraries\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(brms)\nlibrary(bayesplot)\nlibrary(tidybayes) \nlibrary(ggpubr)\nlibrary(gridExtra)\n```\n:::\n\n\n## Set ggplot Theme And Color Scheme\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set ggplot theme\ntheme_set(theme_minimal())\n# set ggplot colors\ncolors <- c(\"#d1e1ec\", \"#b3cde0\", \"#6497b1\", \"#005b96\", \"#03396c\", \"#011f4b\")\n```\n:::\n\n\n# The Data\n\n## Example Dataframe\n\nBelow is an example for how one participants' data might look. These data are fake, but provide an overview for how the data are organized.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fill dataframe with fake values for one participant\nfaketable <- data.frame(\n  row = c(1, 2, 3, 4, \"...\", 44, 45, 46, 47, \"...\", 82, 83, 84, 85, \"...\", 127, 128, 129, 130),\n  subject = c(rep(1, times = 4), \"...\", rep(1, times = 4), \"...\", rep(1, times = 4), \"...\", rep(1, times = 4)),\n  modality = c(rep(\"visual\", times = 4), \"...\", rep(\"visual\", times = 4), \"...\", rep(\"olfactory\", times = 4), \"...\", rep(\"olfactory\", times = 4)),\n  congruency = c(rep(c(\"congruent\", \"incongruent\"), times = 2), \"...\",rep(c(\"congruent\", \"incongruent\"), times = 2), \"...\", rep(c(\"congruent\", \"incongruent\"), times = 2), \"...\",rep(c(\"congruent\", \"incongruent\"), times = 2)),\n  cue_type = c(rep(\"object\", time = 4), \"...\", rep(\"category\", times = 4), \"...\", rep(\"object\", time = 4), \"...\", rep(\"category\", times = 4)),\n  auditory_cue = c(\"lavender\", \"lilac\", \"lemon\", \"pear\", \"...\", \"flower\", \"flower\", \"fruit\", \"fruit\", \"...\", \"lavender\", \"lilac\", \"lemon\", \"pear\", \"...\", \"flower\", \"flower\", \"fruit\", \"fruit\"),\n  target = c(\"lavender\", \"lavender\", \"lemon\", \"lemon\", \"...\", \"lavender\", \"pear\", \"lemon\", \"lilac\", \"...\", \"lavender\", \"lavender\", \"lemon\", \"lemon\", \"...\", \"lavender\", \"pear\", \"lemon\", \"lilac\"),\n  reaction_time = c(564, 740, 602, 557, \"...\", 471, 649, 668, 519, \"...\", 1121, 1576, 1844, 1343, \"...\", 1876, 1265, 1721, 1846)\n  )\n# display fake dataframe with nice kable styling\nfaketable %>%\n  kbl(caption = \"Example dataframe\") %>%\n  kable_classic(full_width = F, html_font = \"Cambria\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style=\"font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Example dataframe</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> row </th>\n   <th style=\"text-align:left;\"> subject </th>\n   <th style=\"text-align:left;\"> modality </th>\n   <th style=\"text-align:left;\"> congruency </th>\n   <th style=\"text-align:left;\"> cue_type </th>\n   <th style=\"text-align:left;\"> auditory_cue </th>\n   <th style=\"text-align:left;\"> target </th>\n   <th style=\"text-align:left;\"> reaction_time </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> visual </td>\n   <td style=\"text-align:left;\"> congruent </td>\n   <td style=\"text-align:left;\"> object </td>\n   <td style=\"text-align:left;\"> lavender </td>\n   <td style=\"text-align:left;\"> lavender </td>\n   <td style=\"text-align:left;\"> 564 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> visual </td>\n   <td style=\"text-align:left;\"> incongruent </td>\n   <td style=\"text-align:left;\"> object </td>\n   <td style=\"text-align:left;\"> lilac </td>\n   <td style=\"text-align:left;\"> lavender </td>\n   <td style=\"text-align:left;\"> 740 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> visual </td>\n   <td style=\"text-align:left;\"> congruent </td>\n   <td style=\"text-align:left;\"> object </td>\n   <td style=\"text-align:left;\"> lemon </td>\n   <td style=\"text-align:left;\"> lemon </td>\n   <td style=\"text-align:left;\"> 602 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> visual </td>\n   <td style=\"text-align:left;\"> incongruent </td>\n   <td style=\"text-align:left;\"> object </td>\n   <td style=\"text-align:left;\"> pear </td>\n   <td style=\"text-align:left;\"> lemon </td>\n   <td style=\"text-align:left;\"> 557 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 44 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> visual </td>\n   <td style=\"text-align:left;\"> congruent </td>\n   <td style=\"text-align:left;\"> category </td>\n   <td style=\"text-align:left;\"> flower </td>\n   <td style=\"text-align:left;\"> lavender </td>\n   <td style=\"text-align:left;\"> 471 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 45 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> visual </td>\n   <td style=\"text-align:left;\"> incongruent </td>\n   <td style=\"text-align:left;\"> category </td>\n   <td style=\"text-align:left;\"> flower </td>\n   <td style=\"text-align:left;\"> pear </td>\n   <td style=\"text-align:left;\"> 649 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 46 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> visual </td>\n   <td style=\"text-align:left;\"> congruent </td>\n   <td style=\"text-align:left;\"> category </td>\n   <td style=\"text-align:left;\"> fruit </td>\n   <td style=\"text-align:left;\"> lemon </td>\n   <td style=\"text-align:left;\"> 668 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 47 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> visual </td>\n   <td style=\"text-align:left;\"> incongruent </td>\n   <td style=\"text-align:left;\"> category </td>\n   <td style=\"text-align:left;\"> fruit </td>\n   <td style=\"text-align:left;\"> lilac </td>\n   <td style=\"text-align:left;\"> 519 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 82 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> olfactory </td>\n   <td style=\"text-align:left;\"> congruent </td>\n   <td style=\"text-align:left;\"> object </td>\n   <td style=\"text-align:left;\"> lavender </td>\n   <td style=\"text-align:left;\"> lavender </td>\n   <td style=\"text-align:left;\"> 1121 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 83 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> olfactory </td>\n   <td style=\"text-align:left;\"> incongruent </td>\n   <td style=\"text-align:left;\"> object </td>\n   <td style=\"text-align:left;\"> lilac </td>\n   <td style=\"text-align:left;\"> lavender </td>\n   <td style=\"text-align:left;\"> 1576 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 84 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> olfactory </td>\n   <td style=\"text-align:left;\"> congruent </td>\n   <td style=\"text-align:left;\"> object </td>\n   <td style=\"text-align:left;\"> lemon </td>\n   <td style=\"text-align:left;\"> lemon </td>\n   <td style=\"text-align:left;\"> 1844 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 85 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> olfactory </td>\n   <td style=\"text-align:left;\"> incongruent </td>\n   <td style=\"text-align:left;\"> object </td>\n   <td style=\"text-align:left;\"> pear </td>\n   <td style=\"text-align:left;\"> lemon </td>\n   <td style=\"text-align:left;\"> 1343 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 127 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> olfactory </td>\n   <td style=\"text-align:left;\"> congruent </td>\n   <td style=\"text-align:left;\"> category </td>\n   <td style=\"text-align:left;\"> flower </td>\n   <td style=\"text-align:left;\"> lavender </td>\n   <td style=\"text-align:left;\"> 1876 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 128 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> olfactory </td>\n   <td style=\"text-align:left;\"> incongruent </td>\n   <td style=\"text-align:left;\"> category </td>\n   <td style=\"text-align:left;\"> flower </td>\n   <td style=\"text-align:left;\"> pear </td>\n   <td style=\"text-align:left;\"> 1265 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 129 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> olfactory </td>\n   <td style=\"text-align:left;\"> congruent </td>\n   <td style=\"text-align:left;\"> category </td>\n   <td style=\"text-align:left;\"> fruit </td>\n   <td style=\"text-align:left;\"> lemon </td>\n   <td style=\"text-align:left;\"> 1721 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 130 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> olfactory </td>\n   <td style=\"text-align:left;\"> incongruent </td>\n   <td style=\"text-align:left;\"> category </td>\n   <td style=\"text-align:left;\"> fruit </td>\n   <td style=\"text-align:left;\"> lilac </td>\n   <td style=\"text-align:left;\"> 1846 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Load Data\n\nThe data I am using is a single .csv file from our previous experiment. These data were pre-processed in a separate R script that took each individual participants' data and combined them into a single dataframe. The data are not aggregated, so they still represent the participants' raw data. However, 5 participants were removed for having very low accuracy in the task. Additionally, we were only interested in trials where participants' correctly determined whether the cue and target matched/did not match. Thus, these data only represent \"correct\" trials. Additionally, all participants' in this dataset had at least 80% accuracy across the study.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load data\ndf <- read.csv(file = \"C:/Users/STPI0560/Desktop/Archieve/Stat 2.5/assignment/data/object_category.csv\", header = TRUE)\n# glimpse first few rows\nhead(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  participant modality  congruency cue_type      cue   target reaction_time\n1         101   visual incongruent   object     Pear Lavender     1933.3277\n2         101   visual   congruent   object     Pear     Pear      400.3761\n3         101   visual   congruent   object    Lemon    Lemon      500.3686\n4         101   visual incongruent   object    Lilac     Pear      833.7295\n5         101   visual   congruent   object    Lilac    Lilac      533.7733\n6         101   visual   congruent   object Lavender Lavender      883.7940\n```\n\n\n:::\n:::\n\n\nSome columns need to be changed to factors for the analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Columns to convert to factors\ncols_to_factor <- c(\"participant\", \"modality\", \"congruency\", \"cue_type\", \"cue\", \"target\")\n# Convert specified columns to factors\ndf[cols_to_factor] <- lapply(df[cols_to_factor], as.factor)\n```\n:::\n\n\nFirst, I wanted to plot the distribution of the dependent variable (reaction time) for both visual and olfactory target trials. This is because reaction time is often skewed. If the distributions are indeed skewed, I may want to model them using an Exgaussian distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add mean lines\nggplot(df, aes(x=reaction_time, fill = modality)) +\n  geom_histogram(bins = 100)+\n  theme(legend.position=\"top\") +\n  scale_fill_manual(values = c(colors[2], colors[5]))\n```\n\n::: {.cell-output-display}\n![](2-jneuro-behavioural_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nThey definitely appear skewed. Thus, I will take that into account with my model. However, I want to try both an Exgaussian and Gaussian model. I will then see how well each model recovers the distribution of the dependent variable using a Posterior Predictive Check (PPC).\n\n# Bayesian Hierarchical Model\n\nThis model will be a 3-way factorial design. Originally we did not want to have a 3-way design as we believed we would be underpowered to detect a 3-way interaction. However, a reviewer insisted on adopting this approach. Thus, to match the original study, I will do that here. Here I want to see how target modality (visual, olfactory), cue/target congruency (congruent, incongruent), and cue-type (object-cue, category-cue) affect reaction time. Most importantly, I will look at the 2-way interaction between modality and congruency, and the 3-way interaction between modality, congruency, and cue-type.\n\nI want to add a random intercept and random slopes for each target and each participant in the model. I believe my model should look something like what I have outlined below.\n\n#### Notations\n\n-   $Y_{ijk}$ : Reaction time for participant $i$, condition $j$, target $k$.\n-   $M_j$: Modality.\n-   $C_j$: Congruency.\n-   $T_j$: Cue_type.\n-   ${Target}_k$: Target.\n\n#### Parameters\n\n-   $\\beta_0$: Intercept.\n-   $\\beta_1$: Coefficient for modality $M$.\n-   $\\beta_2$: Coefficient for congruency $C$.\n-   $\\beta_3$: Coefficient for cue_type $T$.\n-   $\\beta_{12}$: Coefficient for $M \\times C$.\n-   $\\beta_{13}$: Coefficient for $M \\times T$.\n-   $\\beta_{23}$: Coefficient for $C \\times T$.\n-   $\\beta_{123}$: Coefficient for $M \\times C \\times T$.\n\n#### Random Effects\n\n-   $u_{0i}$: Random intercept for participant $i$.\n-   $u_{1i}$: Random slope for target $k$ by participant $i$.\n\n#### Model Equation\n\nThe full model equation is:\n\n$Y_{ijk} = \\beta_0 + \\beta_1 M_j + \\beta_2 C_j + \\beta_3 T_j + \\beta_{12} (M_j \\cdot C_j) + \\beta_{13} (M_j \\cdot T_j) + \\beta_{23} (C_j \\cdot T_j) + \\beta_{123} (M_j \\cdot C_j \\cdot T_j) + u_{0i} + u_{1i} \\text{Target}_k + \\epsilon_{ijk}$\n\n#### Priors\n\n-   Coefficients:\n    -   $\\beta_0 \\sim \\mathcal{N}(1200, 200)$\n    -   $\\beta_1 \\sim \\mathcal{N}(500, 100)$\n    -   $\\beta_2 \\sim \\mathcal{N}(200, 50)$\n    -   $\\beta_3 \\sim \\mathcal{N}(100, 50)$\n    -   $\\beta_{12}, \\beta_{13}, \\beta_{23}, \\beta_{123} \\sim \\mathcal{N}(0, 1)$\n-   Random effects:\n    -   $(u_{0i}, u_{1i})^T \\sim \\mathcal{N}(0, \\Sigma_u)$\n    -   $Sigma_u$ is the covariance matrix of the random effects, where $\\Sigma_u \\sim \\text{LKJ}(2)$\n\n#### Residual Error\n\n-   $\\epsilon_{ijk} \\sim \\mathcal{N}(0, \\sigma^2)$\n\nWhere $\\text{ExGaussian}(\\mu, \\sigma, \\tau)$ denotes the ex-Gaussian distribution with: - $\\mu$: Mean of the normal component. - $\\sigma$: Standard deviation of the normal component. - $\\tau$: Mean of the exponential component.\n\nAdditionally, $\\text{Gaussian}(\\mu, \\sigma)$ denotes the Gaussian distribution with: - $\\mu$: Mean of the normal component. - $\\sigma$: Standard deviation of the normal component.\n\nThe ex-Gaussian distribution combines a normal distribution with parameters $\\mu$ and $\\sigma$, and an exponential distribution with parameter $\\tau$. The Guassian distribution does not include the parameter $\\tau$. I am using both the Gaussian and ex-Gaussian distribution to model reaction time.\n\n## Gaussian model\n\n### Prior Predictive Check.\n\nI want to use informative priors for my model as I have already conducted several other similar studies and have several ideas about how reaction times will differ between different conditions. My original plan was to conduct a Prior Predictive Check to see how my informative priors would generate reaction time data. However, this proved too difficult and time consuming. The Prior Predictive Check gave estimates of some pararmeters in the millions, while also having very low effective sample sizes (ess). Some of the ess values were as low as 20, even with 4 chains running for 10,000 iterations. I think the model is simply to complex for the number of iterations I would need to run for stable estimates. Therefore, I will be going ahead without a Prior Predictive Check.\n\n### Informative Priors\n\nI decided to use informative priors as I have run several studies looking at modality and congruency regarding vision and olfaction. Those have been outlined in the Notation section above. I did not put informative priors on the interaction terms however, because it is very hard to predict exactly how they will turn out.\n\n### Fitting Gaussian Model in brm\n\nFirst, I estimated the 3-way factorial model using a Gaussian distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# run Gaussian model in brm\ngaussian_model <- brm(\n  reaction_time ~ modality*congruency*cue_type + (target|participant),\n  data = df,\n  family = gaussian(),\n  prior = c(prior(normal(1200, 200), class = Intercept),\n            prior(normal(500, 100), class = b, coef = \"modalityvisual\"),\n            prior(normal(200, 50), class = b, coef = \"congruencyincongruent\"),\n            prior(normal(100, 50), class = b, coef = \"cue_typeobject\"),\n            prior(cauchy(0, 2), class = sd),\n            prior(cauchy(0, 2), class = sigma),\n            prior(lkj(2), class = cor)),\n  iter  = 6000,\n  warmup = 2000,\n  file = \"C:/Users/STPI0560/Desktop/Archieve/Stat 2.5/assignment/models/gaussian_model\"\n  )\n```\n:::\n\n\n## Exgaussian Model\n\nNext, I run an Exgaussian model. Everything is identical to the Gaussian model otherwise.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# run Exgaussian model in brm\nexgaussian_model <- brm(\n  reaction_time ~ modality*congruency*cue_type + (target|participant),\n  data = df,\n  family = exgaussian(),\n  prior = c(prior(normal(1200, 200), class = Intercept),\n            prior(normal(500, 100), class = b, coef = \"modalityvisual\"),\n            prior(normal(200, 50), class = b, coef = \"congruencyincongruent\"),\n            prior(normal(100, 50), class = b, coef = \"cue_typeobject\"),\n            prior(cauchy(0, 2), class = sd),\n            prior(cauchy(0, 2), class = sigma),\n            prior(lkj(2), class = cor)),\n  iter  = 6000,\n  warmup = 2000, \n  file = \"C:/Users/STPI0560/Desktop/Archieve/Stat 2.5/assignment/models/exgaussian_model\",\n  )\n```\n:::\n\n\nUsing informative priors with the Exgaussian model led to sever errors, with R-hat values over 3 and ess values as low as 5. Not shown here, I ran another Exgaussian model where I used the default priors brm gives you. This model did well, so I will use it from here.\n\n## Model Comparison\n\nMy plan was to first compare these models using the loo function. However, due to their complexity, I would need to redo both models and save the parameters as the models go. I have done this before and know it would take at least twice as long to run (sometimes longer). Given that the Exgaussian model took more than a day to complete, I just don't have time. Instead I will let the PPC below guide my model selection.\n\n# Posterior Predictive Checks\n\nNow that I have the two models, I want to see how each one recovers the dependent variable. I will perform a PPC on both models to see.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get reaction time distribution\ny <- df$reaction_time\n# Draw 500 reaction time distributions from Gaussian model\nyrep <- posterior_predict(gaussian_model, draws = 500)\n# Draw 500 reaction time distributions from Exgaussian model\nyrep_exgaus <- posterior_predict(exgaussian_model, draws = 500)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# set color scheme\ncolor_scheme_set(\"brightblue\")\n# gaussian ppc graph\ngaussian_ppc <- ppc_dens_overlay(y, yrep[1:50, ]) + ggtitle(\"Gaussian PPC\")\n# exgaussian ppc graph\nexgaussian_ppc <- ppc_dens_overlay(y, yrep_exgaus[1:50, ]) + ggtitle(\"Exgaussian PPC\")\n# Arrange the plots side by side\ngrid.arrange(gaussian_ppc, exgaussian_ppc, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](2-jneuro-behavioural_files/figure-html/unnamed-chunk-11-1.png){width=2400}\n:::\n:::\n\n\nNeither model recovers the dependent variable perfectly, perhaps due to its bimodal nature. I would actually say that the Guassian performs slightly better here as it undershoots the first large bump (visual target peak responses), but almost matches the second smaller bump. The Exgaussian model overshoots the first bump, and then undershoots the second. I could standardize the predictors which might help with this fit. However, I do not actually like interpreting standardized coefficients since their are additional mental steps you need to take to understand the output. I would prefer to work with the unstandardized predictors, even if the PPC is not perfect.\n\nI can also see how well the ppc recovers the mean reaction time split by different groups. I decided to check how well each model can represent the two means for modality, congruency, and cue-type.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make 6 graphs, 3 for Guassian and 3 for Exgaussian\ngaussian_modality_ppc <- ppc_stat_grouped(y, yrep[1:1000, ], group = df$modality, stat = \"mean\") + ggtitle(\"Gaussian PPC\")\nexgaussian_modality_ppc <- ppc_stat_grouped(y, yrep_exgaus[1:1000, ], group = df$modality, stat = \"mean\") + ggtitle(\"Exgaussian PPC\")\ngaussian_congruency_ppc <- ppc_stat_grouped(y, yrep[1:1000, ], group = df$congruency, stat = \"mean\") + ggtitle(\"Gaussian PPC\")\nexgaussian_congruency_ppc <- ppc_stat_grouped(y, yrep_exgaus[1:1000, ], group = df$congruency, stat = \"mean\") + ggtitle(\"Exgaussian PPC\")\ngaussian_cuetype_ppc <- ppc_stat_grouped(y, yrep[1:1000, ], group = df$cue_type, stat = \"mean\") + ggtitle(\"Gaussian PPC\")\nexgaussian_cuetype_ppc <- ppc_stat_grouped(y, yrep_exgaus[1:1000, ], group = df$cue_type, stat = \"mean\") + ggtitle(\"Exgaussian PPC\")\n\n# plot the 6 graphs in a 3 x 2 grid\ngrid.arrange(gaussian_modality_ppc, exgaussian_modality_ppc,\n             gaussian_congruency_ppc, exgaussian_congruency_ppc,\n             gaussian_cuetype_ppc, exgaussian_cuetype_ppc,\n             ncol = 2, nrow = 3)\n```\n\n::: {.cell-output-display}\n![](2-jneuro-behavioural_files/figure-html/unnamed-chunk-12-1.png){width=3000}\n:::\n:::\n\n\nIt's pretty clear that the Exgaussian model does not recover the dependent variable very well. Thus, I will continue the analysis using the Guassian model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# remove ppc variables (they take up a lot of space)\nrm(y)\nrm(yrep)\nrm(yrep_exgaus)\n```\n:::\n\n\n# Gaussian Model Diagnostics check\n\n## MCMC Traceplots\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmcmc_trace(gaussian_model, pars = c(\"b_Intercept\", \"b_modalityvisual\", \"b_congruencyincongruent\", \"b_cue_typeobject\", \"b_modalityvisual:congruencyincongruent\", \"b_modalityvisual:cue_typeobject\", \"b_congruencyincongruent:cue_typeobject\", \"b_modalityvisual:congruencyincongruent:cue_typeobject\", \"sigma\"), \n           facet_args = list(ncol = 2, strip.position = \"left\"))\n```\n\n::: {.cell-output-display}\n![](2-jneuro-behavioural_files/figure-html/unnamed-chunk-14-1.png){width=2700}\n:::\n:::\n\n\nAll chains had Rhat values of 1, so I know they converged. This just gives a bit more visual evidence of that.\n\n# Gaussian Model Fixed Effect Estimates\n\nBefore looking at outputs, I want to discuss the model summary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# select fixed-effects\ngaussian_summary <- fixef(gaussian_model)\n# display fake dataframe with nice kable styling\ngaussian_summary %>%\n  kbl(caption = \"Fixed-effect summary\") %>%\n  kable_classic(full_width = F, html_font = \"Cambria\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style=\"font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Fixed-effect summary</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Estimate </th>\n   <th style=\"text-align:right;\"> Est.Error </th>\n   <th style=\"text-align:right;\"> Q2.5 </th>\n   <th style=\"text-align:right;\"> Q97.5 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Intercept </td>\n   <td style=\"text-align:right;\"> 1763.80622 </td>\n   <td style=\"text-align:right;\"> 40.74753 </td>\n   <td style=\"text-align:right;\"> 1682.65982 </td>\n   <td style=\"text-align:right;\"> 1844.08140 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> modalityvisual </td>\n   <td style=\"text-align:right;\"> -1176.19344 </td>\n   <td style=\"text-align:right;\"> 13.88879 </td>\n   <td style=\"text-align:right;\"> -1203.60028 </td>\n   <td style=\"text-align:right;\"> -1149.00212 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> congruencyincongruent </td>\n   <td style=\"text-align:right;\"> 109.16309 </td>\n   <td style=\"text-align:right;\"> 13.97318 </td>\n   <td style=\"text-align:right;\"> 81.54296 </td>\n   <td style=\"text-align:right;\"> 136.55348 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> cue_typeobject </td>\n   <td style=\"text-align:right;\"> -118.04836 </td>\n   <td style=\"text-align:right;\"> 13.74276 </td>\n   <td style=\"text-align:right;\"> -144.70101 </td>\n   <td style=\"text-align:right;\"> -90.69817 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> modalityvisual:congruencyincongruent </td>\n   <td style=\"text-align:right;\"> -53.85335 </td>\n   <td style=\"text-align:right;\"> 19.57608 </td>\n   <td style=\"text-align:right;\"> -92.02107 </td>\n   <td style=\"text-align:right;\"> -15.15032 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> modalityvisual:cue_typeobject </td>\n   <td style=\"text-align:right;\"> 67.15566 </td>\n   <td style=\"text-align:right;\"> 19.52747 </td>\n   <td style=\"text-align:right;\"> 28.77962 </td>\n   <td style=\"text-align:right;\"> 105.27742 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> congruencyincongruent:cue_typeobject </td>\n   <td style=\"text-align:right;\"> -4.88533 </td>\n   <td style=\"text-align:right;\"> 19.87079 </td>\n   <td style=\"text-align:right;\"> -43.57404 </td>\n   <td style=\"text-align:right;\"> 33.98897 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> modalityvisual:congruencyincongruent:cue_typeobject </td>\n   <td style=\"text-align:right;\"> 15.12504 </td>\n   <td style=\"text-align:right;\"> 27.86762 </td>\n   <td style=\"text-align:right;\"> -38.99643 </td>\n   <td style=\"text-align:right;\"> 69.25071 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nFirst, participants were 1176ms faster at responding to visual targets than they are olfactory targets. Participants are 109ms slower at responding to targets that do not match (incongruent) the cue compared to targets that do match (congruent) the cue. Participants are 118ms faster at responding to targets when an object-based cue precedes it compared to when a category cue precedes it. Participants are 54ms slower at responding to incongruent cue/target presentations, but only when the target is olfactory. The other effects overlap quite substantially with zero, so I will not go into detail regarding those. Additionally, all Rhat values were 1, and the effective sample sizes were very large. Below I display the full summary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(gaussian_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: reaction_time ~ modality * congruency * cue_type + (target | participant) \n   Data: df (Number of observations: 11476) \n  Draws: 4 chains, each with iter = 6000; warmup = 2000; thin = 1;\n         total post-warmup draws = 16000\n\nMultilevel Hyperparameters:\n~participant (Number of levels: 64) \n                             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)                  258.65     24.50   216.31   311.55 1.00     2907\nsd(targetLemon)                 81.51     14.36    54.02   110.53 1.00     2563\nsd(targetLilac)                103.74     14.65    76.74   133.59 1.00     2361\nsd(targetPear)                  51.47     29.29     0.37    94.40 1.00      455\ncor(Intercept,targetLemon)      -0.15      0.17    -0.46     0.20 1.00     2577\ncor(Intercept,targetLilac)      -0.06      0.17    -0.37     0.27 1.00     1796\ncor(targetLemon,targetLilac)     0.77      0.11     0.51     0.93 1.00     3562\ncor(Intercept,targetPear)       -0.15      0.24    -0.56     0.45 1.00     6762\ncor(targetLemon,targetPear)      0.32      0.29    -0.44     0.73 1.00     1442\ncor(targetLilac,targetPear)      0.31      0.28    -0.44     0.71 1.00     1679\n                             Tail_ESS\nsd(Intercept)                    5437\nsd(targetLemon)                  6648\nsd(targetLilac)                  8877\nsd(targetPear)                   1565\ncor(Intercept,targetLemon)       7532\ncor(Intercept,targetLilac)       6575\ncor(targetLemon,targetLilac)     7012\ncor(Intercept,targetPear)        2309\ncor(targetLemon,targetPear)      1839\ncor(targetLilac,targetPear)      1696\n\nRegression Coefficients:\n                                                    Estimate Est.Error l-95% CI\nIntercept                                            1763.81     40.75  1682.66\nmodalityvisual                                      -1176.19     13.89 -1203.60\ncongruencyincongruent                                 109.16     13.97    81.54\ncue_typeobject                                       -118.05     13.74  -144.70\nmodalityvisual:congruencyincongruent                  -53.85     19.58   -92.02\nmodalityvisual:cue_typeobject                          67.16     19.53    28.78\ncongruencyincongruent:cue_typeobject                   -4.89     19.87   -43.57\nmodalityvisual:congruencyincongruent:cue_typeobject    15.13     27.87   -39.00\n                                                    u-95% CI Rhat Bulk_ESS\nIntercept                                            1844.08 1.00      847\nmodalityvisual                                      -1149.00 1.00    11091\ncongruencyincongruent                                 136.55 1.00    11029\ncue_typeobject                                        -90.70 1.00    11197\nmodalityvisual:congruencyincongruent                  -15.15 1.00    10397\nmodalityvisual:cue_typeobject                         105.28 1.00     9408\ncongruencyincongruent:cue_typeobject                   33.99 1.00    10806\nmodalityvisual:congruencyincongruent:cue_typeobject    69.25 1.00     9653\n                                                    Tail_ESS\nIntercept                                               2107\nmodalityvisual                                         12780\ncongruencyincongruent                                  12235\ncue_typeobject                                         13101\nmodalityvisual:congruencyincongruent                   12388\nmodalityvisual:cue_typeobject                          12467\ncongruencyincongruent:cue_typeobject                   12816\nmodalityvisual:congruencyincongruent:cue_typeobject    12229\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma   385.21      2.66   380.06   390.50 1.00    15627    11084\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\nNext I am calculating all possible estimated reaction times from the model depending on modality, congruency, and cue type. I am not going into detail below about why certain reaction time estimates are the result of specific combinations of coefficients. Hopefully it will be obvious based on whether each categorical predictor represents 0 or 1.\n\nolfactory congruent category = $\\beta_{0}$ = 1763.81\n\nvisual congruent category = $\\beta_{0} + \\beta_{1}x_{i1}$ = 1763.81 + (-1176.19) = 587.62\n\nolfactory incongruent category = $\\beta_{0} + \\beta_{2}x_{i2}$ = 1763.81 + 109.16 = 1872.97\n\nvisual incongruent category = $\\beta_{0} + \\beta_{1}x_{i1} + \\beta_{2}x_{i2} + \\beta_{4}x_{i1}x_{i2}$ = 1763.81 + (-1176.19) + 109.16 + (-53.85) = 642.93\n\nolfactory congruent object = $\\beta_{0} + \\beta_{3}x_{i3}$ = 1763.81 + (-118.05) = 1645.76\n\nvisual congruent object = $\\beta_{0} + \\beta_{1}x_{i1} + \\beta_{3}x_{i3} + \\beta_{5}x_{i1}x_{i3}$ = 1763.81 + (-1176.19) + (-118.05) + 67.16 = 536.73\n\nolfactory incongruent object = $\\beta_{0} + \\beta_{2}x_{i2} + \\beta_{3}x_{i3} + \\beta_{6}x_{i2}x_{i3}$ = 1763.81 + 109.16 + (-118.05) + -4.89 = 1750.03\n\nvisual incongruent object = $\\beta_{0} + \\beta_{1}x_{i1} + \\beta_{2}x_{i2} + \\beta_{3}x_{i3} + \\beta_{4}x_{i1}x_{i2} + \\beta_{5}x_{i1}x_{i3} + \\beta_{6}x_{i2}x_{i3} + \\beta_{7}x_{i1}x_{i2}x_{i3}$ = 1763.81 + (-1176.19) + 109.16 + (-118.05) + (-53.85) + 67.16 + -4.89 + 15.13 = 602.28\n\nNow that I have my reaction time estimates, I will make a dataframe and then plot it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make coefficients dataframe\ncoefficient_dataframe <- data.frame(\n  \"modality\" = c(\"olfactory\", \"olfactory\", \"olfactory\", \"olfactory\", \"visual\", \"visual\", \"visual\", \"visual\"),\n  \"congruency\" = c(\"congruent\", \"congruent\", \"incongruent\", \"incongruent\", \"congruent\", \"congruent\", \"incongruent\", \"incongruent\"),\n  \"cue_type\" = c(\"category\", \"object\", \"category\", \"object\", \"category\", \"object\", \"category\", \"object\"),\n  \"reaction_time\" = c(1763.81, 1645.76, 1872.97, 1750.03, 587.62, 536.73, 642.93, 602.28)\n  )\n```\n:::\n\n\nBelow I am plotting the estimated fixed effect coefficients.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot coefficients\nggplot(coefficient_dataframe, aes(x = modality, y = reaction_time, fill = congruency, group = congruency, color = congruency)) +\n  geom_point() +\n  geom_line() +\n  facet_wrap(~cue_type) +\n  scale_color_manual(values = c(colors[2], colors[4]))\n```\n\n::: {.cell-output-display}\n![](2-jneuro-behavioural_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nOlfactory trials are clearly much slower than visual trials. When the cue and target match (are congruent), people are also faster at responding. The main effect of cue-type is a bit harder to see, but it is apparant that people are faster at responding when cues are object-based. The two-way interaction between modality and congruency is also visible: The disparity between congruent and incongruent responses is larger when the target is olfactory (relative to visual).\n\nOne thing to not is that this graph might be a bit misleading. Visually, because there is such a large difference between visual and olfactory reaction times (about 1200ms), it is hard to see smaller effects. Additionally, this is a within-subjects design. Therefore, what matters is individual differences between factors, and this can be hard to see too. I will try to plot things out and explain them in a more intuitive way below.\n\n# Plot Posterior Estimates\n\n## Fixed Effects\n\nHere I am taking all draws from all markov chains for all parameters and plotting a histogram of them. I will also take the model estimates and credible intervals and plot those under the histogram.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make posterior draws dataframe\ndraws_posterior <- gaussian_model |>\n  # select coefficients\n  spread_draws(b_Intercept, b_modalityvisual, b_congruencyincongruent, b_cue_typeobject, `b_modalityvisual:congruencyincongruent`, `b_modalityvisual:congruencyincongruent:cue_typeobject`) |>\n  # new column called \"posterior\"\n  mutate(distribution = \"posterior\")\n```\n:::\n\n\n### Main Effects\n\nBelow I plot the posterior distributions for the main fixed effects.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# graph of modality\nmodality_main_graph <- ggplot(draws_posterior, aes(x = b_modalityvisual)) +\n  geom_histogram(binwidth = 0.75, position = \"identity\", color = colors[3], fill = colors[3]) +\n  geom_point(aes(x = fixef(gaussian_model)[2, 1], y = 0), colour = \"black\", size = 3) +\n  geom_segment(aes(x = fixef(gaussian_model)[2, 3], y = 0, xend = fixef(gaussian_model)[2, 4], yend = 0), size = 1, color = \"black\") +\n  ggtitle(\"Main Effect: Modality\") +\n  labs(x = \"Vision - Olfaction\",y = \"\") +\n  theme(axis.title = element_text(size = 9, face = \"bold\"),\n        plot.title = element_text(size = 11))\n\n# graph of congruency\ncongruency_main_graph <- ggplot(draws_posterior, aes(x = b_congruencyincongruent)) +\n  geom_histogram(binwidth = 0.75, position = \"identity\", color = colors[3], fill = colors[3]) +\n  geom_point(aes(x = fixef(gaussian_model)[3, 1], y = 0), colour = \"black\", size = 3) +\n  geom_segment(aes(x = fixef(gaussian_model)[3, 3], y = 0, xend = fixef(gaussian_model)[3, 4], yend = 0), size = 1, color = \"black\") +\n  ggtitle(\"Main Effect: Congruency\") +\n  labs(x = \"Incongruent - Congruent\",y = \"\") +\n  theme(axis.title = element_text(size = 9, face = \"bold\"),\n        plot.title = element_text(size = 11))\n\n# graph of cue-type\ncuetype_main_graph <- ggplot(draws_posterior, aes(x = b_cue_typeobject)) +\n  geom_histogram(binwidth = 0.75, position = \"identity\", color = colors[3], fill = colors[3]) +\n  geom_point(aes(x = fixef(gaussian_model)[4, 1], y = 0), colour = \"black\", size = 3) +\n  geom_segment(aes(x = fixef(gaussian_model)[4, 3], y = 0, xend = fixef(gaussian_model)[4, 4], yend = 0), size = 1, color = \"black\") +\n  ggtitle(\"Main Effect: Cue Type\") +\n  labs(x = \"Object-Cue - Category-Cue\",y = \"\") +\n  theme(axis.title = element_text(size = 9, face = \"bold\"),\n        plot.title = element_text(size = 11))\n\n# arrange graphs beside one another\nggarrange(modality_main_graph, congruency_main_graph, cuetype_main_graph, ncol = 3)\n```\n\n::: {.cell-output-display}\n![](2-jneuro-behavioural_files/figure-html/unnamed-chunk-20-1.png){width=3000}\n:::\n:::\n\n\nFirst, visual trials are 1176ms faster than olfactory trials. Because olfactory trials are the intercept (1764ms), visual trials are estimated to be approximately 588ms. This is a very big difference, but not surprising as it takes longer to process an odor compared to a visual stimulus. Next, incongruent trials are 109ms slower than congruent trials. So people tend to respond more slowly when the auditory cue and target do not match. Finally, people are 118ms faster at responding to targets when the cue is object-based rather than category-based.\n\nCentral to our main hypothesis, we were interested in whether the congruency effect (people responding slower when the cue and target did not match) was larger for olfactory target trials compared to visual target trials.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# graph of modality x congruency posterior\ncongruency_modality_graph <- ggplot(draws_posterior, aes(x = `b_modalityvisual:congruencyincongruent`)) +\n  geom_histogram(binwidth = 0.75, position = \"identity\", color = colors[3], fill = colors[3]) +\n  geom_point(aes(x = fixef(gaussian_model)[5, 1], y = 0), colour = \"black\", size = 3) +\n  geom_segment(aes(x = fixef(gaussian_model)[5, 3], y = 0, xend = fixef(gaussian_model)[5, 4], yend = 0), size = 1, color = \"black\") +\n  ggtitle(\"Interaction: Modality x Congruency\") +\n  xlab(\"\") +\n  ylab(\"\") +\n  theme(axis.title = element_text(size = 9, face = \"bold\"),\n        plot.title = element_text(size = 11))\n\ncongruency_modality_cuetype_graph <- ggplot(draws_posterior, aes(x = `b_modalityvisual:congruencyincongruent:cue_typeobject`)) +\n  geom_histogram(binwidth = 0.75, position = \"identity\", color = colors[3], fill = colors[3]) +\n  geom_point(aes(x = fixef(gaussian_model)[8, 1], y = 0), colour = \"black\", size = 3) +\n  geom_segment(aes(x = fixef(gaussian_model)[8, 3], y = 0, xend = fixef(gaussian_model)[8, 4], yend = 0), size = 1, color = \"black\") +\n  ggtitle(\"Interaction: Modality x Congruency x Cue-Type\") +\n  xlab(\"\") +\n  ylab(\"\") +\n  theme(axis.title = element_text(size = 9, face = \"bold\"),\n        plot.title = element_text(size = 11))\n\n# arrange graphs beside one another\nggarrange(congruency_modality_graph, congruency_modality_cuetype_graph, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](2-jneuro-behavioural_files/figure-html/unnamed-chunk-21-1.png){width=768}\n:::\n:::\n\n\nThis can be interpreted like this: people respond more slowly to incongruent cue target presentations, but this difference is greater when the target is olfactory compared to when it is visual. We could also say they are 53ms slower at responding to incongruent olfactory targets compared to incongruent visual targets. In addition, the 95% credible intervals do not overlap with zero (-92.02, -15.15). All of the 95% most probable reaction times for this interaction are negative, so I think we can say this difference is likely negative too. For comparison, this interaction was statistically significant in the original paper (p = 0.02). I actually think a p-value that close to the threshold is not amazingly convincing, so it kind of matches the interpretation of the credible interval here. The plot on the right represents the 3-way interaction. This lets us see whether the disparity in congruent and incongruent reaction times, which is larger in olfaction, occurs when object-cues preceed the olfactory target. The model suggests this is not the case.\n\nThere are other interactions as well, but they were not central to our main hypotheses so I won't go into them here. In addition, I'm not a fan of 3-way interactions as they are hard to interpret and usually very underpowered to detect, so I don't see much value in looking at the 3-way interaction here.\n\n# Participant-Level Predictions\n\nBecause this is a class on random-effect models, I want to look at the random-effects specifically. Below I will process the data and estimates in such a way that I can display the participant-level random-effects and fixed-effects together. I am only doing this as an exercise, so I will just plot the results for the main effect of modality.\n\n## Modality random effects\n\nBelow is some pre-processing for displaying main random-effects estimates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# temporary dataframe to be filled in loop\ntemp_df <- data.frame(\"participant\" = factor(),\n                      \"empirical_olfactory_rt\" = numeric(),\n                      \"estimated_olfactory_rt\" = numeric(),\n                      \"empicial_visual_rt\" = numeric(),\n                      \"estimated_visual_rt\" = numeric())\n# for each unique participant:\nfor (i in unique(df$participant)) { \n  # ith participants' reaction time random effect for olfaction\n  olfaction_rt_i <- fixef(gaussian_model)[1]  + ranef(gaussian_model)$participant[i, 1, 1] + ranef(gaussian_model)$participant[i, 1, 2] + ranef(gaussian_model)$participant[i, 1, 3] + ranef(gaussian_model)$participant[i, 1, 4]\n  # ith participants' reaction time random effect for vision\n  visual_rt_i <- fixef(gaussian_model)[1] + (fixef(gaussian_model)[2]) + ranef(gaussian_model)$participant[i, 1, 1] + ranef(gaussian_model)$participant[i, 1, 2] + ranef(gaussian_model)$participant[i, 1, 3] + ranef(gaussian_model)$participant[i, 1, 4]\n  # dataframe of fixed and random modality effect estimates for ith person\n  participant_df <- data.frame(\"participant\" = i,\n                      \"empirical_olfactory_rt\" = fixef(gaussian_model)[1],\n                      \"estimated_olfactory_rt\" = olfaction_rt_i,\n                      \"empicial_visual_rt\" = fixef(gaussian_model)[1] + (fixef(gaussian_model)[2]),\n                      \"estimated_visual_rt\" = fixef(gaussian_model)[1] + (fixef(gaussian_model)[2]) + ranef(gaussian_model)$participant[i, 1, 1] + ranef(gaussian_model)$participant[i, 1, 2] + ranef(gaussian_model)$participant[i, 1, 3] + ranef(gaussian_model)$participant[i, 1, 4])\n  # here all participant fixed and random modality effect estimates are combined in a single dataframe\n  temp_df <- rbind(temp_df, participant_df)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# reshape from wide to long\nmodality_df <- temp_df %>% pivot_longer(cols = c('empirical_olfactory_rt', 'estimated_olfactory_rt', 'empicial_visual_rt', 'estimated_visual_rt'),\n                    names_to = 'coefficient',\n                    values_to = 'rt')\n# create new column\nmodality_df$group <- factor(ifelse(modality_df$coefficient == \"empirical_olfactory_rt\", \"empirical\",\n                            ifelse(modality_df$coefficient == \"empicial_visual_rt\", \"empirical\", \"estimated\")))\n# create new column\nmodality_df$group2 <- factor(ifelse(modality_df$coefficient == \"empirical_olfactory_rt\", \"olfactory\",\n                            ifelse(modality_df$coefficient == \"estimated_olfactory_rt\", \"olfactory\", \"visual\")))\n# rename columns\ncolnames(modality_df) <- c(\"participant\", \"coefficient\", \"rt\", \"estimate\", \"modality\")\n\nmodality_df_estimates <- modality_df[modality_df$estimate == \"estimated\", ]\nmodality_df_estimates <- aggregate(modality_df$rt, list(modality_df$participant, modality_df$modality), mean)\ncolnames(modality_df_estimates) <- c(\"participant\", \"modality\", \"rt\")\n\n# Calculate mean rt for each modality\nmean_values <- modality_df_estimates %>%\n  group_by(modality) %>%\n  summarize(mean_rt = mean(rt))\n\nmean_values <- data.frame(\"participant\" = c(101, 101),\n                          \"modality\" = c(\"olfactory\", \"visual\"),\n                          \"rt\" = c(1837, 612))\nmean_values$participant <- as.factor(mean_values$participant)\nmean_values$modality <- as.factor(mean_values$modality)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# graph random effects for modality\nggplot(modality_df_estimates, aes(x = modality, y = rt, group = participant)) +\n  geom_point(color = \"grey\") +\n  geom_line(color = \"grey\")  +\n  geom_point(data = mean_values, aes(x = modality, y = rt), color = \"black\", size = 3) +\n  geom_line(data = mean_values, aes(x = modality, y = rt, group = 1), color = \"black\", size = 1.5) +\n  ggtitle(\"Modality Random Effects\")\n```\n\n::: {.cell-output-display}\n![](2-jneuro-behavioural_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\nAn alternate way to view this is to put each participants' random effect estimate on a plot with the fixed effect estimate, and plot each of these on individual panels. Maybe not as intuitive as the previous plot, but it still makes sense to look at it like this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# empty list where each runner's graph will be saved.\ntemp_list <- list()  \n# loop through runners, grab their specific intercepts/slope from previous dataframe, and save graph to list\nfor (i in unique(modality_df$participant)) {\n  # runner-specific graph\n  temp_graph <- ggplot(modality_df[modality_df$participant == i, ], aes(x = modality, y = rt, color = estimate, group = estimate)) +\n  geom_point() +\n  geom_line() +\n    ylim(0, 2800) +\n    ggtitle(paste0(\"Subject \", i)) +\n    theme(legend.position = \"none\")\n  # save ith runner graph to temp_list\n  temp_list[[i]] <- temp_graph\n}\n\narg_list <- c(temp_list, list(nrow = 13, ncol = 5))\n# Use do.call to pass all elements of graph_list to ggarrange\narranged_plots <- do.call(\"ggarrange\", arg_list)\n# Print or display the arranged plots\nprint(arranged_plots)\n```\n\n::: {.cell-output-display}\n![](2-jneuro-behavioural_files/figure-html/unnamed-chunk-25-1.png){width=768}\n:::\n:::\n\n\n# Conclusion\n\nThe Bayesian random effects model seems to converge with the frequentist analysis I published. The interpretations, like with the 2-way factorial design, lead to similar conclusions regardless of whether I use p-values or posterior estimates.\n",
    "supporting": [
      "2-jneuro-behavioural_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}